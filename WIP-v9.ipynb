{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "READ (described in Sec. 3.2),\n",
    "WRITE (described in Sec. 3.2).\n",
    "\n",
    "ZERO(a, b) = 0, \n",
    "ONE(a, b) = 1, \n",
    "TWO(a, b) = 2, \n",
    "\n",
    "INC(a, b) = (a+1) mod M, \n",
    "ADD(a, b) = (a+b) mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "from theano import tensor\n",
    "from collections import namedtuple\n",
    "from theano.tensor.extra_ops import to_one_hot\n",
    "from theano.tensor import roll\n",
    "from theano.tensor import stack\n",
    "from theano.tensor import batched_dot\n",
    "from theano.tensor import concatenate\n",
    "from theano.tensor import as_tensor\n",
    "from theano.tensor import set_subtensor\n",
    "from theano import shared\n",
    "from numpy.random import uniform\n",
    "from theano.tensor.nnet import softmax, relu, sigmoid\n",
    "from theano import function, config, shared, sandbox, Out\n",
    "\n",
    "def zero() :\n",
    "    return to_one_hot(np.asarray([0]),M)\n",
    "def one() :\n",
    "    return to_one_hot(np.asarray([1]),M)\n",
    "def two() :\n",
    "    return to_one_hot(np.asarray([2]),M)\n",
    "def get_const(value) :\n",
    "    return to_one_hot(np.asarray([value % M]),M)\n",
    "def create_memory_tape(init_val=0):\n",
    "    m = stack([get_const(init_val) for i in range(M)], axis=1)\n",
    "    #return shared(np.asarray(m.eval()), config.floatX) \n",
    "    return m\n",
    "def inc(a) :\n",
    "    return roll(a, 1, axis=1)\n",
    "def negate(a) :\n",
    "    return roll(a[:, ::-1], 1, axis=1)\n",
    "def add(a,b) :\n",
    "    rows = [roll(b[:,], j, axis=1) for j in range(M)]\n",
    "    return (batched_dot(a, stack(rows, axis=1)))\n",
    "def sub(a,b) :\n",
    "    b_negative = negate(b)\n",
    "    return add(a, b_negative)\n",
    "def eq_zero(a) :\n",
    "    r = tensor.zeros_like(as_tensor(a))\n",
    "    r = set_subtensor(r[:,1], a[:, 0])\n",
    "    r = set_subtensor(r[:, 0], 1 - a[:, 0])\n",
    "    return r\n",
    "def lt(a,b):\n",
    "    return tensor.lt(as_tensor(a),as_tensor(b))\n",
    "def lte(a,b):\n",
    "    return tensor.le(as_tensor(a),as_tensor(b))\n",
    "def eq(a,b):\n",
    "    return tensor.eq(as_tensor(a),as_tensor(b))\n",
    "def min(a,b):\n",
    "    if(lte(a,b)):\n",
    "        return as_tensor(a)\n",
    "    else:\n",
    "        return as_tensor(b)\n",
    "def max(a,b):\n",
    "    if(lt(a,b)):\n",
    "        return as_tensor(b)\n",
    "    else:\n",
    "        return as_tensor(a)    \n",
    "def read(mem, a) :\n",
    "    ptr = as_tensor(a)\n",
    "    return weighted_avg(mem, ptr), mem\n",
    "def write(mem, a, b) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    mem = (x + y)\n",
    "    return val, mem\n",
    "def write_external(a, b, ext_mem) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, ext_mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    ext_mem = (x + y)\n",
    "    return ext_mem\n",
    "\n",
    "def get_registers(init_val):\n",
    "    return stack([get_const(init_val) for i in range(R)], axis=1)\n",
    "\n",
    "def weighted_avg(inputs, coefficient) :\n",
    "    return batched_dot(inputs.transpose(0, 2, 1), coefficient.dimshuffle(0, 1, 'x')).flatten(2);\n",
    "\n",
    "def compute_gate_new(module, inputs, coefficients, memory_tape, debug=False) :\n",
    "    \"\"\" Arity of this gate must be equal to the number of given\n",
    "        coefficients list\n",
    "    \"\"\" \n",
    "    if (len(coefficients) != module.arity) :\n",
    "        print(\"Error: Incorrect number of coefficients: \",  len(coefficients), \" to module arity: \", module.arity)\n",
    "    \n",
    "    params = [weighted_avg(inputs, as_tensor(coef)) for coef in coefficients]\n",
    "    \n",
    "    if (debug == True):\n",
    "        for i, p in enumerate(params):\n",
    "            print(\"compute_gate_new: weighted param [\", i ,\"] = \", p.eval())\n",
    "    \n",
    "    if (module.memory_function == True) :\n",
    "        #print(\"read/write \")\n",
    "        output, memory_tape = module.function(memory_tape, *params)\n",
    "    else :   \n",
    "        output = module.function(*params)\n",
    "    \n",
    "    if (debug == True):\n",
    "        print(\"output from module: \", output.eval())\n",
    "    \n",
    "    #error check for constant gates\n",
    "    return output, memory_tape\n",
    "\n",
    "\n",
    "def get_n_tensor(t, count, idx):\n",
    "    result=[]\n",
    "    if count > 0: \n",
    "        result = [t[idx+i] for i in range(count)]\n",
    "    return result, (idx+count)\n",
    "\n",
    "def fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug=False):\n",
    "    # Initially, only the registers may be used as inputs.\n",
    "    Q= len(gates)\n",
    "    gate_inputs = registers\n",
    "    idx=0    \n",
    "    \n",
    "    # Run through all the gates.\n",
    "    for i in range(Q):\n",
    "        c, idx = get_n_tensor(gate_coef, gates[i].arity, idx) \n",
    "        output, memory_tape = compute_gate_new(gates[i], gate_inputs, c, memory_tape)\n",
    "        # Append the output of the gate as an input for future gates.\n",
    "        gate_inputs = concatenate([gate_inputs, output.dimshuffle(0,'x',1)], axis=1)\n",
    "        if (debug==True):\n",
    "            print(\"gate i = \", i, \"arity:\", gates[i].arity, \"gate inputs: \", gate_inputs.eval().argmax(axis=2), \"gate output: \", output.eval().argmax())    \n",
    "            print(\"concatenated inputs: \", gate_inputs.eval().argmax(axis=2))       \n",
    "        \n",
    "    # All leftover coefficients are for registers.\n",
    "    new_registers = []\n",
    "             \n",
    "    for i in range(len(reg_coef)):\n",
    "        # (R+Q) x M dot 1 X (R+Q) \n",
    "        new_registers.append(weighted_avg(gate_inputs, reg_coef[i]))\n",
    "        if (debug == True) :\n",
    "            print(\"register [\", i, \"]  new value: reg_coef\", reg_coef[i].eval().argmax(),\"weighted_avg of gate inputs and reg_coef: \", weighted_avg(gate_inputs, reg_coef[i]).eval().argmax())\n",
    "    return tensor.stack(new_registers, axis=1), memory_tape\n",
    "\n",
    "\n",
    "# coefficients = [r1,r2..rR,g1_param1,g1_param2,...,gQ_param1,gQ_param2,c1,c1..CR,cR+1,..cR+Q]\n",
    "def gen_random_weights(layer1, layer2, dtype=np.float64, _min=-1, _max=1):\n",
    "    weights = uniform(low=_min, high=_max, size=(layer1, layer2))\n",
    "    var = shared(weights.astype(dtype), name=\"w{0}x{1}\".format(layer1, layer2))   \n",
    "    #var = tensor.addbroadcast(var, 0)\n",
    "    return var\n",
    "\n",
    "def gen_network_weights(gates, layers):\n",
    "    n_registers = R #input is R registers\n",
    "    w = []\n",
    "    current_layer_units = n_registers\n",
    "    \n",
    "    for next_layer_units in layers:\n",
    "        w.append(gen_random_weights(current_layer_units + 1, next_layer_units))\n",
    "        current_layer_units = next_layer_units\n",
    "    \n",
    "    #output wt for gate coefficients\n",
    "    gate_coef = []\n",
    "    for i, gate in enumerate(gates):\n",
    "        print(i, gate)\n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            gate_coef.append(gen_random_weights(current_layer_units + 1, gate_output_units))            \n",
    "    \n",
    "    #print(\"gen_network_weights => gate_coef\", gate_coef)         \n",
    "    \n",
    "    #output wt for new registers\n",
    "    reg_coef = []\n",
    "    reg_output_units = n_registers + len(gates)\n",
    "    for _ in range(n_registers):\n",
    "        reg_coef.append(gen_random_weights(current_layer_units + 1, n_registers + len(gates)))    \n",
    "    \n",
    "    #print(\"gen_network_weights => reg_coef\", reg_coef)      \n",
    "     \n",
    "    prob_completion_coef = (gen_random_weights(current_layer_units + 1, 1))\n",
    "\n",
    "    for i in gate_coef:\n",
    "        w.append(i)\n",
    "\n",
    "    for x in reg_coef:\n",
    "        w.append(x)\n",
    "    \n",
    "    w.append(prob_completion_coef)   \n",
    "    return w\n",
    "\n",
    "def aug_ones_col(inputs):\n",
    "    print(\"OMFG\")\n",
    "    s = inputs.shape\n",
    "    col_elems = s[1]\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), col_elems))\n",
    "    x = concatenate([inputs.T,ones], axis=1)\n",
    "    return x.T\n",
    "\n",
    "def aug_ones_col_new(inputs):\n",
    "    x=[]\n",
    "    s = inputs.shape\n",
    "    #print(s.eval())\n",
    "    d = inputs.ndim\n",
    "    row_elems = s[d-2]\n",
    "    #print(\"aug one col, dimension of inputs = \", d)\n",
    "    matrix = tensor.reshape(inputs, (s[d-2],s[d-1]))\n",
    "    #print(matrix.eval())\n",
    "    matrix = tensor.shape_padleft(matrix)\n",
    "    #print(matrix.eval())\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), row_elems))\n",
    "    #print(ones.eval())\n",
    "    #print(\"shuffled ones: \", ones.dimshuffle(0,'x',1).eval())\n",
    "    #print(\"shuffled matrix: \",matrix.dimshuffle(0,2,1).eval())\n",
    "    x = concatenate([matrix.dimshuffle(0,2,1),ones.dimshuffle(0,'x',1)], axis=1)\n",
    "    return x.dimshuffle(0,2,1)\n",
    "\n",
    "def controller_forward_prop(n_registers, layers, weight_matrix, gates, registers) :\n",
    "    inputs = registers[:,:,0]\n",
    "    inputs = aug_ones_col_new(inputs)\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        W = weight_matrix[i]\n",
    "        inputs = aug_ones_col_new(relu(inputs.dot(W)))  \n",
    "    \n",
    "    #extract gate coefficients\n",
    "    gate_coef = []\n",
    "    n_gate_coef = 0\n",
    "    for i, gate in enumerate(gates): \n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            n_gate_coef += 1 \n",
    "            \n",
    "    for W in weight_matrix[len(layers):len(layers) + n_gate_coef]:\n",
    "        gate_coef.append(softmax(inputs.dot(W)[0]))            \n",
    "\n",
    "    reg_coef = []\n",
    "    \n",
    "    for W in (weight_matrix[len(layers)+n_gate_coef:len(layers)+n_gate_coef+n_registers]):\n",
    "        reg_coef.append(softmax(inputs.dot(W)[0])) \n",
    "        \n",
    "    p = sigmoid(inputs.dot(weight_matrix[-1]))\n",
    "    \n",
    "    return p, reg_coef, gate_coef\n",
    "\n",
    "def calculate_cost_at_t(prob_complete_t, t, cum_cost, cum_prob_t, p_incomplete, memory_in, desired_output, output_len, debug) :\n",
    "    e = 1e-100\n",
    "    cost_t = 0\n",
    "    #TODO: Find use for desired registers in calculating cost. Now, only desired memory layout is matched.\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        #Compute the loss for this register using the mask.\n",
    "        mask = to_one_hot(desired_output.argmax(axis=2)[:,i], M)        \n",
    "        a = tensor.log(memory_in[:, i, :] + e)\n",
    "        x = mask * a\n",
    "        loss = (x).sum(axis=1)\n",
    "        cost_t += tensor.shape_padright(loss, 1)\n",
    "    if (debug == True):\n",
    "        print(\"Desired value at mem location [\", i, \"] is \", mask.eval().argmax(), \"but actual value is [\", memory_in[:,i,:].eval().argmax(), \"loss is \", loss.eval(), \" cost = \", cost_t.eval()) \n",
    "\n",
    "    if (t >= MAX_TIMESTEP):\n",
    "        prob_complete = 1 - cum_prob_t\n",
    "    else:\n",
    "        prob_complete = prob_complete_t * p_incomplete\n",
    "    \n",
    "    p_incomplete *= (1 - prob_complete_t)   \n",
    "    cum_prob_t += prob_complete\n",
    "        \n",
    "    cum_cost = -(cost_t*prob_complete_t)\n",
    "    #print (\"cost at t\", cost_t)\n",
    "    #print (\"p of completion at t\", prob_complete)\n",
    "    \n",
    "    return cum_cost, cum_prob_t, p_incomplete\n",
    "\n",
    "def machine_compute_step_t(debug, R, layers, w, gates, t, desired_output, output_len, registers, memory_tape, cost_t, cum_prob, prob_incomplete) : \n",
    "    \n",
    "    p, reg_coef, gate_coef = controller_forward_prop(R, layers, w, gates, registers)\n",
    "    \n",
    "    new_registers, new_memory_tape = fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug)\n",
    "    \n",
    "    cost_t, cum_prob_t, prob_incomplete = calculate_cost_at_t(p, t, cost_t, cum_prob, prob_incomplete, new_memory_tape, desired_output, output_len, debug)\n",
    "    \n",
    "    return new_registers, new_memory_tape, cost_t, cum_prob_t, prob_incomplete\n",
    "\n",
    "def compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len):\n",
    "    #w = make_broadcastable(w)\n",
    "    # Create symbolic variables for the input to the machine\n",
    "    # and for the desired output of the machine.\n",
    "      \n",
    "    #initial_registers = registers\n",
    "    #desired_output = memory_tape\n",
    "\n",
    "    initial_registers = tensor.dtensor3(\"Registers\")\n",
    "    initial_memory = tensor.dtensor3(\"Memory_Tape\")\n",
    "    desired_output = tensor.dtensor3(\"Y\")\n",
    "     \n",
    "    \n",
    "    # Run the model for all timesteps. The arguments are \n",
    "    # registers, cost, cumulative probability complete, \n",
    "    # and probability incomplete. The latter are initialized\n",
    "    # to zero and to one, respectively.\n",
    "    \n",
    "    v0 = as_tensor(0)\n",
    "    v1 = as_tensor(1)\n",
    "    output = [initial_registers, initial_memory, v0, v0, v1]\n",
    "    intermediate_registers = []\n",
    "    for timestep in range(MAX_TIMESTEP):\n",
    "        print(\"compute_all_timesteps t = \", timestep)\n",
    "        output = machine_compute_step_t(False, R, layers, w, gates, timestep+1, desired_output, output_len, *(output))\n",
    "        intermediate_registers.append(output[0])\n",
    "        \n",
    "        #registers=new_registers\n",
    "\n",
    "    # Add in regularization, to avoid overfitting simple examples.\n",
    "    reg_cost = reg_lambda * sum((p * p).sum() for p in list(w))\n",
    "    \n",
    "    # Get the final cost: regularization plus loss.\n",
    "    final_cost = reg_cost + output[2].sum()\n",
    "    \n",
    "    # Return the symbolic variables, the final cost, and the\n",
    "    # intermediate register values for analysis and prediction.\n",
    "    return initial_registers, initial_memory, desired_output, final_cost, intermediate_registers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Module(arity=1, function=<function read at 0x135af2938>, memory_function=True))\n",
      "(1, Module(arity=1, function=<function inc at 0x124cf5140>, memory_function=False))\n",
      "(2, Module(arity=2, function=<function lt at 0x135af28c0>, memory_function=False))\n",
      "(3, Module(arity=2, function=<function min at 0x135af25f0>, memory_function=False))\n",
      "(4, Module(arity=2, function=<function write at 0x135af29b0>, memory_function=True))\n",
      "('weight matrix: ', [w3x1, w2x2, w3x2, w3x3, w3x4, w3x4, w3x5, w3x5, w3x6, w3x6, w3x7, w3x7, w3x1])\n"
     ]
    }
   ],
   "source": [
    "#Maximum Representable Integer M is set below\n",
    "M = 16\n",
    "# Number of registers\n",
    "R = 2\n",
    "#Max number of timesteps\n",
    "MAX_TIMESTEP = 5\n",
    "\n",
    "Module = namedtuple(\"Module\", \"arity function memory_function\")\n",
    "\n",
    "m_zero = Module(0, zero, False)\n",
    "m_one = Module(0, one, False)\n",
    "m_two = Module(0, two, False)\n",
    "m_inc = Module(1, inc, False)\n",
    "m_negate = Module(1, negate, False)\n",
    "m_add = Module(2, add, False)\n",
    "m_sub = Module(2, sub, False)\n",
    "m_eq_zero = Module(1, eq_zero, False)\n",
    "m_read = Module(1, read, True)\n",
    "m_write = Module(2, write, True)\n",
    "m_lt = Module(2, lt, False)\n",
    "m_lte = Module(2, lte, False)\n",
    "m_eq = Module(2, eq, False)\n",
    "m_min = Module(2, min, False)\n",
    "m_max = Module(2, max, False)\n",
    "\n",
    "gates = [m_read, m_inc, m_lt, m_min, m_write]\n",
    "N = len(gates)\n",
    "\n",
    "registers = get_registers(1)\n",
    "memory_tape = create_memory_tape()\n",
    "desired_out = create_memory_tape(0)\n",
    "for i in range(M):\n",
    "     desired_out = write_external(get_const(i), get_const(i), desired_out)\n",
    "        \n",
    "layers = [1,2]\n",
    "w = gen_network_weights(gates, layers)\n",
    "print(\"weight matrix: \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('compute_all_timesteps t = ', 0)\n",
      "('compute_all_timesteps t = ', 1)\n",
      "('compute_all_timesteps t = ', 2)\n",
      "('compute_all_timesteps t = ', 3)\n",
      "('compute_all_timesteps t = ', 4)\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "output_len = 1\n",
    "result  = compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len)\n",
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Registers,\n",
       " Memory_Tape,\n",
       " Y,\n",
       " Elemwise{add,no_inplace}.0,\n",
       " [Join.0, Join.0, Join.0, Join.0, Join.0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradients = theano.grad(final_cost, list(w)) #, disconnected_inputs='warn', return_disconnected='Disconnected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n"
     ]
    }
   ],
   "source": [
    "for r in intermediate_registers:\n",
    "    print (r.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile training function to compute gradients.\n",
    "train = theano.function([initial_registers, initial_memory, desired_output], [final_cost] + gradients) #, on_unused_input='ignore', allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile prediction function (registers after one timestep)\n",
    "predict = theano.function([initial_registers, initial_memory], intermediate_registers[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Access Task\n",
    "input = [ 7,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "output = [ 13 ]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_out.shape.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('desired_out.eval()', array([[13]]))\n",
      "('memory_tape.eval()', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('registers.eval()', array([[0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print (\"desired_out.eval()\", desired_out.eval().argmax(axis=2))\n",
    "print (\"memory_tape.eval()\", memory_tape.eval().argmax(axis=2))\n",
    "print (\"registers.eval()\", registers.eval().argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(6.234160848431787), array([[ 0.15817691],\n",
      "       [ 0.19405676],\n",
      "       [ 0.2795831 ]]), array([[ 0.01372796,  0.1565657 ],\n",
      "       [-0.07302425,  0.42707281]]), array([[ 0.06057222,  0.26085614],\n",
      "       [-0.03231689,  0.0801639 ],\n",
      "       [-0.16759537, -0.02303606]]), array([[ 0.05423171,  0.07153301, -0.05765532],\n",
      "       [ 0.00528494,  0.1923966 , -0.04028468],\n",
      "       [-0.17478911, -0.18089881,  0.04720526]]), array([[ 0.16142096, -0.06168463, -0.0304605 , -0.14247695],\n",
      "       [-0.13982379,  0.16828223, -0.06986455,  0.13769004],\n",
      "       [-0.06234009, -0.13569939, -0.18171548, -0.05973439]]), array([[ 0.06549288,  0.11193271, -0.15103856, -0.101647  ],\n",
      "       [ 0.12943572, -0.11285003, -0.12190806, -0.08356006],\n",
      "       [ 0.14927382, -0.04503218, -0.06048131, -0.12664837]]), array([[ 0.09879374,  0.12381521,  0.0341211 ,  0.16695382,  0.00330613],\n",
      "       [ 0.02197201,  0.0520403 , -0.19717396, -0.13825159,  0.02263162],\n",
      "       [ 0.16955022,  0.17491642, -0.09062839,  0.20202347,  0.13548093]]), array([[-0.1085891 ,  0.00839348, -0.1797006 ,  0.00375164, -0.15163484],\n",
      "       [ 0.12550263, -0.05338451, -0.10578782, -0.10046064,  0.1906595 ],\n",
      "       [ 0.12585863, -0.08437633,  0.00677768,  0.19877806, -0.12183734]]), array([[-0.17677739, -0.0376452 ,  0.00868275, -0.09059676, -0.10116249,\n",
      "        -0.03113926],\n",
      "       [-0.04525818, -0.00950359, -0.10426231,  0.18860347, -0.03143612,\n",
      "        -0.18937659],\n",
      "       [ 0.13021095,  0.12817004, -0.02790038,  0.1731753 ,  0.00087404,\n",
      "        -0.08273122]]), array([[ 0.1635897 ,  0.13560782, -0.00400935, -0.14971477,  0.02696709,\n",
      "        -0.00122367],\n",
      "       [ 0.10155199,  0.12244543,  0.02082136,  0.01734908,  0.07487588,\n",
      "        -0.15165118],\n",
      "       [ 0.19209112,  0.20339859, -0.18895469,  0.02498743, -0.15291778,\n",
      "        -0.15968743]]), array([[ 0.02400989, -0.08719025, -0.05498552, -0.03445863, -0.00328958,\n",
      "        -0.08495768, -0.09265213],\n",
      "       [-0.19215263, -0.0261894 , -0.21052323, -0.09835735,  0.01356076,\n",
      "         0.15088197, -0.07932021],\n",
      "       [-0.08680345, -0.02781459, -0.05722111, -0.09971863, -0.15349741,\n",
      "        -0.12397511, -0.04242417]]), array([[-0.13141356,  0.06329455, -0.02583858,  0.23210013,  0.0471235 ,\n",
      "        -0.12389227, -0.01791477],\n",
      "       [-0.11003474,  0.06896257, -0.17796564, -0.1586117 , -0.16441454,\n",
      "         0.14356497, -0.13116129],\n",
      "       [ 0.04104108,  0.04847361, -0.05489157,  0.24612423, -0.17242291,\n",
      "         0.0810186 , -0.05406391]]), array([[ 0.56653008],\n",
      "       [ 0.19638264],\n",
      "       [ 0.64406016]])]\n",
      "[array(6.234160848431787), array([[ 0.15817691],\n",
      "       [ 0.19405676],\n",
      "       [ 0.2795831 ]]), array([[ 0.01372796,  0.1565657 ],\n",
      "       [-0.07302425,  0.42707281]]), array([[ 0.06057222,  0.26085614],\n",
      "       [-0.03231689,  0.0801639 ],\n",
      "       [-0.16759537, -0.02303606]]), array([[ 0.05423171,  0.07153301, -0.05765532],\n",
      "       [ 0.00528494,  0.1923966 , -0.04028468],\n",
      "       [-0.17478911, -0.18089881,  0.04720526]]), array([[ 0.16142096, -0.06168463, -0.0304605 , -0.14247695],\n",
      "       [-0.13982379,  0.16828223, -0.06986455,  0.13769004],\n",
      "       [-0.06234009, -0.13569939, -0.18171548, -0.05973439]]), array([[ 0.06549288,  0.11193271, -0.15103856, -0.101647  ],\n",
      "       [ 0.12943572, -0.11285003, -0.12190806, -0.08356006],\n",
      "       [ 0.14927382, -0.04503218, -0.06048131, -0.12664837]]), array([[ 0.09879374,  0.12381521,  0.0341211 ,  0.16695382,  0.00330613],\n",
      "       [ 0.02197201,  0.0520403 , -0.19717396, -0.13825159,  0.02263162],\n",
      "       [ 0.16955022,  0.17491642, -0.09062839,  0.20202347,  0.13548093]]), array([[-0.1085891 ,  0.00839348, -0.1797006 ,  0.00375164, -0.15163484],\n",
      "       [ 0.12550263, -0.05338451, -0.10578782, -0.10046064,  0.1906595 ],\n",
      "       [ 0.12585863, -0.08437633,  0.00677768,  0.19877806, -0.12183734]]), array([[-0.17677739, -0.0376452 ,  0.00868275, -0.09059676, -0.10116249,\n",
      "        -0.03113926],\n",
      "       [-0.04525818, -0.00950359, -0.10426231,  0.18860347, -0.03143612,\n",
      "        -0.18937659],\n",
      "       [ 0.13021095,  0.12817004, -0.02790038,  0.1731753 ,  0.00087404,\n",
      "        -0.08273122]]), array([[ 0.1635897 ,  0.13560782, -0.00400935, -0.14971477,  0.02696709,\n",
      "        -0.00122367],\n",
      "       [ 0.10155199,  0.12244543,  0.02082136,  0.01734908,  0.07487588,\n",
      "        -0.15165118],\n",
      "       [ 0.19209112,  0.20339859, -0.18895469,  0.02498743, -0.15291778,\n",
      "        -0.15968743]]), array([[ 0.02400989, -0.08719025, -0.05498552, -0.03445863, -0.00328958,\n",
      "        -0.08495768, -0.09265213],\n",
      "       [-0.19215263, -0.0261894 , -0.21052323, -0.09835735,  0.01356076,\n",
      "         0.15088197, -0.07932021],\n",
      "       [-0.08680345, -0.02781459, -0.05722111, -0.09971863, -0.15349741,\n",
      "        -0.12397511, -0.04242417]]), array([[-0.13141356,  0.06329455, -0.02583858,  0.23210013,  0.0471235 ,\n",
      "        -0.12389227, -0.01791477],\n",
      "       [-0.11003474,  0.06896257, -0.17796564, -0.1586117 , -0.16441454,\n",
      "         0.14356497, -0.13116129],\n",
      "       [ 0.04104108,  0.04847361, -0.05489157,  0.24612423, -0.17242291,\n",
      "         0.0810186 , -0.05406391]]), array([[ 0.56653008],\n",
      "       [ 0.19638264],\n",
      "       [ 0.64406016]])]\n",
      "[array(6.234160848431787), array([[ 0.15817691],\n",
      "       [ 0.19405676],\n",
      "       [ 0.2795831 ]]), array([[ 0.01372796,  0.1565657 ],\n",
      "       [-0.07302425,  0.42707281]]), array([[ 0.06057222,  0.26085614],\n",
      "       [-0.03231689,  0.0801639 ],\n",
      "       [-0.16759537, -0.02303606]]), array([[ 0.05423171,  0.07153301, -0.05765532],\n",
      "       [ 0.00528494,  0.1923966 , -0.04028468],\n",
      "       [-0.17478911, -0.18089881,  0.04720526]]), array([[ 0.16142096, -0.06168463, -0.0304605 , -0.14247695],\n",
      "       [-0.13982379,  0.16828223, -0.06986455,  0.13769004],\n",
      "       [-0.06234009, -0.13569939, -0.18171548, -0.05973439]]), array([[ 0.06549288,  0.11193271, -0.15103856, -0.101647  ],\n",
      "       [ 0.12943572, -0.11285003, -0.12190806, -0.08356006],\n",
      "       [ 0.14927382, -0.04503218, -0.06048131, -0.12664837]]), array([[ 0.09879374,  0.12381521,  0.0341211 ,  0.16695382,  0.00330613],\n",
      "       [ 0.02197201,  0.0520403 , -0.19717396, -0.13825159,  0.02263162],\n",
      "       [ 0.16955022,  0.17491642, -0.09062839,  0.20202347,  0.13548093]]), array([[-0.1085891 ,  0.00839348, -0.1797006 ,  0.00375164, -0.15163484],\n",
      "       [ 0.12550263, -0.05338451, -0.10578782, -0.10046064,  0.1906595 ],\n",
      "       [ 0.12585863, -0.08437633,  0.00677768,  0.19877806, -0.12183734]]), array([[-0.17677739, -0.0376452 ,  0.00868275, -0.09059676, -0.10116249,\n",
      "        -0.03113926],\n",
      "       [-0.04525818, -0.00950359, -0.10426231,  0.18860347, -0.03143612,\n",
      "        -0.18937659],\n",
      "       [ 0.13021095,  0.12817004, -0.02790038,  0.1731753 ,  0.00087404,\n",
      "        -0.08273122]]), array([[ 0.1635897 ,  0.13560782, -0.00400935, -0.14971477,  0.02696709,\n",
      "        -0.00122367],\n",
      "       [ 0.10155199,  0.12244543,  0.02082136,  0.01734908,  0.07487588,\n",
      "        -0.15165118],\n",
      "       [ 0.19209112,  0.20339859, -0.18895469,  0.02498743, -0.15291778,\n",
      "        -0.15968743]]), array([[ 0.02400989, -0.08719025, -0.05498552, -0.03445863, -0.00328958,\n",
      "        -0.08495768, -0.09265213],\n",
      "       [-0.19215263, -0.0261894 , -0.21052323, -0.09835735,  0.01356076,\n",
      "         0.15088197, -0.07932021],\n",
      "       [-0.08680345, -0.02781459, -0.05722111, -0.09971863, -0.15349741,\n",
      "        -0.12397511, -0.04242417]]), array([[-0.13141356,  0.06329455, -0.02583858,  0.23210013,  0.0471235 ,\n",
      "        -0.12389227, -0.01791477],\n",
      "       [-0.11003474,  0.06896257, -0.17796564, -0.1586117 , -0.16441454,\n",
      "         0.14356497, -0.13116129],\n",
      "       [ 0.04104108,  0.04847361, -0.05489157,  0.24612423, -0.17242291,\n",
      "         0.0810186 , -0.05406391]]), array([[ 0.56653008],\n",
      "       [ 0.19638264],\n",
      "       [ 0.64406016]])]\n",
      "[array(6.234160848431787), array([[ 0.15817691],\n",
      "       [ 0.19405676],\n",
      "       [ 0.2795831 ]]), array([[ 0.01372796,  0.1565657 ],\n",
      "       [-0.07302425,  0.42707281]]), array([[ 0.06057222,  0.26085614],\n",
      "       [-0.03231689,  0.0801639 ],\n",
      "       [-0.16759537, -0.02303606]]), array([[ 0.05423171,  0.07153301, -0.05765532],\n",
      "       [ 0.00528494,  0.1923966 , -0.04028468],\n",
      "       [-0.17478911, -0.18089881,  0.04720526]]), array([[ 0.16142096, -0.06168463, -0.0304605 , -0.14247695],\n",
      "       [-0.13982379,  0.16828223, -0.06986455,  0.13769004],\n",
      "       [-0.06234009, -0.13569939, -0.18171548, -0.05973439]]), array([[ 0.06549288,  0.11193271, -0.15103856, -0.101647  ],\n",
      "       [ 0.12943572, -0.11285003, -0.12190806, -0.08356006],\n",
      "       [ 0.14927382, -0.04503218, -0.06048131, -0.12664837]]), array([[ 0.09879374,  0.12381521,  0.0341211 ,  0.16695382,  0.00330613],\n",
      "       [ 0.02197201,  0.0520403 , -0.19717396, -0.13825159,  0.02263162],\n",
      "       [ 0.16955022,  0.17491642, -0.09062839,  0.20202347,  0.13548093]]), array([[-0.1085891 ,  0.00839348, -0.1797006 ,  0.00375164, -0.15163484],\n",
      "       [ 0.12550263, -0.05338451, -0.10578782, -0.10046064,  0.1906595 ],\n",
      "       [ 0.12585863, -0.08437633,  0.00677768,  0.19877806, -0.12183734]]), array([[-0.17677739, -0.0376452 ,  0.00868275, -0.09059676, -0.10116249,\n",
      "        -0.03113926],\n",
      "       [-0.04525818, -0.00950359, -0.10426231,  0.18860347, -0.03143612,\n",
      "        -0.18937659],\n",
      "       [ 0.13021095,  0.12817004, -0.02790038,  0.1731753 ,  0.00087404,\n",
      "        -0.08273122]]), array([[ 0.1635897 ,  0.13560782, -0.00400935, -0.14971477,  0.02696709,\n",
      "        -0.00122367],\n",
      "       [ 0.10155199,  0.12244543,  0.02082136,  0.01734908,  0.07487588,\n",
      "        -0.15165118],\n",
      "       [ 0.19209112,  0.20339859, -0.18895469,  0.02498743, -0.15291778,\n",
      "        -0.15968743]]), array([[ 0.02400989, -0.08719025, -0.05498552, -0.03445863, -0.00328958,\n",
      "        -0.08495768, -0.09265213],\n",
      "       [-0.19215263, -0.0261894 , -0.21052323, -0.09835735,  0.01356076,\n",
      "         0.15088197, -0.07932021],\n",
      "       [-0.08680345, -0.02781459, -0.05722111, -0.09971863, -0.15349741,\n",
      "        -0.12397511, -0.04242417]]), array([[-0.13141356,  0.06329455, -0.02583858,  0.23210013,  0.0471235 ,\n",
      "        -0.12389227, -0.01791477],\n",
      "       [-0.11003474,  0.06896257, -0.17796564, -0.1586117 , -0.16441454,\n",
      "         0.14356497, -0.13116129],\n",
      "       [ 0.04104108,  0.04847361, -0.05489157,  0.24612423, -0.17242291,\n",
      "         0.0810186 , -0.05406391]]), array([[ 0.56653008],\n",
      "       [ 0.19638264],\n",
      "       [ 0.64406016]])]\n",
      "[array(6.234160848431787), array([[ 0.15817691],\n",
      "       [ 0.19405676],\n",
      "       [ 0.2795831 ]]), array([[ 0.01372796,  0.1565657 ],\n",
      "       [-0.07302425,  0.42707281]]), array([[ 0.06057222,  0.26085614],\n",
      "       [-0.03231689,  0.0801639 ],\n",
      "       [-0.16759537, -0.02303606]]), array([[ 0.05423171,  0.07153301, -0.05765532],\n",
      "       [ 0.00528494,  0.1923966 , -0.04028468],\n",
      "       [-0.17478911, -0.18089881,  0.04720526]]), array([[ 0.16142096, -0.06168463, -0.0304605 , -0.14247695],\n",
      "       [-0.13982379,  0.16828223, -0.06986455,  0.13769004],\n",
      "       [-0.06234009, -0.13569939, -0.18171548, -0.05973439]]), array([[ 0.06549288,  0.11193271, -0.15103856, -0.101647  ],\n",
      "       [ 0.12943572, -0.11285003, -0.12190806, -0.08356006],\n",
      "       [ 0.14927382, -0.04503218, -0.06048131, -0.12664837]]), array([[ 0.09879374,  0.12381521,  0.0341211 ,  0.16695382,  0.00330613],\n",
      "       [ 0.02197201,  0.0520403 , -0.19717396, -0.13825159,  0.02263162],\n",
      "       [ 0.16955022,  0.17491642, -0.09062839,  0.20202347,  0.13548093]]), array([[-0.1085891 ,  0.00839348, -0.1797006 ,  0.00375164, -0.15163484],\n",
      "       [ 0.12550263, -0.05338451, -0.10578782, -0.10046064,  0.1906595 ],\n",
      "       [ 0.12585863, -0.08437633,  0.00677768,  0.19877806, -0.12183734]]), array([[-0.17677739, -0.0376452 ,  0.00868275, -0.09059676, -0.10116249,\n",
      "        -0.03113926],\n",
      "       [-0.04525818, -0.00950359, -0.10426231,  0.18860347, -0.03143612,\n",
      "        -0.18937659],\n",
      "       [ 0.13021095,  0.12817004, -0.02790038,  0.1731753 ,  0.00087404,\n",
      "        -0.08273122]]), array([[ 0.1635897 ,  0.13560782, -0.00400935, -0.14971477,  0.02696709,\n",
      "        -0.00122367],\n",
      "       [ 0.10155199,  0.12244543,  0.02082136,  0.01734908,  0.07487588,\n",
      "        -0.15165118],\n",
      "       [ 0.19209112,  0.20339859, -0.18895469,  0.02498743, -0.15291778,\n",
      "        -0.15968743]]), array([[ 0.02400989, -0.08719025, -0.05498552, -0.03445863, -0.00328958,\n",
      "        -0.08495768, -0.09265213],\n",
      "       [-0.19215263, -0.0261894 , -0.21052323, -0.09835735,  0.01356076,\n",
      "         0.15088197, -0.07932021],\n",
      "       [-0.08680345, -0.02781459, -0.05722111, -0.09971863, -0.15349741,\n",
      "        -0.12397511, -0.04242417]]), array([[-0.13141356,  0.06329455, -0.02583858,  0.23210013,  0.0471235 ,\n",
      "        -0.12389227, -0.01791477],\n",
      "       [-0.11003474,  0.06896257, -0.17796564, -0.1586117 , -0.16441454,\n",
      "         0.14356497, -0.13116129],\n",
      "       [ 0.04104108,  0.04847361, -0.05489157,  0.24612423, -0.17242291,\n",
      "         0.0810186 , -0.05406391]]), array([[ 0.56653008],\n",
      "       [ 0.19638264],\n",
      "       [ 0.64406016]])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    output_train = train(registers.eval(), memory_tape.eval(), desired_out.eval())\n",
    "    print(output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(6.234160848431787), array([[ 0.15817691],\n",
       "        [ 0.19405676],\n",
       "        [ 0.2795831 ]]), array([[ 0.01372796,  0.1565657 ],\n",
       "        [-0.07302425,  0.42707281]]), array([[ 0.06057222,  0.26085614],\n",
       "        [-0.03231689,  0.0801639 ],\n",
       "        [-0.16759537, -0.02303606]]), array([[ 0.05423171,  0.07153301, -0.05765532],\n",
       "        [ 0.00528494,  0.1923966 , -0.04028468],\n",
       "        [-0.17478911, -0.18089881,  0.04720526]]), array([[ 0.16142096, -0.06168463, -0.0304605 , -0.14247695],\n",
       "        [-0.13982379,  0.16828223, -0.06986455,  0.13769004],\n",
       "        [-0.06234009, -0.13569939, -0.18171548, -0.05973439]]), array([[ 0.06549288,  0.11193271, -0.15103856, -0.101647  ],\n",
       "        [ 0.12943572, -0.11285003, -0.12190806, -0.08356006],\n",
       "        [ 0.14927382, -0.04503218, -0.06048131, -0.12664837]]), array([[ 0.09879374,  0.12381521,  0.0341211 ,  0.16695382,  0.00330613],\n",
       "        [ 0.02197201,  0.0520403 , -0.19717396, -0.13825159,  0.02263162],\n",
       "        [ 0.16955022,  0.17491642, -0.09062839,  0.20202347,  0.13548093]]), array([[-0.1085891 ,  0.00839348, -0.1797006 ,  0.00375164, -0.15163484],\n",
       "        [ 0.12550263, -0.05338451, -0.10578782, -0.10046064,  0.1906595 ],\n",
       "        [ 0.12585863, -0.08437633,  0.00677768,  0.19877806, -0.12183734]]), array([[-0.17677739, -0.0376452 ,  0.00868275, -0.09059676, -0.10116249,\n",
       "         -0.03113926],\n",
       "        [-0.04525818, -0.00950359, -0.10426231,  0.18860347, -0.03143612,\n",
       "         -0.18937659],\n",
       "        [ 0.13021095,  0.12817004, -0.02790038,  0.1731753 ,  0.00087404,\n",
       "         -0.08273122]]), array([[ 0.1635897 ,  0.13560782, -0.00400935, -0.14971477,  0.02696709,\n",
       "         -0.00122367],\n",
       "        [ 0.10155199,  0.12244543,  0.02082136,  0.01734908,  0.07487588,\n",
       "         -0.15165118],\n",
       "        [ 0.19209112,  0.20339859, -0.18895469,  0.02498743, -0.15291778,\n",
       "         -0.15968743]]), array([[ 0.02400989, -0.08719025, -0.05498552, -0.03445863, -0.00328958,\n",
       "         -0.08495768, -0.09265213],\n",
       "        [-0.19215263, -0.0261894 , -0.21052323, -0.09835735,  0.01356076,\n",
       "          0.15088197, -0.07932021],\n",
       "        [-0.08680345, -0.02781459, -0.05722111, -0.09971863, -0.15349741,\n",
       "         -0.12397511, -0.04242417]]), array([[-0.13141356,  0.06329455, -0.02583858,  0.23210013,  0.0471235 ,\n",
       "         -0.12389227, -0.01791477],\n",
       "        [-0.11003474,  0.06896257, -0.17796564, -0.1586117 , -0.16441454,\n",
       "          0.14356497, -0.13116129],\n",
       "        [ 0.04104108,  0.04847361, -0.05489157,  0.24612423, -0.17242291,\n",
       "          0.0810186 , -0.05406391]]), array([[ 0.56653008],\n",
       "        [ 0.19638264],\n",
       "        [ 0.64406016]])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This code is borrowed from http://andrew.gibiansky.com/ based on ADAM optimization technique proposed in the paper\n",
    "def adam_optimize(params, train, train_inputs, mem, train_outputs, output_len,\n",
    "                  alpha=0.001, b1=0.9, b2=0.999,\n",
    "                  epsilon=1e-8, batch_size=3):\n",
    "    \"\"\"Implementation of Adam optimization method, with hyperparameters\n",
    "    taken as recommended by the original publication.\"\"\"\n",
    "    # Initialize first and second moment estimates to zero.\n",
    "    # This causes some bias, which is addressed later.\n",
    "    moment1 =  [0 for _ in params]\n",
    "    moment2 = [0 for _ in params]\n",
    "    \n",
    "    timestep = 0  # Current optimization step\n",
    "    batch = 0     # Where does this batch start\n",
    "    \n",
    "    converged = False\n",
    "    gradients = []\n",
    "    while not converged:\n",
    "        timestep += 1\n",
    "        \n",
    "        # Train on a small batch.\n",
    "        #inputs = train_inputs   \n",
    "        inputs  = train_inputs[batch:batch+batch_size, :, :]\n",
    "        #outputs = train_outputs \n",
    "        outputs = train_outputs[batch:batch+batch_size, :]   \n",
    "        #print(\"training now\")\n",
    "        result = train(inputs, mem, outputs)\n",
    "        cost = result[0]\n",
    "        gradients = result[1:]\n",
    "        #print(\"gradients now\", gradients)\n",
    "        \n",
    "        # Advance to next batch.\n",
    "        batch = (batch + batch_size) % train_inputs.shape[0]\n",
    "\n",
    "        # Compute first and second moment estimates.\n",
    "        # These are decaying moving averages; first moment\n",
    "        # uses the gradient, second uses squared gradient.\n",
    "        moment1  = [b1 * m + (1 - b1) * gradient\n",
    "                    for (m, gradient)\n",
    "                    in zip(moment1, gradients)]\n",
    "        moment2 = [b2 * v + (1 - b2) * gradient ** 2\n",
    "                   for (v, gradient)\n",
    "                   in zip(moment2, gradients)]\n",
    "        \n",
    "        # Correct for initialization bias and compute new values.\n",
    "        correction1 = 1. / (1 - b1 ** timestep)\n",
    "        correction2 = 1. / (1 - b2 ** timestep)\n",
    "        corrected1 = [correction1 * m for m in moment1]\n",
    "        corrected2 = [correction2 * v for v in moment2]\n",
    "        \n",
    "        # Compute new parameter values.\n",
    "        params_new = [p.get_value() - alpha * m1 / (np.sqrt(m2) + epsilon)\n",
    "                      for (p, m1, m2) in zip(params, corrected1, corrected2)]\n",
    "\n",
    "        # Check for convergence by looking at magnitude of delta.\n",
    "        delta = [abs(p.get_value() - p_new)\n",
    "                 for (p, p_new) in zip(params, params_new)]\n",
    "        converged = all((d < 0.5 * alpha).all() for d in delta)        \n",
    "        \n",
    "        # Update parameters to new values.\n",
    "        for p, p_new in zip(params, params_new):\n",
    "            p.set_value(p_new.astype('float32'))\n",
    "            \n",
    "        # Provide some output for tracking during runtime.\n",
    "        if timestep % 100 == 1 or converged:\n",
    "            print(\"Cost (t = %4d): \\t%.2f\" % (timestep - 1, cost))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#registers = get_registers(2)\n",
    "#memory_tape = create_memory_tape()\n",
    "#desired_out = create_memory_tape(0)\n",
    "#for i in range(M):\n",
    "#     desired_out = write_external(get_const(i), get_const(i), desired_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit()\n",
    "sys.setrecursionlimit(40000)\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task based Input Output Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (t =    0): \t3.51\n",
      "Cost (t =  100): \t1.89\n",
      "Cost (t =  200): \t0.25\n",
      "Cost (t =  300): \t2.47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-493c25575a4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-80fde849b672>\u001b[0m in \u001b[0;36madam_optimize\u001b[0;34m(params, train, train_inputs, mem, train_outputs, output_len, alpha, b1, b2, epsilon, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(\"training now\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_with_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# print a simple traceback from KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 for thunk, node, old_storage in zip(self.thunks, self.nodes,\n\u001b[1;32m    292\u001b[0m                                                     self.post_thunk_clear):\n\u001b[0;32m--> 293\u001b[0;31m                     \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mold_s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_storage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mnout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mufunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mufunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mimpl\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m   3674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3675\u001b[0m         \u001b[0moutput_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3676\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3677\u001b[0m         ret = utils.to_return_values([storage[0] for storage in\n\u001b[1;32m   3678\u001b[0m                                       output_storage])\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[1;32m   3670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3671\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3672\u001b[0;31m             \u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   3544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3546\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproducers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3547\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompose_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mimpl\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0mnfunc_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'add'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = adam_optimize(w, train, registers.eval(), memory_tape.eval(), desired_out.eval(),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('registers = ', array([[1, 1]]))\n",
      "('memory tape:  ', array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))\n",
      "('desired tape: ', array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[1, 1, 0]]), 'gate output: ', 0)\n",
      "('concatenated inputs: ', array([[1, 1, 0]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[1, 1, 0, 2]]), 'gate output: ', 2)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2]]))\n",
      "('gate i = ', 2, 'arity:', 2, 'gate inputs: ', array([[1, 1, 0, 2, 1]]), 'gate output: ', 1)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2, 1]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[1, 1, 0, 2, 1, 1]]), 'gate output: ', 1)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2, 1, 1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[1, 1, 0, 2, 1, 1, 1]]), 'gate output: ', 1)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2, 1, 1, 1]]))\n",
      "('register [', 0, ']  new value: reg_coef', 6, 'weighted_avg of gate inputs and reg_coef: ', 1)\n",
      "('register [', 1, ']  new value: reg_coef', 1, 'weighted_avg of gate inputs and reg_coef: ', 1)\n",
      "('Desired value at mem location [', 0, '] is ', 0, 'but actual value is [', 0, 'loss is ', array([-0.37484262]), ' cost = ', array([[-0.37484262]]))\n",
      "('cost = ', array([[[ 0.20449926]]]))\n",
      "('prob_incomplete = ', array([[[ 0.45443969]]]))\n",
      "('registers = ', array([[1, 1]]))\n",
      "('memory tape:  ', array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))\n",
      "('desired tape: ', array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[1, 1, 0]]), 'gate output: ', 0)\n",
      "('concatenated inputs: ', array([[1, 1, 0]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[1, 1, 0, 2]]), 'gate output: ', 2)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2]]))\n",
      "('gate i = ', 2, 'arity:', 2, 'gate inputs: ', array([[1, 1, 0, 2, 1]]), 'gate output: ', 1)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2, 1]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[1, 1, 0, 2, 1, 1]]), 'gate output: ', 1)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2, 1, 1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[1, 1, 0, 2, 1, 1, 1]]), 'gate output: ', 1)\n",
      "('concatenated inputs: ', array([[1, 1, 0, 2, 1, 1, 1]]))\n",
      "('register [', 0, ']  new value: reg_coef', 6, 'weighted_avg of gate inputs and reg_coef: ', 1)\n",
      "('register [', 1, ']  new value: reg_coef', 1, 'weighted_avg of gate inputs and reg_coef: ', 1)\n",
      "('Desired value at mem location [', 0, '] is ', 0, 'but actual value is [', 0, 'loss is ', array([-0.63053421]), ' cost = ', array([[-0.63053421]]))\n",
      "('cost = ', array([[[ 0.34381234]]]))\n",
      "('prob_incomplete = ', array([[[ 0.20664667]]]))\n",
      "('registers = ', array([[1, 1]]))"
     ]
    }
   ],
   "source": [
    "v0 = as_tensor(0)\n",
    "v1 = as_tensor(1)\n",
    "output = [registers, memory_tape, v0, v0, v1]\n",
    "new_registers = []\n",
    "for timestep in range(10):\n",
    "    #print(\"compute_all_timesteps t = \", timestep)\n",
    "    \n",
    "    print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "    print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "    print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "    \n",
    "    output = machine_compute_step_t(True, R, layers, w, gates, timestep+1, desired_out, 1, *(output))\n",
    "    registers, memory_tape, cost_t, cum_prob_t, prob_incomplete = output\n",
    "    \n",
    "    print(\"cost = \", output[2].eval())\n",
    "    print(\"prob_incomplete = \", prob_incomplete.eval())\n",
    "    \n",
    "\n",
    "    \n",
    "    #new_registers.append(output[0])\n",
    "    #registers=new_registers\n",
    "    #memory_tape=new_memory_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": "6",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
