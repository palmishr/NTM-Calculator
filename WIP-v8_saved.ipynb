{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "READ (described in Sec. 3.2),\n",
    "WRITE (described in Sec. 3.2).\n",
    "\n",
    "ZERO(a, b) = 0, \n",
    "ONE(a, b) = 1, \n",
    "TWO(a, b) = 2, \n",
    "\n",
    "INC(a, b) = (a+1) mod M, \n",
    "ADD(a, b) = (a+b) mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "from theano import tensor\n",
    "from collections import namedtuple\n",
    "from theano.tensor.extra_ops import to_one_hot\n",
    "from theano.tensor import roll\n",
    "from theano.tensor import stack\n",
    "from theano.tensor import batched_dot\n",
    "from theano.tensor import concatenate\n",
    "from theano.tensor import as_tensor\n",
    "from theano.tensor import set_subtensor\n",
    "from theano import shared\n",
    "from numpy.random import uniform\n",
    "from theano.tensor.nnet import softmax, relu, sigmoid\n",
    "from theano import function, config, shared, sandbox, Out\n",
    "\n",
    "def zero() :\n",
    "    return to_one_hot(np.asarray([0]),M)\n",
    "def one() :\n",
    "    return to_one_hot(np.asarray([1]),M)\n",
    "def two() :\n",
    "    return to_one_hot(np.asarray([2]),M)\n",
    "def get_const(value) :\n",
    "    return to_one_hot(np.asarray([value % M]),M)\n",
    "def create_memory_tape(init_val=0):\n",
    "    m = stack([get_const(init_val) for i in range(M)], axis=1)\n",
    "    #return shared(np.asarray(m.eval()), config.floatX) \n",
    "    return m\n",
    "def inc(a) :\n",
    "    return roll(a, 1, axis=1)\n",
    "def negate(a) :\n",
    "    return roll(a[:, ::-1], 1, axis=1)\n",
    "def add(a,b) :\n",
    "    rows = [roll(b[:,], j, axis=1) for j in range(M)]\n",
    "    return (batched_dot(a, stack(rows, axis=1)))\n",
    "def sub(a,b) :\n",
    "    b_negative = negate(b)\n",
    "    return add(a, b_negative)\n",
    "def eq_zero(a) :\n",
    "    r = tensor.zeros_like(as_tensor(a))\n",
    "    r = set_subtensor(r[:,1], a[:, 0])\n",
    "    r = set_subtensor(r[:, 0], 1 - a[:, 0])\n",
    "    return r\n",
    "def lt(a,b):\n",
    "    return tensor.lt(as_tensor(a),as_tensor(b))\n",
    "def lte(a,b):\n",
    "    return tensor.le(as_tensor(a),as_tensor(b))\n",
    "def eq(a,b):\n",
    "    return tensor.eq(as_tensor(a),as_tensor(b))\n",
    "def min(a,b):\n",
    "    if(lte(a,b)):\n",
    "        return as_tensor(a)\n",
    "    else:\n",
    "        return as_tensor(b)\n",
    "def max(a,b):\n",
    "    if(lt(a,b)):\n",
    "        return as_tensor(b)\n",
    "    else:\n",
    "        return as_tensor(a)    \n",
    "def read(mem, a) :\n",
    "    ptr = as_tensor(a)\n",
    "    return weighted_avg(mem, ptr), mem\n",
    "def write(mem, a, b) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    mem = (x + y)\n",
    "    #print(\"write gate: memory updated\", mem.type)\n",
    "    return val, mem\n",
    "def write_external(a, b, ext_mem) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, ext_mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    ext_mem = (x + y)\n",
    "    return ext_mem\n",
    "\n",
    "def get_registers(init_val):\n",
    "    return stack([get_const(init_val) for i in range(R)], axis=1)\n",
    "\n",
    "def weighted_avg(inputs, coefficient) :\n",
    "    return batched_dot(inputs.transpose(0, 2, 1), coefficient.dimshuffle(0, 1, 'x')).flatten(2);\n",
    "\n",
    "def compute_gate_new(module, inputs, coefficients, memory_tape, debug=False) :\n",
    "    \"\"\" Arity of this gate must be equal to the number of given\n",
    "        coefficients list\n",
    "    \"\"\" \n",
    "    if (len(coefficients) != module.arity) :\n",
    "        print(\"Error: Incorrect number of coefficients: \",  len(coefficients), \" to module arity: \", module.arity)\n",
    "    \n",
    "    params = [weighted_avg(inputs, as_tensor(coef)) for coef in coefficients]\n",
    "    \n",
    "    if (debug == True):\n",
    "        for i, p in enumerate(params):\n",
    "            print(\"compute_gate_new: weighted param [\", i ,\"] = \", p.eval())\n",
    "    \n",
    "    if (module.memory_function == True) :\n",
    "        #print(\"read/write now!\")\n",
    "        output, memory_tape = module.function(memory_tape, *params)\n",
    "    else :   \n",
    "        output = module.function(*params)\n",
    "    \n",
    "    if (debug == True):\n",
    "        print(\"output from module: \", output.eval())\n",
    "    \n",
    "    #error check for constant gates\n",
    "    return output, memory_tape\n",
    "\n",
    "\n",
    "def get_n_tensor(t, count, idx):\n",
    "    result=[]\n",
    "    if count > 0: \n",
    "        result = [t[idx+i] for i in range(count)]\n",
    "    return result, (idx+count)\n",
    "\n",
    "def fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug=False):\n",
    "    # Initially, only the registers may be used as inputs.\n",
    "    Q= len(gates)\n",
    "    gate_inputs = registers\n",
    "    idx=0    \n",
    "    \n",
    "    # Run through all the gates.\n",
    "    for i in range(Q):\n",
    "        c, idx = get_n_tensor(gate_coef, gates[i].arity, idx) \n",
    "        output, memory_tape = compute_gate_new(gates[i], gate_inputs, c, memory_tape)\n",
    "        # Append the output of the gate as an input for future gates.\n",
    "        gate_inputs = concatenate([gate_inputs, output.dimshuffle(0,'x',1)], axis=1)\n",
    "        if (debug==True):\n",
    "            print(\"gate i = \", i, \"R :\", R, \"arity:\", gates[i].arity, \"my gate output: \", output.eval(), \"my gate inputs: \", gate_inputs.eval())    \n",
    "            print(\"Concatenated inputs: \", gate_inputs.eval())       \n",
    "        \n",
    "    # All leftover coefficients are for registers.\n",
    "    new_registers = []\n",
    "             \n",
    "    for i in range(len(reg_coef)):\n",
    "        # (R+Q) x M dot 1 X (R+Q) \n",
    "        new_registers.append(weighted_avg(gate_inputs, reg_coef[i]))\n",
    "        if (debug == True) :\n",
    "            print(\"new register: weighted_avg argmax of gate inputs and reg coef: \", weighted_avg(gate_inputs, reg_coef[i]).eval().argmax(), \"reg_coef argmax\", reg_coef[i].eval().argmax())\n",
    "    return tensor.stack(new_registers, axis=1), memory_tape\n",
    "\n",
    "\n",
    "# coefficients = [r1,r2..rR,g1_param1,g1_param2,...,gQ_param1,gQ_param2,c1,c1..CR,cR+1,..cR+Q]\n",
    "def gen_random_weights(layer1, layer2, dtype=np.float64, _min=-1, _max=1):\n",
    "    weights = uniform(low=_min, high=_max, size=(layer1, layer2))\n",
    "    var = shared(weights.astype(dtype), name=\"w{0}x{1}\".format(layer1, layer2))   \n",
    "    #var = tensor.addbroadcast(var, 0)\n",
    "    return var\n",
    "\n",
    "def gen_network_weights(gates, layers):\n",
    "    n_registers = R #input is R registers\n",
    "    w = []\n",
    "    current_layer_units = n_registers\n",
    "    \n",
    "    for next_layer_units in layers:\n",
    "        w.append(gen_random_weights(current_layer_units + 1, next_layer_units))\n",
    "        current_layer_units = next_layer_units\n",
    "    \n",
    "    #output wt for gate coefficients\n",
    "    gate_coef = []\n",
    "    for i, gate in enumerate(gates):\n",
    "        print(i, gate)\n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            gate_coef.append(gen_random_weights(current_layer_units + 1, gate_output_units))            \n",
    "    \n",
    "    #print(\"gen_network_weights => gate_coef\", gate_coef)         \n",
    "    \n",
    "    #output wt for new registers\n",
    "    reg_coef = []\n",
    "    reg_output_units = n_registers + len(gates)\n",
    "    for _ in range(n_registers):\n",
    "        reg_coef.append(gen_random_weights(current_layer_units + 1, n_registers + len(gates)))    \n",
    "    \n",
    "    #print(\"gen_network_weights => reg_coef\", reg_coef)      \n",
    "     \n",
    "    prob_completion_coef = (gen_random_weights(current_layer_units + 1, 1))\n",
    "\n",
    "    for i in gate_coef:\n",
    "        w.append(i)\n",
    "\n",
    "    for x in reg_coef:\n",
    "        w.append(x)\n",
    "    \n",
    "    w.append(prob_completion_coef)   \n",
    "    return w\n",
    "\n",
    "def aug_ones_col(inputs):\n",
    "    print(\"OMFG\")\n",
    "    s = inputs.shape\n",
    "    col_elems = s[1]\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), col_elems))\n",
    "    x = concatenate([inputs.T,ones], axis=1)\n",
    "    return x.T\n",
    "\n",
    "def aug_ones_col_new(inputs):\n",
    "    x=[]\n",
    "    s = inputs.shape\n",
    "    #print(s.eval())\n",
    "    d = inputs.ndim\n",
    "    row_elems = s[d-2]\n",
    "    #print(\"aug one col, dimension of inputs = \", d)\n",
    "    matrix = tensor.reshape(inputs, (s[d-2],s[d-1]))\n",
    "    #print(matrix.eval())\n",
    "    matrix = tensor.shape_padleft(matrix)\n",
    "    #print(matrix.eval())\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), row_elems))\n",
    "    #print(ones.eval())\n",
    "    #print(\"shuffled ones: \", ones.dimshuffle(0,'x',1).eval())\n",
    "    #print(\"shuffled matrix: \",matrix.dimshuffle(0,2,1).eval())\n",
    "    x = concatenate([matrix.dimshuffle(0,2,1),ones.dimshuffle(0,'x',1)], axis=1)\n",
    "    return x.dimshuffle(0,2,1)\n",
    "\n",
    "def controller_forward_prop(n_registers, layers, weight_matrix, gates, registers) :\n",
    "    inputs = registers[:,:,0]\n",
    "    inputs = aug_ones_col_new(inputs)\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        W = weight_matrix[i]\n",
    "        inputs = aug_ones_col_new(relu(inputs.dot(W)))  \n",
    "    \n",
    "    #extract gate coefficients\n",
    "    gate_coef = []\n",
    "    n_gate_coef = 0\n",
    "    for i, gate in enumerate(gates): \n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            n_gate_coef += 1 \n",
    "            \n",
    "    for W in weight_matrix[len(layers):len(layers) + n_gate_coef]:\n",
    "        gate_coef.append(softmax(inputs.dot(W)[0]))            \n",
    "\n",
    "    reg_coef = []\n",
    "    \n",
    "    for W in (weight_matrix[len(layers)+n_gate_coef:len(layers)+n_gate_coef+n_registers]):\n",
    "        reg_coef.append(softmax(inputs.dot(W)[0])) \n",
    "        \n",
    "    p = sigmoid(inputs.dot(weight_matrix[-1]))\n",
    "    \n",
    "    return p, reg_coef, gate_coef\n",
    "\n",
    "def calculate_cost_at_t(prob_complete_t, t, cum_cost, cum_prob_t, p_incomplete, memory_in, desired_output, output_len, debug) :\n",
    "    e = 1e-100\n",
    "    cost_t = 0\n",
    "    #TODO: Find use for desired registers in calculating cost. Now, only desired memory layout is matched.\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        #Compute the loss for this register using the mask.\n",
    "        mask = to_one_hot(desired_output.argmax(axis=2)[:,i], M)        \n",
    "        a = tensor.log(memory_in[:, i, :] + e)\n",
    "        x = mask * a\n",
    "        loss = (x).sum(axis=1)\n",
    "        cost_t += tensor.shape_padright(loss, 1)\n",
    "    if (debug == True):\n",
    "        print(\"Desired value at mem location [\", i, \"] is \", mask.eval().argmax(), \"but actual value is [\", memory_in[:,i,:].eval().argmax(), \"loss is \", loss.eval(), \" cost = \", cost_t.eval()) \n",
    "\n",
    "    if (t >= MAX_TIMESTEP):\n",
    "        prob_complete = 1 - cum_prob_t\n",
    "    else:\n",
    "        prob_complete = prob_complete_t * p_incomplete\n",
    "    \n",
    "    p_incomplete *= (1 - prob_complete_t)   \n",
    "    cum_prob_t += prob_complete\n",
    "        \n",
    "    cum_cost = -(cost_t*prob_complete_t)\n",
    "    #print (\"cost at t\", cost_t)\n",
    "    #print (\"p of completion at t\", prob_complete)\n",
    "    \n",
    "    return cum_cost, cum_prob_t, p_incomplete\n",
    "\n",
    "def machine_compute_step_t(debug, R, layers, w, gates, t, desired_output, output_len, registers, memory_tape, cost_t, cum_prob, prob_incomplete) : \n",
    "    \n",
    "    p, reg_coef, gate_coef = controller_forward_prop(R, layers, w, gates, registers)\n",
    "    \n",
    "    new_registers, new_memory_tape = fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug)\n",
    "    \n",
    "    cost_t, cum_prob_t, prob_incomplete = calculate_cost_at_t(p, t, cost_t, cum_prob, prob_incomplete, new_memory_tape, desired_output, output_len, debug)\n",
    "    \n",
    "    return new_registers, new_memory_tape, cost_t, cum_prob_t, prob_incomplete\n",
    "\n",
    "def compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len):\n",
    "    #w = make_broadcastable(w)\n",
    "    # Create symbolic variables for the input to the machine\n",
    "    # and for the desired output of the machine.\n",
    "      \n",
    "    #initial_registers = registers\n",
    "    #desired_output = memory_tape\n",
    "\n",
    "    initial_registers = tensor.dtensor3(\"Registers\")\n",
    "    initial_memory = tensor.dtensor3(\"Memory_Tape\")\n",
    "    desired_output = tensor.dtensor3(\"Y\")\n",
    "     \n",
    "    \n",
    "    # Run the model for all timesteps. The arguments are \n",
    "    # registers, cost, cumulative probability complete, \n",
    "    # and probability incomplete. The latter are initialized\n",
    "    # to zero and to one, respectively.\n",
    "    \n",
    "    v0 = as_tensor(0)\n",
    "    v1 = as_tensor(1)\n",
    "    output = [initial_registers, initial_memory, v0, v0, v1]\n",
    "    intermediate_registers = []\n",
    "    for timestep in range(MAX_TIMESTEP):\n",
    "        print(\"compute_all_timesteps t = \", timestep)\n",
    "        output = machine_compute_step_t(False, R, layers, w, gates, timestep+1, desired_output, output_len, *(output))\n",
    "        intermediate_registers.append(output[0])\n",
    "        \n",
    "        #registers=new_registers\n",
    "\n",
    "    # Add in regularization, to avoid overfitting simple examples.\n",
    "    reg_cost = reg_lambda * sum((p * p).sum() for p in list(w))\n",
    "    \n",
    "    # Get the final cost: regularization plus loss.\n",
    "    final_cost = reg_cost + output[2].sum()\n",
    "    \n",
    "    # Return the symbolic variables, the final cost, and the\n",
    "    # intermediate register values for analysis and prediction.\n",
    "    return initial_registers, initial_memory, desired_output, final_cost, intermediate_registers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Module(arity=1, function=<function read at 0x106b86230>, memory_function=True))\n",
      "(1, Module(arity=1, function=<function inc at 0x106b82cf8>, memory_function=False))\n",
      "(2, Module(arity=2, function=<function lt at 0x106b82f50>, memory_function=False))\n",
      "(3, Module(arity=2, function=<function min at 0x106b86140>, memory_function=False))\n",
      "(4, Module(arity=2, function=<function write at 0x106b862a8>, memory_function=True))\n",
      "('weight matrix: ', [w3x1, w2x2, w3x2, w3x3, w3x4, w3x4, w3x5, w3x5, w3x6, w3x6, w3x7, w3x7, w3x1])\n"
     ]
    }
   ],
   "source": [
    "#Maximum Representable Integer M is set below\n",
    "M = 16\n",
    "# Number of registers\n",
    "R = 2\n",
    "#Max number of timesteps\n",
    "MAX_TIMESTEP = 5\n",
    "\n",
    "Module = namedtuple(\"Module\", \"arity function memory_function\")\n",
    "\n",
    "m_zero = Module(0, zero, False)\n",
    "m_one = Module(0, one, False)\n",
    "m_two = Module(0, two, False)\n",
    "m_inc = Module(1, inc, False)\n",
    "m_negate = Module(1, negate, False)\n",
    "m_add = Module(2, add, False)\n",
    "m_sub = Module(2, sub, False)\n",
    "m_eq_zero = Module(1, eq_zero, False)\n",
    "m_read = Module(1, read, True)\n",
    "m_write = Module(2, write, True)\n",
    "m_lt = Module(2, lt, False)\n",
    "m_lte = Module(2, lte, False)\n",
    "m_eq = Module(2, eq, False)\n",
    "m_min = Module(2, min, False)\n",
    "m_max = Module(2, max, False)\n",
    "\n",
    "gates = [m_read, m_inc, m_lt, m_min, m_write]\n",
    "N = len(gates)\n",
    "\n",
    "registers = get_registers(1)\n",
    "memory_tape = create_memory_tape()\n",
    "desired_out = create_memory_tape(0)\n",
    "for i in range(M):\n",
    "     desired_out = write_external(get_const(i), get_const(i), desired_out)\n",
    "        \n",
    "layers = [1,2]\n",
    "w = gen_network_weights(gates, layers)\n",
    "print(\"weight matrix: \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('compute_all_timesteps t = ', 0)\n",
      "('compute_all_timesteps t = ', 1)\n",
      "('compute_all_timesteps t = ', 2)\n",
      "('compute_all_timesteps t = ', 3)\n",
      "('compute_all_timesteps t = ', 4)\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "output_len = M\n",
    "result  = compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len)\n",
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Registers,\n",
       " Memory_Tape,\n",
       " Y,\n",
       " Elemwise{add,no_inplace}.0,\n",
       " [Join.0, Join.0, Join.0, Join.0, Join.0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradients = theano.grad(final_cost, list(w)) #, disconnected_inputs='warn', return_disconnected='Disconnected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n",
      "TensorType(float64, 3D)\n"
     ]
    }
   ],
   "source": [
    "for r in intermediate_registers:\n",
    "    print (r.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile training function to compute gradients.\n",
    "train = theano.function([initial_registers, initial_memory, desired_output], [final_cost] + gradients) #, on_unused_input='ignore', allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile prediction function (registers after one timestep)\n",
    "predict = theano.function([initial_registers, initial_memory], intermediate_registers[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    output_train = train(registers.eval(), memory_tape.eval(), desired_out.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(1377.1944222635361), array([[ 0.01534355],\n",
       "        [-0.05771496],\n",
       "        [-0.1562771 ]]), array([[  1.10450928e-01,   1.36550612e-02],\n",
       "        [  8.40694793e+01,  -1.86932764e-01]]), array([[-0.10239065, -0.02650435],\n",
       "        [ 0.03336372, -0.10320154],\n",
       "        [-0.02110737, -0.12504492]]), array([[-0.15608317, -0.03163312,  0.08399274],\n",
       "        [ 0.09873842, -0.15461   ,  0.02544683],\n",
       "        [ 0.07044295,  0.19657399, -0.04488378]]), array([[-0.15053301, -0.08745199,  0.17696243,  0.08211676],\n",
       "        [-0.12523196,  0.06675526,  0.13385073, -0.05702877],\n",
       "        [ 0.0391238 ,  0.08993994,  0.0035428 ,  0.00150313]]), array([[ 0.12012156,  0.11169121,  0.10317543,  0.17816953],\n",
       "        [ 0.03958255,  0.08383777, -0.19307736, -0.11006563],\n",
       "        [-0.0965774 , -0.06584564,  0.13872239,  0.04755252]]), array([[ 0.32460716, -0.05250864,  0.32285572,  0.02358304, -0.57819645],\n",
       "        [-0.14311541,  0.13878391,  0.12230059, -0.1808767 ,  0.14280589],\n",
       "        [ 0.74124373, -0.06806565,  0.24601226, -0.01117556, -1.01792735]]), array([[ 0.03795289, -0.04216725, -0.08170991, -0.19509423, -0.04949354],\n",
       "        [-0.04146496, -0.02145908,  0.17531945,  0.10108114,  0.18962187],\n",
       "        [ 0.0121682 ,  0.17487449,  0.03665768,  0.19813529, -0.0446606 ]]), array([[ 0.21399947, -0.02494758,  0.26000185, -0.02187188, -0.63755929,\n",
       "          0.48104102],\n",
       "        [-0.15027504, -0.18038479,  0.10384146, -0.12577114,  0.05008527,\n",
       "         -0.15441326],\n",
       "        [ 0.00117727,  0.08661241,  0.07136736,  0.10829011, -1.16456303,\n",
       "          0.72405507]]), array([[ 0.27055912,  0.41853166,  0.23718055,  0.06969536, -1.26427449,\n",
       "          0.01699009],\n",
       "        [ 0.06458696, -0.16797218, -0.19311732,  0.03079223,  0.01940862,\n",
       "          0.08565199],\n",
       "        [ 0.48847969,  0.9607687 ,  0.76799109,  0.25541083, -2.37125985,\n",
       "         -0.05611666]]), array([[ 0.07907832,  0.19027739, -0.17955843,  0.06104131, -0.31791341,\n",
       "         -0.0489882 ,  0.06425331],\n",
       "        [-0.07085587,  0.07929159,  0.04805467, -0.16042384,  0.10211375,\n",
       "         -0.05643715,  0.18985809],\n",
       "        [ 0.18539854,  0.29583791, -0.17037565, -0.16137297, -0.37320674,\n",
       "          0.14530441,  0.05077519]]), array([[ 0.06198774,  0.24916535,  0.47882121,  0.08390018, -0.55447185,\n",
       "          0.16118844, -0.14622389],\n",
       "        [ 0.07122791,  0.0254085 ,  0.15147898, -0.06467064,  0.07891732,\n",
       "         -0.19715279,  0.13595666],\n",
       "        [-0.06074187, -0.04390032,  0.55481038,  0.41905962, -1.22548628,\n",
       "          0.32493329, -0.03681365]]), array([[  2.96772258e+02],\n",
       "        [ -1.78629009e-01],\n",
       "        [  4.68772735e+02]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This code is borrowed from http://andrew.gibiansky.com/ based on ADAM optimization technique proposed in the paper\n",
    "def adam_optimize(params, train, train_inputs, mem, train_outputs, output_len,\n",
    "                  alpha=0.001, b1=0.9, b2=0.999,\n",
    "                  epsilon=1e-8, batch_size=3):\n",
    "    \"\"\"Implementation of Adam optimization method, with hyperparameters\n",
    "    taken as recommended by the original publication.\"\"\"\n",
    "    # Initialize first and second moment estimates to zero.\n",
    "    # This causes some bias, which is addressed later.\n",
    "    moment1 =  [0 for _ in params]\n",
    "    moment2 = [0 for _ in params]\n",
    "    \n",
    "    timestep = 0  # Current optimization step\n",
    "    batch = 0     # Where does this batch start\n",
    "    \n",
    "    converged = False\n",
    "    gradients = []\n",
    "    while not converged:\n",
    "        timestep += 1\n",
    "        \n",
    "        # Train on a small batch.\n",
    "        #inputs = train_inputs   \n",
    "        inputs  = train_inputs[batch:batch+batch_size, :, :]\n",
    "        #outputs = train_outputs \n",
    "        outputs = train_outputs[batch:batch+batch_size, :]   \n",
    "        #print(\"training now\")\n",
    "        result = train(inputs, mem, outputs)\n",
    "        cost = result[0]\n",
    "        gradients = result[1:]\n",
    "        #print(\"gradients now\", gradients)\n",
    "        \n",
    "        # Advance to next batch.\n",
    "        batch = (batch + batch_size) % train_inputs.shape[0]\n",
    "\n",
    "        # Compute first and second moment estimates.\n",
    "        # These are decaying moving averages; first moment\n",
    "        # uses the gradient, second uses squared gradient.\n",
    "        moment1  = [b1 * m + (1 - b1) * gradient\n",
    "                    for (m, gradient)\n",
    "                    in zip(moment1, gradients)]\n",
    "        moment2 = [b2 * v + (1 - b2) * gradient ** 2\n",
    "                   for (v, gradient)\n",
    "                   in zip(moment2, gradients)]\n",
    "        \n",
    "        # Correct for initialization bias and compute new values.\n",
    "        correction1 = 1. / (1 - b1 ** timestep)\n",
    "        correction2 = 1. / (1 - b2 ** timestep)\n",
    "        corrected1 = [correction1 * m for m in moment1]\n",
    "        corrected2 = [correction2 * v for v in moment2]\n",
    "        \n",
    "        # Compute new parameter values.\n",
    "        params_new = [p.get_value() - alpha * m1 / (np.sqrt(m2) + epsilon)\n",
    "                      for (p, m1, m2) in zip(params, corrected1, corrected2)]\n",
    "\n",
    "        # Check for convergence by looking at magnitude of delta.\n",
    "        delta = [abs(p.get_value() - p_new)\n",
    "                 for (p, p_new) in zip(params, params_new)]\n",
    "        converged = all((d < 0.5 * alpha).all() for d in delta)        \n",
    "        \n",
    "        # Update parameters to new values.\n",
    "        for p, p_new in zip(params, params_new):\n",
    "            p.set_value(p_new.astype('float32'))\n",
    "            \n",
    "        # Provide some output for tracking during runtime.\n",
    "        if timestep % 100 == 1 or converged:\n",
    "            print(\"Cost (t = %4d): \\t%.2f\" % (timestep - 1, cost))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#registers = get_registers(2)\n",
    "#memory_tape = create_memory_tape()\n",
    "#desired_out = create_memory_tape(0)\n",
    "#for i in range(M):\n",
    "#     desired_out = write_external(get_const(i), get_const(i), desired_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit()\n",
    "sys.setrecursionlimit(40000)\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task based Input Output Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Access Task\n",
    "input = [ 3,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "output = [ 4,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('desired_out.eval()', array([[ 4,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('memory_tape.eval()', array([[ 3,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('registers.eval()', array([[1, 1]]))\n"
     ]
    }
   ],
   "source": [
    "print (\"desired_out.eval()\", desired_out.eval().argmax(axis=2))\n",
    "print (\"memory_tape.eval()\", memory_tape.eval().argmax(axis=2))\n",
    "print (\"registers.eval()\", registers.eval().argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (t =    0): \t12.64\n",
      "Cost (t =  100): \t10.68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bbe503298621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-80fde849b672>\u001b[0m in \u001b[0;36madam_optimize\u001b[0;34m(params, train, train_inputs, mem, train_outputs, output_len, alpha, b1, b2, epsilon, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print(\"training now\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_with_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# print a simple traceback from KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 for thunk, node, old_storage in zip(self.thunks, self.nodes,\n\u001b[1;32m    292\u001b[0m                                                     self.post_thunk_clear):\n\u001b[0;32m--> 293\u001b[0;31m                     \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mold_s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_storage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/elemwise.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mnout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mufunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mufunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mimpl\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m   3674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3675\u001b[0m         \u001b[0moutput_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3676\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3677\u001b[0m         ret = utils.to_return_values([storage[0] for storage in\n\u001b[1;32m   3678\u001b[0m                                       output_storage])\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[1;32m   3669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3671\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3672\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = adam_optimize(w, train, registers.eval(), memory_tape.eval(), desired_out.eval(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gate i = ', 0, 'R :', 2, 'arity:', 1, 'my gate output: ', array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.]]), 'my gate inputs: ', array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('Concatenated inputs: ', array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('gate i = ', 1, 'R :', 2, 'arity:', 1, 'my gate output: ', array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.]]), 'my gate inputs: ', array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('Concatenated inputs: ', array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('gate i = ', 2, 'R :', 2, 'arity:', 2, 'my gate output: ', array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8), 'my gate inputs: ', array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('Concatenated inputs: ', array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('gate i = ', 3, 'R :', 2, 'arity:', 2, 'my gate output: ', array([[ 0.        ,  0.78339791,  0.21660209,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ]]), 'my gate inputs: ', array([[[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.78339791,  0.21660209,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ]]]))\n",
      "('Concatenated inputs: ', array([[[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.78339791,  0.21660209,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ]]]))\n",
      "('gate i = ', 4, 'R :', 2, 'arity:', 2, 'my gate output: ', array([[ 0.        ,  0.69095859,  0.30904141,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ]]), 'my gate inputs: ', array([[[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.78339791,  0.21660209,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.69095859,  0.30904141,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ]]]))\n",
      "('Concatenated inputs: ', array([[[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.78339791,  0.21660209,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ],\n",
      "        [ 0.        ,  0.69095859,  0.30904141,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "          0.        ]]]))\n",
      "('new register: weighted_avg argmax of gate inputs and reg coef: ', 1, 'reg_coef argmax', 6)\n",
      "('new register: weighted_avg argmax of gate inputs and reg coef: ', 1, 'reg_coef argmax', 2)"
     ]
    }
   ],
   "source": [
    "v0 = as_tensor(0)\n",
    "v1 = as_tensor(1)\n",
    "output = [registers, memory_tape, v0, v0, v1]\n",
    "new_registers = []\n",
    "for timestep in range(10):\n",
    "    #print(\"compute_all_timesteps t = \", timestep)\n",
    "    \n",
    "    output = machine_compute_step_t(True, R, layers, w, gates, timestep+1, desired_out, 1, *(output))\n",
    "    registers, memory_tape, cost_t, cum_prob_t, prob_incomplete = output\n",
    "    \n",
    "    print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "    print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "    print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "    print(\"cost = \", output[2].eval())\n",
    "    \n",
    "    #new_registers.append(output[0])\n",
    "    #registers=new_registers\n",
    "    #memory_tape=new_memory_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p __str__ = [[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "from theano import pp, tensor as T\n",
    "from theano import tensor as T, function, printing\n",
    "\n",
    "p = printing.Print('p')\n",
    "printed_r = p(initial_registers)\n",
    "f = function([initial_registers], printed_r)\n",
    "p_r = f(registers.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registers =  [[[  0.00000000e+000   1.68733456e-048   3.93711398e-048   4.37598441e-080\n",
      "     4.14789411e-020   6.51811920e-020   1.00000000e+000   2.45786088e-040\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000]\n",
      "  [  5.92556329e-021   9.49183839e-029   5.33863566e-077   9.12919712e-040\n",
      "     1.00000000e+000   2.37022516e-020   2.96278157e-020   3.99936297e-068\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000]\n",
      "  [  3.89420956e-105   5.62444855e-049   3.20249434e-087   4.27974840e-060\n",
      "     1.00000000e+000   1.20627068e-039   2.96278157e-020   3.99936297e-068\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000]\n",
      "  [  0.00000000e+000   5.62444855e-049   3.20249434e-087   4.27974840e-060\n",
      "     1.00000000e+000   1.20627068e-039   2.96278157e-020   3.99936297e-068\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "     0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000]]]\n",
      "memory tape:  [[0 1 2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "desired tape:  [[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]]\n"
     ]
    }
   ],
   "source": [
    "print(\"registers = \", registers.eval())\n",
    "print(\"memory tape: \", memory_tape.eval().argmax(axis=2))\n",
    "print(\"desired tape: \", desired_out.eval().argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_mem_op = printing.Print('print_mem')\n",
    "printed_mem = print_mem_op(initial_memory)\n",
    "f_mem = function([initial_memory], printed_mem)\n",
    "p_mem = f(memory_tape.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_t, cum_prob_t, prob_incomplete = calculate_cost_at_t(True, 0.5, 2, 0, 0, 0.5, memory_tape, desired_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": "6",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
