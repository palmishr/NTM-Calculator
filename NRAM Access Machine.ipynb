{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "READ (described in Sec. 3.2),\n",
    "WRITE (described in Sec. 3.2).\n",
    "\n",
    "ZERO(a, b) = 0, \n",
    "ONE(a, b) = 1, \n",
    "TWO(a, b) = 2, \n",
    "\n",
    "INC(a, b) = (a+1) mod M, \n",
    "ADD(a, b) = (a+b) mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "from theano import tensor\n",
    "from collections import namedtuple\n",
    "from theano.tensor.extra_ops import to_one_hot\n",
    "from theano.tensor import roll\n",
    "from theano.tensor import stack\n",
    "from theano.tensor import batched_dot\n",
    "from theano.tensor import concatenate\n",
    "from theano.tensor import as_tensor\n",
    "from theano.tensor import set_subtensor\n",
    "from theano import shared\n",
    "from numpy.random import uniform\n",
    "from theano.tensor.nnet import softmax, relu, sigmoid\n",
    "from theano import function, config, shared, sandbox, Out\n",
    "\n",
    "def zero() :\n",
    "    return to_one_hot(np.asarray([0]),M)\n",
    "def one() :\n",
    "    return to_one_hot(np.asarray([1]),M)\n",
    "def two() :\n",
    "    return to_one_hot(np.asarray([2]),M)\n",
    "def get_const(value) :\n",
    "    return to_one_hot(np.asarray([value % M]),M)\n",
    "def create_memory_tape(init_val=0):\n",
    "    m = stack([get_const(init_val) for i in range(M)], axis=1)\n",
    "    #return shared(np.asarray(m.eval()), config.floatX) \n",
    "    return m\n",
    "def inc(a) :\n",
    "    return roll(a, 1, axis=1)\n",
    "def negate(a) :\n",
    "    return roll(a[:, ::-1], 1, axis=1)\n",
    "def add(a,b) :\n",
    "    rows = [roll(b[:,], j, axis=1) for j in range(M)]\n",
    "    return (batched_dot(a, stack(rows, axis=1)))\n",
    "def sub(a,b) :\n",
    "    b_negative = negate(b)\n",
    "    return add(a, b_negative)\n",
    "def eq_zero(a) :\n",
    "    r = tensor.zeros_like(as_tensor(a))\n",
    "    r = set_subtensor(r[:,1], a[:, 0])\n",
    "    r = set_subtensor(r[:, 0], 1 - a[:, 0])\n",
    "    return r\n",
    "def lt(a,b):\n",
    "    a = as_tensor(a)\n",
    "    b = as_tensor(b)\n",
    "    b = set_subtensor(b[:,0], [0]) \n",
    "    b = roll(b[:,], -1, axis=1)\n",
    "    rows = [set_subtensor(tensor.zeros_like(as_tensor(b))[:,j:M], b[:,j:M]) for j in range(M)]\n",
    "    result = ((tensor.dot(as_tensor(a), stack(rows, axis =1))).sum()).dimshuffle('x')\n",
    "    return set_subtensor(tensor.zeros_like(as_tensor(b))[:,1], result)\n",
    "def eq(a,b):\n",
    "    elemwise_result = tensor.eq(as_tensor(a),as_tensor(b))\n",
    "    sum = elemwise_result.sum()\n",
    "    result = tensor.eq(sum,M).dimshuffle('x')\n",
    "    return set_subtensor(tensor.zeros_like(as_tensor(a))[:,1], result)\n",
    "def max_(a,b):\n",
    "    if(tensor.eq([0],lt(a,b))):\n",
    "        return as_tensor(b)\n",
    "    else:\n",
    "        return as_tensor(a)\n",
    "def min_(a,b):\n",
    "    if(tensor.eq([1],lt(a,b))):\n",
    "        return as_tensor(a)\n",
    "    else:\n",
    "        return as_tensor(b)    \n",
    "def read(mem, a) :\n",
    "    ptr = as_tensor(a)\n",
    "    return weighted_avg(mem, ptr), mem\n",
    "def write(mem, a, b) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    mem = (x + y)\n",
    "    return val, mem\n",
    "def write_external(a, b, ext_mem) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, ext_mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    ext_mem = (x + y)\n",
    "    return ext_mem\n",
    "\n",
    "def get_registers(init_val):\n",
    "    return stack([get_const(init_val) for i in range(R)], axis=1)\n",
    "\n",
    "def weighted_avg(inputs, coefficient) :\n",
    "    return batched_dot(inputs.transpose(0, 2, 1), coefficient.dimshuffle(0, 1, 'x')).flatten(2);\n",
    "\n",
    "def compute_gate_new(module, inputs, coefficients, memory_tape, debug=False) :\n",
    "    \"\"\" Arity of this gate must be equal to the number of given\n",
    "        coefficients list\n",
    "    \"\"\" \n",
    "    if (len(coefficients) != module.arity) :\n",
    "        print(\"Error: Incorrect number of coefficients: \",  len(coefficients), \" to module arity: \", module.arity)\n",
    "    \n",
    "    params = [weighted_avg(inputs, as_tensor(coef)) for coef in coefficients]\n",
    "    \n",
    "    if (debug == True):\n",
    "        for i, p in enumerate(params):\n",
    "            print(\"compute_gate_new: coeff\", coefficients[i].eval(), \" weighted param [\", i ,\"] = \", p.eval().argmax())\n",
    "    \n",
    "    if (module.memory_function == True) :\n",
    "        #print(\"read/write \")\n",
    "        output, memory_tape = module.function(memory_tape, *params)\n",
    "    else :   \n",
    "        output = module.function(*params)\n",
    "    \n",
    "    #error check for constant gates\n",
    "    return output, memory_tape\n",
    "\n",
    "\n",
    "def get_n_tensor(t, count, idx):\n",
    "    result=[]\n",
    "    if count > 0: \n",
    "        result = [t[idx+i] for i in range(count)]\n",
    "    return result, (idx+count)\n",
    "\n",
    "def fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug=False):\n",
    "    # Initially, only the registers may be used as inputs.\n",
    "    Q= len(gates)\n",
    "    gate_inputs = registers\n",
    "    idx=0    \n",
    "    \n",
    "    # Run through all the gates.\n",
    "    for i in range(Q):\n",
    "        c, idx = get_n_tensor(gate_coef, gates[i].arity, idx) \n",
    "        if (debug==True):\n",
    "            print(\"gate i = \", i, \"arity:\", gates[i].arity, \"gate inputs: \", gate_inputs.eval().argmax(axis=2))\n",
    "        output, memory_tape = compute_gate_new(gates[i], gate_inputs, c, memory_tape, debug)\n",
    "        # Append the output of the gate as an input for future gates.\n",
    "        gate_inputs = concatenate([gate_inputs, output.dimshuffle(0,'x',1)], axis=1)\n",
    "        if (debug==True):\n",
    "            print(\"gate output: \", output.eval().argmax())    \n",
    "            print(\"concatenated inputs: \", gate_inputs.eval().argmax(axis=2))       \n",
    "        \n",
    "    # All leftover coefficients are for registers.\n",
    "    new_registers = []\n",
    "             \n",
    "    for i in range(len(reg_coef)):\n",
    "        # (R+Q) x M dot 1 X (R+Q) \n",
    "        new_registers.append(weighted_avg(gate_inputs, reg_coef[i]))\n",
    "        if (debug == True) :\n",
    "            print(\"register [\", i, \"]  new value: reg_coef\", reg_coef[i].eval().argmax(),\"weighted_avg of gate inputs and reg_coef: \", weighted_avg(gate_inputs, reg_coef[i]).eval().argmax())\n",
    "    return tensor.stack(new_registers, axis=1), memory_tape\n",
    "\n",
    "\n",
    "# coefficients = [r1,r2..rR,g1_param1,g1_param2,...,gQ_param1,gQ_param2,c1,c1..CR,cR+1,..cR+Q]\n",
    "def gen_random_weights(layer1, layer2, dtype=np.float64, _min=-1, _max=1):\n",
    "    weights = uniform(low=_min, high=_max, size=(layer1, layer2))\n",
    "    var = shared(weights.astype(dtype), name=\"w{0}x{1}\".format(layer1, layer2))   \n",
    "    #var = tensor.addbroadcast(var, 0)\n",
    "    return var\n",
    "\n",
    "def gen_network_weights(gates, layers):\n",
    "    n_registers = R #input is R registers\n",
    "    w = []\n",
    "    current_layer_units = n_registers\n",
    "    for next_layer_units in layers:\n",
    "        w.append(gen_random_weights(current_layer_units + 1, next_layer_units))\n",
    "        current_layer_units = next_layer_units\n",
    "    #output wt for gate coefficients\n",
    "    gate_coef = []\n",
    "    for i, gate in enumerate(gates):\n",
    "        print(i, gate)\n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            gate_coef.append(gen_random_weights(current_layer_units + 1, gate_output_units))            \n",
    "    \n",
    "    #print(\"gen_network_weights => gate_coef\", gate_coef)         \n",
    "    #output wt for new registers\n",
    "    reg_coef = []\n",
    "    reg_output_units = n_registers + len(gates)\n",
    "    for _ in range(n_registers):\n",
    "        reg_coef.append(gen_random_weights(current_layer_units + 1, n_registers + len(gates)))    \n",
    "    \n",
    "    #print(\"gen_network_weights => reg_coef\", reg_coef)      \n",
    "    prob_completion_coef = (gen_random_weights(current_layer_units + 1, 1))\n",
    "\n",
    "    for i in gate_coef:\n",
    "        w.append(i)\n",
    "\n",
    "    for x in reg_coef:\n",
    "        w.append(x)\n",
    "    \n",
    "    w.append(prob_completion_coef)   \n",
    "    return w\n",
    "\n",
    "def aug_ones_col(inputs):\n",
    "    print(\"OMFG\")\n",
    "    s = inputs.shape\n",
    "    col_elems = s[1]\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), col_elems))\n",
    "    x = concatenate([inputs.T,ones], axis=1)\n",
    "    return x.T\n",
    "\n",
    "def aug_ones_col_new(inputs):\n",
    "    x=[]\n",
    "    s = inputs.shape\n",
    "    d = inputs.ndim\n",
    "    row_elems = s[d-2]\n",
    "    matrix = tensor.reshape(inputs, (s[d-2],s[d-1]))\n",
    "    matrix = tensor.shape_padleft(matrix)\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), row_elems))\n",
    "    x = concatenate([matrix.dimshuffle(0,2,1),ones.dimshuffle(0,'x',1)], axis=1)\n",
    "    return x.dimshuffle(0,2,1)\n",
    "\n",
    "def controller_forward_prop(n_registers, layers, weight_matrix, gates, registers, debug) :\n",
    "    inputs = aug_ones_col_new(registers[:,:,0])\n",
    "    if (debug == True):\n",
    "        print(\"registers: \", registers.eval())\n",
    "        print(\"registers[:,:,0]: \", registers[:,:,0].eval())\n",
    "        print(\"inputs: \", inputs.eval())\n",
    "        \n",
    "    for i in range(len(layers)):\n",
    "        W = weight_matrix[i]\n",
    "        inputs = aug_ones_col_new(relu(inputs.dot(W)))  \n",
    "        if (debug == True):\n",
    "            print(\"compute layers inputs: \", inputs.eval())\n",
    "    \n",
    "    #extract gate coefficients\n",
    "    gate_coef = []\n",
    "    n_gate_coef = 0\n",
    "    \n",
    "    for i, gate in enumerate(gates): \n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            n_gate_coef += 1  \n",
    "            \n",
    "    for W in weight_matrix[len(layers):len(layers) + n_gate_coef]:\n",
    "        gate_coef.append(softmax(inputs.dot(W)[0]))            \n",
    "    \n",
    "    reg_coef = []\n",
    "    for W in (weight_matrix[len(layers)+n_gate_coef:len(layers)+n_gate_coef+n_registers]):\n",
    "        reg_coef.append(softmax(inputs.dot(W)[0]))  \n",
    "    \n",
    "    if (debug == True):\n",
    "        print(\"inputs.dot(W)\", inputs.dot(W).eval())\n",
    "        print(\"inputs.dot(W)[0]\", inputs.dot(W)[0].eval())\n",
    "        print(\"p_complete inputs: \", inputs.eval())\n",
    "        print(\"inputs.dot(weight_matrix[-1]: \", inputs.dot(weight_matrix[-1]).eval())  \n",
    "              \n",
    "    p = sigmoid((inputs.dot(weight_matrix[-1])))\n",
    "    if (debug == True):\n",
    "        print(\"p_complete: \", p.eval())\n",
    "        \n",
    "    return p, reg_coef, gate_coef\n",
    "\n",
    "def calculate_cost_at_t(prob_complete_t, t, cum_cost, cum_prob_t, p_incomplete, memory_in, desired_output, output_len, debug) :\n",
    "    e_min = 1e-100\n",
    "    e_max = 1e+100\n",
    "    cost_t = 0\n",
    "    #TODO: Find use for desired registers in calculating cost. Now, only desired memory layout is matched.\n",
    "    for i in range(output_len):\n",
    "        #Compute the loss for this register using the mask.\n",
    "        y = to_one_hot(desired_output.argmax(axis=2)[:,i], M)   \n",
    "        y_hat = to_one_hot(memory_in.argmax(axis=2)[:,i], M) \n",
    "        ln_y_hat = tensor.log(tensor.clip(memory_in[:, i, :], e_min, e_max))\n",
    "        ln_1_minus_y_hat = tensor.log(tensor.clip(1 - memory_in[:, i, :], e_min, e_max))\n",
    "        x1 = y * ln_y_hat\n",
    "        x2 = (1 - y) * ln_1_minus_y_hat\n",
    "        loss = (x1+x2).sum(axis=1) \n",
    "        cost_t += tensor.shape_padright(loss, 1)\n",
    "        if (debug == True):\n",
    "            #print(\"desired_output at i\", desired_output[:,i].eval())\n",
    "            #print(\"memory value at i\", memory_in[:, i, :].eval())\n",
    "            #print(\"y \", y.eval())\n",
    "            #print(\"y_hat \", y_hat.eval())\n",
    "            #print(\"ln_y_hat \", ln_y_hat.eval())\n",
    "            #print(\"ln_1_minus_y_hat \", ln_1_minus_y_hat.eval())\n",
    "            #print(\"x1 \", x1.eval())\n",
    "            #print(\"x2 \", x2.eval())\n",
    "            print(\"loss \", loss.eval())\n",
    "            #print(\"tensor.shape_padright(loss, 1) \", tensor.shape_padright(loss, 1).eval())\n",
    "            #print(\"Desired value at mem location [\", i, \"] is \", y.eval().argmax(), \"but actual value is [\", memory_in[:,i,:].eval().argmax(), \"loss is \", loss.eval(), \" cost = \", cost_t.eval()) \n",
    "    \n",
    "    if (t == MAX_TIMESTEP):\n",
    "        prob_complete = 1 - cum_prob_t\n",
    "    else:\n",
    "        prob_complete = (prob_complete_t * p_incomplete)\n",
    "    \n",
    "    cum_prob_t += prob_complete\n",
    "    p_incomplete *= (1 - prob_complete_t)\n",
    "    cum_cost -= (cost_t*prob_complete)\n",
    "    \n",
    "    if (debug == True):\n",
    "        print(\"prob_complete_t\", prob_complete_t.eval())\n",
    "        print(\"p_incomplete\", p_incomplete.eval())\n",
    "        print(\"prob_complete\", prob_complete.eval())\n",
    "        print(\"cum_prob_t\", cum_prob_t.eval())\n",
    "        print(\"cost_t*prob_complete\", (cost_t*prob_complete).eval())\n",
    "        print(\"cum_cost\", cum_cost.eval())\n",
    "    return cum_cost, cum_prob_t, p_incomplete\n",
    "\n",
    "def machine_compute_step_t(debug, R, layers, w, gates, t, desired_output, output_len, registers, memory_tape, cost_t, cum_prob, prob_incomplete) : \n",
    "    prob_complete_t, reg_coef, gate_coef = controller_forward_prop(R, layers, w, gates, registers, debug)\n",
    "    new_registers, new_memory_tape = fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug)\n",
    "    cost_t, cum_prob_t, prob_incomplete = calculate_cost_at_t(prob_complete_t, t, cost_t, cum_prob, prob_incomplete, new_memory_tape, desired_output, output_len, debug)\n",
    "    return new_registers, new_memory_tape, cost_t, cum_prob_t, prob_incomplete\n",
    "\n",
    "def compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len):\n",
    "    #w = make_broadcastable(w)\n",
    "    # Create symbolic variables for the input to the machine\n",
    "    # and for the desired output of the machine.\n",
    "      \n",
    "    #initial_registers = registers\n",
    "    #desired_output = memory_tape\n",
    "\n",
    "    initial_registers = tensor.dtensor3(\"Registers\")\n",
    "    initial_memory = tensor.dtensor3(\"Memory_Tape\")\n",
    "    desired_output = tensor.dtensor3(\"Y\")\n",
    "     \n",
    "    \n",
    "    # Run the model for all timesteps. The arguments are \n",
    "    # registers, cost, cumulative probability complete, \n",
    "    # and probability incomplete. The latter are initialized\n",
    "    # to zero and to one, respectively.\n",
    "    \n",
    "    v0 = as_tensor(0)\n",
    "    v1 = as_tensor(1)\n",
    "    output = [initial_registers, initial_memory, v0, v0, v1]\n",
    "    intermediate_registers = []\n",
    "    for timestep in range(MAX_TIMESTEP):\n",
    "        print(\"compute_all_timesteps t = \", timestep)\n",
    "        output = machine_compute_step_t(False, R, layers, w, gates, timestep+1, desired_output, output_len, *(output))\n",
    "        intermediate_registers.append(output[0])\n",
    "\n",
    "    # Add in regularization, to avoid overfitting simple examples.\n",
    "    reg_cost = reg_lambda * sum((p * p).sum() for p in list(w))\n",
    "    \n",
    "    # Get the final cost: regularization plus loss.\n",
    "    final_cost = reg_cost + output[2].sum()\n",
    "    \n",
    "    # Return the symbolic variables, the final cost, and the\n",
    "    # intermediate register values for analysis and prediction.\n",
    "    return initial_registers, initial_memory, desired_output, final_cost, intermediate_registers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Module(arity=1, function=<function read at 0x106b3c758>, memory_function=True))\n",
      "(1, Module(arity=1, function=<function inc at 0x106b3c320>, memory_function=False))\n",
      "(2, Module(arity=0, function=<function zero at 0x106b39d70>, memory_function=False))\n",
      "(3, Module(arity=2, function=<function lt at 0x106b3c578>, memory_function=False))\n",
      "(4, Module(arity=2, function=<function min_ at 0x106b3c6e0>, memory_function=False))\n",
      "(5, Module(arity=2, function=<function write at 0x106b3c7d0>, memory_function=True))\n",
      "('weight matrix: ', [w3x5, w6x5, w6x2, w6x3, w6x5, w6x5, w6x6, w6x6, w6x7, w6x7, w6x8, w6x8, w6x1])\n"
     ]
    }
   ],
   "source": [
    "#Maximum Representable Integer M is set below\n",
    "M = 16\n",
    "# Number of registers\n",
    "R = 2\n",
    "#Max number of timesteps\n",
    "MAX_TIMESTEP = 5\n",
    "\n",
    "Module = namedtuple(\"Module\", \"arity function memory_function\")\n",
    "\n",
    "m_zero = Module(0, zero, False)\n",
    "m_one = Module(0, one, False)\n",
    "m_two = Module(0, two, False)\n",
    "m_inc = Module(1, inc, False)\n",
    "m_negate = Module(1, negate, False)\n",
    "m_add = Module(2, add, False)\n",
    "m_sub = Module(2, sub, False)\n",
    "m_eq_zero = Module(1, eq_zero, False)\n",
    "m_read = Module(1, read, True)\n",
    "m_write = Module(2, write, True)\n",
    "m_lt = Module(2, lt, False)\n",
    "m_eq = Module(2, eq, False)\n",
    "m_min = Module(2, min_, False)\n",
    "m_max = Module(2, max_, False)\n",
    "\n",
    "gates = [m_read, m_inc, m_zero, m_lt, m_min, m_write]\n",
    "#gates = [m_read, m_write]\n",
    "N = len(gates)\n",
    "\n",
    "registers = get_registers(1)\n",
    "memory_tape = create_memory_tape()\n",
    "desired_out = create_memory_tape(0)\n",
    "for i in range(M):\n",
    "     desired_out = write_external(get_const(i), get_const(i), desired_out)\n",
    "        \n",
    "layers = [5,5]\n",
    "w = gen_network_weights(gates, layers)\n",
    "print(\"weight matrix: \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('compute_all_timesteps t = ', 0)\n",
      "('compute_all_timesteps t = ', 1)\n",
      "('compute_all_timesteps t = ', 2)\n",
      "('compute_all_timesteps t = ', 3)\n",
      "('compute_all_timesteps t = ', 4)\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "output_len = 1\n",
    "result  = compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len)\n",
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Registers,\n",
       " Memory_Tape,\n",
       " Y,\n",
       " Elemwise{add,no_inplace}.0,\n",
       " [Join.0, Join.0, Join.0, Join.0, Join.0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradients = theano.grad(final_cost, list(w)) #, disconnected_inputs='warn', return_disconnected='Disconnected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(gradients)):\n",
    "    theano.gradient.grad_clip(gradients[i], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile training function to compute gradients.\n",
    "train = theano.function([initial_registers, initial_memory, desired_output], [final_cost] + gradients) #, on_unused_input='ignore', allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Access Task\n",
    "input = [ 7,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "output = [ 13 ]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('desired_out.eval()', array([[13]]))\n",
      "('memory_tape.eval()', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('registers.eval()', array([[0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print (\"desired_out.eval()\", desired_out.eval().argmax(axis=2))\n",
    "print (\"memory_tape.eval()\", memory_tape.eval().argmax(axis=2))\n",
    "print (\"registers.eval()\", registers.eval().argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(71.3329429218814), array([[  4.31705273e-02,   2.24454106e+01,  -6.92314258e-02,\n",
      "          1.09350466e-01,  -3.34101883e+01],\n",
      "       [  8.70542068e-02,   2.24745801e+01,  -1.27420656e-01,\n",
      "          1.19600193e-02,  -3.34715117e+01],\n",
      "       [  4.61696860e-01,   2.26276974e+01,   3.55621368e-02,\n",
      "          2.03705002e-01,  -3.34777990e+01]]), array([[ -1.43639274e-01,  -9.93335076e-02,  -1.39343930e-01,\n",
      "         -1.22061298e-01,  -1.96829202e-01],\n",
      "       [ -1.13655509e-01,  -1.20973178e-02,  -7.59040180e+00,\n",
      "         -5.03303054e+01,  -4.67424000e+01],\n",
      "       [ -9.36121738e-02,  -7.35953985e-02,  -1.39594313e-01,\n",
      "         -1.60587768e-02,   7.50432777e-02],\n",
      "       [  1.80390594e-01,   1.33449814e-01,  -1.45953004e-01,\n",
      "         -5.88862422e-02,  -3.21365790e-02],\n",
      "       [ -1.93729120e-01,  -1.12561580e-01,  -8.90046489e+00,\n",
      "         -6.15110785e+01,  -5.70120573e+01],\n",
      "       [ -7.67306190e-02,  -1.77391714e-01,  -5.66014440e+00,\n",
      "         -3.91509881e+01,  -3.65473973e+01]]), array([[ 0.06251684, -0.11580334],\n",
      "       [ 0.01473216, -0.0138915 ],\n",
      "       [-0.05826061, -0.1392364 ],\n",
      "       [ 0.13697621,  0.09650383],\n",
      "       [ 0.18320378, -0.0681576 ],\n",
      "       [ 0.14863625,  0.07667723]]), array([[ 0.11434039, -0.08338629,  0.06214258],\n",
      "       [ 0.12584608, -0.09625852, -0.08621632],\n",
      "       [ 0.02091427,  0.16747747,  0.11848476],\n",
      "       [-0.13075834,  0.1814514 , -0.02813266],\n",
      "       [ 0.056331  , -0.14566471, -0.00178272],\n",
      "       [ 0.06104974,  0.0795656 , -0.00139164]]), array([[-0.16724983,  0.03390951, -0.09110648,  0.18620805,  0.17823529],\n",
      "       [-0.07201409, -0.08819391,  0.15697415, -0.07722522, -0.05406594],\n",
      "       [ 0.11727924,  0.01957454,  0.02953594,  0.18561871, -0.16303047],\n",
      "       [-0.0464348 ,  0.01627761,  0.01089915, -0.06365036, -0.00740785],\n",
      "       [-0.04457885,  0.19216182, -0.12714779,  0.09866126, -0.03589066],\n",
      "       [-0.16670998, -0.10849249, -0.09048541,  0.03773169,  0.19992441]]), array([[-0.03999099, -0.13247137, -0.1486054 ,  0.05029806,  0.10614592],\n",
      "       [ 0.19411951, -0.04458791,  0.06032199, -0.14717149, -0.14711445],\n",
      "       [ 0.03729371, -0.13019274, -0.042585  , -0.09542009, -0.12107233],\n",
      "       [-0.04846197, -0.18320726,  0.06252979, -0.01978823,  0.13561776],\n",
      "       [ 0.09338004,  0.04314928, -0.13355963, -0.00741414, -0.05304668],\n",
      "       [-0.15598928, -0.17564767, -0.1013068 , -0.00406033,  0.10474918]]), array([[ 0.14830696,  0.18863037, -0.04962096, -0.19625141, -0.01303957,\n",
      "        -0.11144976],\n",
      "       [-0.1860706 , -0.07555738,  0.14514758,  0.17166134,  0.17443498,\n",
      "         0.18920891],\n",
      "       [-0.01879398, -0.0877293 , -0.04277338, -0.16721836,  0.18561095,\n",
      "         0.04887409],\n",
      "       [-0.07471898,  0.15246194, -0.18991993, -0.04250388,  0.14947002,\n",
      "        -0.1495554 ],\n",
      "       [ 0.21693917,  0.18389635, -0.04921853,  0.2009624 , -0.08863729,\n",
      "        -0.03401406],\n",
      "       [ 0.14647735,  0.24252791,  0.0650977 , -0.16008549, -0.03155269,\n",
      "        -0.03253411]]), array([[ 0.01902984, -0.03774871,  0.14799363, -0.11680288,  0.10429444,\n",
      "         0.06209297],\n",
      "       [ 0.10673728,  0.12596445,  0.06989114, -0.03713143, -0.01203195,\n",
      "         0.07721584],\n",
      "       [-0.12760832,  0.16861133,  0.06492793,  0.03558753,  0.16288025,\n",
      "        -0.0765283 ],\n",
      "       [-0.00907359, -0.00189725, -0.07869349, -0.13410794, -0.07943575,\n",
      "        -0.08031277],\n",
      "       [-0.17406229,  0.14116791,  0.11941584,  0.06424464, -0.18464311,\n",
      "         0.12158722],\n",
      "       [-0.14631555,  0.02362981,  0.02870819, -0.02373457, -0.00185689,\n",
      "        -0.05496452]]), array([[ 0.11859684,  0.07116279,  0.04183531, -0.18392811, -0.0892084 ,\n",
      "         0.13093149,  0.16044985],\n",
      "       [-0.15109517, -0.08090768, -0.13346189, -0.18412416,  0.13770701,\n",
      "         0.16973038, -0.13887803],\n",
      "       [ 0.0098313 ,  0.1493516 ,  0.57872244, -0.11107475, -0.49211046,\n",
      "        -0.03521909,  0.18227426],\n",
      "       [ 0.16594607,  0.16778411, -0.03056386,  0.18474157,  0.06912009,\n",
      "         0.19768991,  0.19289882],\n",
      "       [-0.05354086, -0.19287179,  0.63242073,  0.00272958, -0.58456596,\n",
      "         0.11687329,  0.28648874],\n",
      "       [-0.057957  , -0.03027067,  0.34979604,  0.09708709, -0.22017867,\n",
      "         0.03787405, -0.0741138 ]]), array([[-0.02878304,  0.10443954,  0.00266007,  0.13232729, -0.00417379,\n",
      "        -0.17669921,  0.06297396],\n",
      "       [ 0.1000288 , -0.10149064, -0.00806835,  0.10056102, -0.11093746,\n",
      "         0.07256485,  0.06392068],\n",
      "       [-0.07204961,  0.11262856,  0.10249278,  0.33884468,  0.16232081,\n",
      "         0.1226669 , -0.10142865],\n",
      "       [-0.14359021,  0.01700293,  0.14314271, -0.08526684,  0.14068235,\n",
      "        -0.1375463 ,  0.12020914],\n",
      "       [ 0.02358412, -0.11238084, -0.26423451,  0.29077262,  0.18978581,\n",
      "        -0.18870221, -0.09487009],\n",
      "       [-0.00844619, -0.05299709, -0.00871162,  0.20526158, -0.03331098,\n",
      "        -0.1483329 , -0.09185743]]), array([[ 0.10715077,  0.15019256, -0.04144146, -0.1494367 , -0.01557202,\n",
      "         0.19399091, -0.09249156,  0.07288502],\n",
      "       [-0.00773193,  0.19576738,  0.03450715,  0.05178546,  0.03714886,\n",
      "         0.18816824,  0.19043536,  0.1306361 ],\n",
      "       [ 0.11864801,  0.28536321, -0.39405356,  0.0946698 , -0.13431182,\n",
      "        -0.01020913, -0.11241601, -0.09389585],\n",
      "       [ 0.16328794,  0.20035632,  0.01331916, -0.00233936,  0.09243216,\n",
      "         0.14285915, -0.07094917, -0.15574537],\n",
      "       [-0.05972887,  0.15112685, -0.48773417,  0.30497609,  0.08692897,\n",
      "        -0.13486346, -0.09406695, -0.07460084],\n",
      "       [-0.17068334,  0.00283684, -0.30578789, -0.0344599 , -0.0336285 ,\n",
      "        -0.0616859 , -0.1919151 ,  0.07174147]]), array([[-0.04643879, -0.05450912,  0.11751618, -0.11006668, -0.13201488,\n",
      "        -0.03058518,  0.13697381,  0.18948483],\n",
      "       [ 0.00507035,  0.12096613,  0.15618578, -0.02211636,  0.00364145,\n",
      "        -0.03281869, -0.04362492,  0.13585258],\n",
      "       [-0.09435604,  0.16498163, -0.1333637 ,  0.13022974, -0.04534805,\n",
      "         0.10737827,  0.10763058,  0.13804848],\n",
      "       [-0.17200185,  0.03651504,  0.16071717,  0.09377527, -0.0311828 ,\n",
      "        -0.12416437, -0.00854726, -0.1946908 ],\n",
      "       [ 0.12406971,  0.03531494, -0.18356261,  0.28225345,  0.09313336,\n",
      "        -0.01127877,  0.1217384 ,  0.12649701],\n",
      "       [-0.05248434, -0.08959011, -0.10483892, -0.1146856 ,  0.15770106,\n",
      "         0.01390695, -0.19875904, -0.16834382]]), array([[ -0.17850006],\n",
      "       [  0.17545612],\n",
      "       [ 51.41335736],\n",
      "       [  2.38247047],\n",
      "       [ 79.61191568],\n",
      "       [ 41.2412651 ]])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    output_train = train(registers.eval(), memory_tape.eval(), desired_out.eval())\n",
    "    cost = output_train[0]\n",
    "    gradients = output_train[1:]\n",
    "    print(output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0]\n",
      "[Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0]\n"
     ]
    }
   ],
   "source": [
    "#training data for \"access\" \n",
    "train_data_size = 50\n",
    "train_inputs_access = []\n",
    "train_outputs_access = []\n",
    "\n",
    "input = []\n",
    "output = []\n",
    "for i in range(train_data_size):\n",
    "    #generated a random array\n",
    "    input = np.random.randint(1,15,size=(M))\n",
    "    input_t = stack([get_const(i) for i in input], axis=1)\n",
    "    #print(\"input array\", input_t.eval().argmax(axis=2))\n",
    "    train_inputs_access.append(input_t)\n",
    "    first_elem = input[0]\n",
    "    output = np.array([[input[first_elem]]])\n",
    "    output_t = stack([get_const(i) for i in output], axis=1)\n",
    "    #print(output_t.eval().argmax(axis=2))\n",
    "    train_outputs_access.append(output_t)\n",
    "print(train_inputs_access)    \n",
    "print(train_outputs_access)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clamp(n, minn, maxn):\n",
    "    for i, item in enumerate(n):\n",
    "        n[i] = (map(lambda x: max(min(maxn, x), minn), item))\n",
    "    return n    \n",
    "    \n",
    "def get_l2_norm(w):\n",
    "    x=0\n",
    "    for i, item in enumerate(w):\n",
    "        x += np.linalg.norm(item)\n",
    "    return x    \n",
    "\n",
    "def add_noise(gradients, mean, std_dev):\n",
    "    result = map(lambda x: x + np.random.normal(mean,std_dev,x.shape), gradients)\n",
    "    return result\n",
    "\n",
    "#This code is borrowed from http://andrew.gibiansky.com/ based on ADAM optimization technique proposed in the paper\n",
    "def adam_optimize(params, train, registers, train_inputs, train_outputs, output_len,\n",
    "                  alpha=0.001, b1=0.9, b2=0.999,\n",
    "                  epsilon=1e-8, batch_size=1):\n",
    "    \"\"\"Implementation of Adam optimization method, with hyperparameters\n",
    "    taken as recommended by the original publication.\"\"\"\n",
    "    # Initialize first and second moment estimates to zero.\n",
    "    # This causes some bias, which is addressed later.\n",
    "    moment1 =  [0 for _ in params]\n",
    "    moment2 = [0 for _ in params]\n",
    "    \n",
    "    timestep = 0  # Current optimization step\n",
    "    batch = 0     # Where does this batch start\n",
    "    \n",
    "    converged = False\n",
    "    gradients = []\n",
    "    \n",
    "    while not converged:\n",
    "        timestep += 1\n",
    "        \n",
    "        inputs  = train_inputs[batch:batch+batch_size][0]\n",
    "        outputs = train_outputs[batch:batch+batch_size][0] \n",
    "        \n",
    "        result = train(registers, inputs.eval(), outputs.eval())\n",
    "        \n",
    "        cost = result[0]\n",
    "        gradients = result[1:]\n",
    "        \n",
    "        gradients=add_noise(gradients, 0, 1/(1 + timestep)**0.55)\n",
    "        \n",
    "        # Advance to next batch.\n",
    "        batch = (batch + batch_size) % len(train_inputs)\n",
    "\n",
    "        # Compute first and second moment estimates.\n",
    "        # These are decaying moving averages; first moment\n",
    "        # uses the gradient, second uses squared gradient.\n",
    "        moment1  = [b1 * m + (1 - b1) * gradient\n",
    "                    for (m, gradient)\n",
    "                    in zip(moment1, gradients)]\n",
    "        moment2 = [b2 * v + (1 - b2) * gradient ** 2\n",
    "                   for (v, gradient)\n",
    "                   in zip(moment2, gradients)]\n",
    "        \n",
    "        # Correct for initialization bias and compute new values.\n",
    "        correction1 = 1. / (1 - b1 ** timestep)\n",
    "        correction2 = 1. / (1 - b2 ** timestep)\n",
    "        corrected1 = [correction1 * m for m in moment1]\n",
    "        corrected2 = [correction2 * v for v in moment2]\n",
    "        \n",
    "        # Compute new parameter values.\n",
    "        params_new = [p.get_value() - alpha * m1 / (np.sqrt(m2) + epsilon)\n",
    "                      for (p, m1, m2) in zip(params, corrected1, corrected2)]\n",
    "\n",
    "        # Check for convergence by looking at magnitude of delta.\n",
    "        delta = [abs(p.get_value() - p_new)\n",
    "                 for (p, p_new) in zip(params, params_new)]\n",
    "        converged = all((d < 0.5 * alpha).all() for d in delta)        \n",
    "        \n",
    "        # Update parameters to new values.\n",
    "        for p, p_new in zip(params, params_new):\n",
    "            p_new = clamp(p_new, -1, 1)\n",
    "            p.set_value(p_new.astype('float32'))\n",
    "            \n",
    "        # Provide some output for tracking during runtime.\n",
    "        if timestep % 100 == 1 or converged:\n",
    "            print(\"Cost (t = %4d): \\t%.2f\" % (timestep - 1, cost))\n",
    "            print(\"l2 norm of gradients: \", get_l2_norm(gradients))\n",
    "            print(\"l2 norm of p_new: \", get_l2_norm(p_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (t =    0): \t55.94\n",
      "('l2 norm of gradients: ', 285.793455006854)\n",
      "('l2 norm of p_new: ', 4.5805877894559988)\n",
      "Cost (t =  100): \t29.18\n",
      "('l2 norm of gradients: ', 125.10614280165575)\n",
      "('l2 norm of p_new: ', 4.5671700921398637)\n",
      "Cost (t =  200): \t20.28\n",
      "('l2 norm of gradients: ', 76.34185983896505)\n",
      "('l2 norm of p_new: ', 4.4340524510580224)\n",
      "Cost (t =  300): \t15.42\n",
      "('l2 norm of gradients: ', 51.627368073352429)\n",
      "('l2 norm of p_new: ', 4.2914139190237979)\n",
      "Cost (t =  400): \t12.16\n",
      "('l2 norm of gradients: ', 38.317028317104501)\n",
      "('l2 norm of p_new: ', 4.1539377285174481)\n",
      "Cost (t =  500): \t9.73\n",
      "('l2 norm of gradients: ', 29.509717728378149)\n",
      "('l2 norm of p_new: ', 4.0244898837390375)\n",
      "Cost (t =  600): \t7.83\n",
      "('l2 norm of gradients: ', 24.121714860937079)\n",
      "('l2 norm of p_new: ', 3.901720487157943)\n",
      "Cost (t =  700): \t6.42\n",
      "('l2 norm of gradients: ', 19.41178266754622)\n",
      "('l2 norm of p_new: ', 3.7875567193865112)\n",
      "Cost (t =  800): \t5.42\n",
      "('l2 norm of gradients: ', 15.962194223920459)\n",
      "('l2 norm of p_new: ', 3.6808303135145186)\n",
      "Cost (t =  900): \t4.69\n",
      "('l2 norm of gradients: ', 13.446358768310578)\n",
      "('l2 norm of p_new: ', 3.5869914454162455)\n",
      "Cost (t = 1000): \t4.15\n",
      "('l2 norm of gradients: ', 11.484914382697436)\n",
      "('l2 norm of p_new: ', 3.5033401032338132)\n",
      "Cost (t = 1100): \t3.74\n",
      "('l2 norm of gradients: ', 9.7512894416723448)\n",
      "('l2 norm of p_new: ', 3.4297534554715146)\n",
      "Cost (t = 1175): \t3.22\n",
      "('l2 norm of gradients: ', 10.024213609374417)\n",
      "('l2 norm of p_new: ', 3.3769705728395274)\n"
     ]
    }
   ],
   "source": [
    "#def adam_optimize(params, train, train_inputs, mem, train_outputs, output_len,\n",
    "#                  alpha=0.001, b1=0.9, b2=0.999,\n",
    "#                  epsilon=1e-8, batch_size=1):\n",
    "    \n",
    "result = adam_optimize(w, train, registers.eval(), train_inputs_access, train_outputs_access, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.04333892e-01   3.22977230e-02  -2.22566426e-02  -4.08585789e-03\n",
      "    8.15865934e-01]\n",
      " [ -5.50128892e-02   1.04259066e-01  -7.73710608e-02  -2.27401387e-02\n",
      "    6.19065940e-01]\n",
      " [  4.00793999e-02   3.23709875e-01   1.91525947e-02  -6.68770808e-04\n",
      "    1.00000000e+00]]\n",
      "[[-0.12018285 -0.05922966 -0.08206513 -0.04878473 -0.17521566]\n",
      " [-0.05836811 -0.00440458 -0.39032587 -0.19385818  0.28980574]\n",
      " [-0.03296703 -0.03237649 -0.10168082 -0.00597899  0.02717541]\n",
      " [ 0.18444966  0.11025048 -0.11753494 -0.02556762 -0.01055628]\n",
      " [-0.24266942 -0.06037302  1.          0.20148782  1.        ]\n",
      " [-0.02814189 -0.17331459  1.          1.          0.74679756]]\n",
      "[[  2.00794544e-02  -8.49843249e-02]\n",
      " [ -2.28182785e-03   3.34775250e-04]\n",
      " [  1.73881888e-01  -2.85365909e-01]\n",
      " [  1.91591322e-01  -3.72342616e-02]\n",
      " [  3.63736421e-01  -2.29456991e-01]\n",
      " [  1.99303031e-01  -4.99068610e-02]]\n",
      "[[ 0.06535435 -0.0390671   0.02776974]\n",
      " [ 0.08767241 -0.03603599 -0.0467042 ]\n",
      " [-0.00980904  0.12480929  0.1582879 ]\n",
      " [-0.11518632  0.17602268  0.00601354]\n",
      " [ 0.0215996  -0.19008859  0.02332358]\n",
      " [ 0.01198554  0.02920246  0.01521768]]\n",
      "[[-0.1611663   0.00412032 -0.03847792  0.19916886  0.1721037 ]\n",
      " [-0.02465107 -0.04374204  0.11925642 -0.04786376 -0.01550709]\n",
      " [ 0.05229126  0.00171816  0.01447365  0.25130954 -0.14756151]\n",
      " [-0.02506083 -0.0022778   0.00715633 -0.01649941 -0.00706975]\n",
      " [-0.01562234  0.20523374 -0.0714998   0.06849382 -0.01853507]\n",
      " [-0.17729057 -0.05351933 -0.02863529  0.0153577   0.24729554]]\n",
      "[[-0.01495465 -0.09642237 -0.13173893  0.01084069  0.05297828]\n",
      " [ 0.22741938 -0.01161837  0.02402956 -0.11703139 -0.1226861 ]\n",
      " [ 0.01531378 -0.08915377 -0.02419994 -0.06710126 -0.03331025]\n",
      " [-0.00788677 -0.19310395  0.01556237 -0.02180795  0.13951933]\n",
      " [ 0.0597462   0.00474066 -0.11251132 -0.03339128  0.0108445 ]\n",
      " [-0.12138419 -0.18298368 -0.06165252 -0.01617566  0.06687403]]\n",
      "[[ 0.11329171  0.2126344  -0.01750159 -0.22912395  0.00407231 -0.05645677]\n",
      " [-0.22918046 -0.03718305  0.12646618  0.16174999  0.15928008  0.20598526]\n",
      " [-0.20606445 -0.21454832  0.83361757 -0.31362462  0.07880593 -0.07954657]\n",
      " [-0.13997713  0.04953712  0.05951652 -0.09697796  0.04914557 -0.18468317]\n",
      " [ 0.12055444 -0.00789004  0.83799517  0.12339086 -0.25203753 -0.10952569]\n",
      " [ 0.00586999  0.20370956  0.47501031 -0.22939034 -0.11279199 -0.05174847]]\n",
      "[[ 0.00052415 -0.01140498  0.13581395 -0.074251    0.05574078  0.014066  ]\n",
      " [ 0.06407868  0.07970664  0.00851542 -0.01227398 -0.00462983  0.03241958]\n",
      " [-0.07165709  0.18564194  0.02255807  0.00563376  0.13555981 -0.03102217]\n",
      " [-0.00399182 -0.00388053 -0.03092615 -0.0871262  -0.04294174 -0.03179094]\n",
      " [-0.16324757  0.08767067  0.08840434  0.01710069 -0.21397175  0.08733115]\n",
      " [-0.13010567  0.00661793  0.00543182 -0.00545915  0.00306408 -0.02223829]]\n",
      "[[ 0.07415383  0.02644333  0.01047059 -0.19321939 -0.06458956  0.10280194\n",
      "   0.14916056]\n",
      " [-0.11815691 -0.03244733 -0.09559155 -0.21416056  0.12423532  0.18229461\n",
      "  -0.09818476]\n",
      " [-0.06637027  0.08537879  0.20993075 -0.11968487  0.54629785 -0.08848069\n",
      "  -0.14453717]\n",
      " [ 0.13218588  0.12775066 -0.1494987   0.18559964  0.47231761  0.20035614\n",
      "   0.14087796]\n",
      " [-0.0639851  -0.23072779 -0.18663682 -0.04064824  0.84462976 -0.00550936\n",
      "   0.06375013]\n",
      " [-0.03886115 -0.05217223 -0.10235512  0.00935204  0.5457561  -0.01983875\n",
      "  -0.18802263]]\n",
      "[[ -8.27950705e-03   5.24248295e-02   7.06955732e-04   9.67840329e-02\n",
      "   -9.72983707e-03  -1.86070502e-01   1.60619039e-02]\n",
      " [  3.73210795e-02  -5.51471859e-02   9.66764288e-04   4.85260934e-02\n",
      "   -6.67332560e-02   2.27949917e-02   2.56517604e-02]\n",
      " [ -1.16380148e-01  -1.88228581e-03   1.99071810e-01   1.45419925e-01\n",
      "   -1.20408446e-01   3.42888944e-02   7.34961748e-01]\n",
      " [ -1.44386753e-01  -4.79059033e-02   1.51973933e-01  -2.06247211e-01\n",
      "    2.79471893e-02  -1.13178432e-01   4.25869107e-01]\n",
      " [ -9.31165963e-02  -1.41916603e-01  -1.82818219e-01  -1.25317350e-01\n",
      "   -9.62555930e-02  -2.38942131e-01   7.93041706e-01]\n",
      " [ -4.93959747e-02  -7.25150779e-02   2.89580841e-02  -7.15609491e-02\n",
      "   -1.22121736e-01  -1.55077487e-01   3.64443898e-01]]\n",
      "[[ 0.04628422  0.13301675 -0.01543448 -0.11867319  0.0042454   0.26183927\n",
      "  -0.03919083  0.02068659]\n",
      " [ 0.00474035  0.24028333  0.0064875   0.01650466  0.01035009  0.21345088\n",
      "   0.2332049   0.09266625]\n",
      " [ 0.44309586  0.71345961 -0.202448   -0.31868365 -0.21864782 -0.17900737\n",
      "  -0.17227443 -0.16622485]\n",
      " [ 0.29533195  0.45561901 -0.09409747 -0.12442697  0.02200508  0.03155324\n",
      "  -0.07153956 -0.18191886]\n",
      " [ 0.21944959  0.35953957  0.05879522 -0.12642537 -0.03657919 -0.30170038\n",
      "  -0.13799967 -0.15511802]\n",
      " [-0.13462828  0.12169461 -0.11661433 -0.18587153 -0.04405629 -0.09808824\n",
      "  -0.21269484 -0.02815659]]\n",
      "[[-0.0186855  -0.0177326   0.08761227 -0.05016618 -0.09841602 -0.0150681\n",
      "   0.09012331  0.2061514 ]\n",
      " [ 0.00574703  0.08511259  0.14744537 -0.00994175 -0.00130683 -0.00667242\n",
      "  -0.00729347  0.10082748]\n",
      " [-0.04175758  0.55820805 -0.1076026  -0.323659   -0.03159919 -0.10975506\n",
      "   0.46008092  0.08475392]\n",
      " [-0.16417572  0.23592015  0.13772936 -0.11944273 -0.01056513 -0.15572838\n",
      "   0.09591636 -0.22597988]\n",
      " [ 0.09345359  0.45451438 -0.20337805  0.11463591  0.03427982 -0.19668791\n",
      "   0.51244903  0.07412516]\n",
      " [-0.01570726  0.12535596 -0.04752951 -0.2854808   0.13333276 -0.07386864\n",
      "  -0.13147098 -0.16121423]]\n",
      "[[-0.1890042 ]\n",
      " [ 0.16683042]\n",
      " [-0.57413751]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 0.44699848]]\n"
     ]
    }
   ],
   "source": [
    "for W in w:\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Access Task\n",
    "input = [ 7,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "output = [ 13 ]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('registers = ', array([[0, 0]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('registers = ', array([[0, 0]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.50540911]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99784644]]]))\n",
      "('registers = ', array([[0, 7]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.52816157]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99458004]]]))\n",
      "('registers = ', array([[7, 7]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.5424753]]]))\n",
      "('prob_incomplete = ', array([[[ 0.98814758]]]))\n",
      "('registers = ', array([[7, 7]]))\n",
      "('memory tape:  ', array([[13,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.55249372]]]))\n",
      "('prob_incomplete = ', array([[[ 0.97801726]]]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3d7bac326892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmachine_compute_step_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mregisters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_prob_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_incomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"registers = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory tape:  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"desired tape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, inputs_to_values)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m             defaults)\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1454\u001b[0m                         optimizer, inputs, outputs)\n\u001b[1;32m   1455\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m                     \u001b[0moptimizer_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36madd_requirements\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShapeFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mattach_feature\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mattach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlreadyThere\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mon_attach\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'on_attach'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mon_import\u001b[0;34m(self, fgraph, node, reason)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0mo_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;31m# this is packed information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mget_node_infer_shape\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             o_shapes = shape_infer(node,\n\u001b[0;32m--> 917\u001b[0;31m                                    [self.shape_of[r] for r in node.inputs])\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mShapeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             o_shapes = self.default_infer_shape(node, [self.shape_of[r] for\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36minfer_shape\u001b[0;34m(self, node, shapes)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0moutshp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \u001b[0mcnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_canonical_form_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcnf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mget_canonical_form_slice\u001b[0;34m(theslice, length)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mslice_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mabs_step\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mslice_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mneg_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnw_stop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs_step\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mneg_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnw_stop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mnw_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch_neg_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# and the return value in that case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAsTensorError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s has no test value'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0mOptional\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msome\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mall\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v0 = as_tensor(0)\n",
    "v1 = as_tensor(1)\n",
    "output = [registers, memory_tape, v0, v0, v1]\n",
    "new_registers = []\n",
    "print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "for timestep in range(MAX_TIMESTEP):\n",
    "    output = machine_compute_step_t(False, R, layers, w, gates, timestep+1, desired_out, 1, *(output))\n",
    "    registers, memory_tape, cost_t, cum_prob_t, prob_incomplete = output    \n",
    "    print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "    print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "    print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "    print(\"cost = \", output[2].eval())\n",
    "    print(\"prob_incomplete = \", prob_incomplete.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('registers = ', array([[0, 0]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('registers: ', array([[[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.]]]))\n",
      "('registers[:,:,0]: ', array([[ 1.,  1.]]))\n",
      "('inputs: ', array([[[ 1.,  1.,  1.]]]))\n",
      "('compute layers inputs: ', array([[[ 1.98015717,  0.        ,  0.        ,  0.        ,  1.63459651,\n",
      "          1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 3.84822199,  0.21068969,  0.        ,  3.94564159,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(W)', array([[[ 4.11058133,  4.00697741, -1.31580737, -2.09189066, -0.43671963,\n",
      "         -1.6898004 , -0.9347702 , -1.40714312]]]))\n",
      "('inputs.dot(W)[0]', array([[ 4.11058133,  4.00697741, -1.31580737, -2.09189066, -0.43671963,\n",
      "        -1.6898004 , -0.9347702 , -1.40714312]]))\n",
      "('p_complete inputs: ', array([[[ 3.84822199,  0.21068969,  0.        ,  3.94564159,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(weight_matrix[-1]: ', array([[[-7.83295971]]]))\n",
      "('p_complete: ', array([[[ 0.00039629]]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[0, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.00532661,  0.99467339]]), ' weighted param [', 0, '] = ', 0)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[0, 0, 7]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[0, 0, 7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.32063514,  0.45826595,  0.22109891]]), ' weighted param [', 0, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[0, 0, 7, 1]]))\n",
      "('gate i = ', 2, 'arity:', 0, 'gate inputs: ', array([[0, 0, 7, 1]]))\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[0, 0, 7, 1, 0]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[0, 0, 7, 1, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.20682421,  0.19880734,  0.25651956,  0.16075332,  0.17709557]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.14304478,  0.16621693,  0.1534917 ,  0.14100404,  0.39624255]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[0, 0, 7, 1, 0, 1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[0, 0, 7, 1, 0, 1]]))\n",
      "('compute_gate_new: coeff', array([[ 0.31240067,  0.19908188,  0.21366727,  0.06180242,  0.13504129,\n",
      "         0.07800647]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.1012304 ,  0.28907089,  0.13634296,  0.11988433,  0.2185481 ,\n",
      "         0.13492331]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[0, 0, 7, 1, 0, 1, 0]]))\n",
      "('gate i = ', 5, 'arity:', 2, 'gate inputs: ', array([[0, 0, 7, 1, 0, 1, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.00140492,  0.00316337,  0.00136146,  0.00339213,  0.98618848,\n",
      "         0.00248214,  0.00200749]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[  7.92378546e-04,   5.05253210e-04,   9.95607065e-01,\n",
      "          8.85512421e-04,   4.82373960e-04,   8.62700430e-04,\n",
      "          8.64716870e-04]]), ' weighted param [', 1, '] = ', 7)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[0, 0, 7, 1, 0, 1, 0, 7]]))\n",
      "('register [', 0, ']  new value: reg_coef', 2, 'weighted_avg of gate inputs and reg_coef: ', 7)\n",
      "('register [', 1, ']  new value: reg_coef', 0, 'weighted_avg of gate inputs and reg_coef: ', 0)\n",
      "('loss ', array([-235.74065506]))\n",
      "('prob_complete_t', array([[[ 0.00039629]]]))\n",
      "('p_incomplete', array([[[ 0.99960371]]]))\n",
      "('prob_complete', array([[[ 0.00039629]]]))\n",
      "('cum_prob_t', array([[[ 0.00039629]]]))\n",
      "('cost_t*prob_complete', array([[[-0.09342243]]]))\n",
      "('cum_cost', array([[[ 0.09342243]]]))\n",
      "('registers = ', array([[7, 0]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.09342243]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99960371]]]))\n",
      "('registers: ', array([[[  3.73992375e-01,   6.03055733e-03,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   6.12763413e-01,   1.28381809e-03,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00],\n",
      "        [  9.91857769e-01,   1.34873169e-03,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   5.05821004e-03,   2.77637627e-04,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00]]]))\n",
      "('registers[:,:,0]: ', array([[ 0.37399238,  0.99185777]]))\n",
      "('inputs: ', array([[[ 0.37399238,  0.99185777,  1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 1.78778664,  0.        ,  0.        ,  0.        ,  1.62198301,\n",
      "          1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 3.64323797,  0.20030562,  0.        ,  3.74065757,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(W)', array([[[ 3.8999053 ,  3.8064486 , -1.24134809, -1.98722034, -0.41513958,\n",
      "         -1.60600554, -0.88123219, -1.33716769]]]))\n",
      "('inputs.dot(W)[0]', array([[ 3.8999053 ,  3.8064486 , -1.24134809, -1.98722034, -0.41513958,\n",
      "        -1.60600554, -0.88123219, -1.33716769]]))\n",
      "('p_complete inputs: ', array([[[ 3.64323797,  0.20030562,  0.        ,  3.74065757,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(weight_matrix[-1]: ', array([[[-7.44503755]]]))\n",
      "('p_complete: ', array([[[ 0.00058399]]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[7, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.00700187,  0.99299813]]), ' weighted param [', 0, '] = ', 0)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[7, 0, 7]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[7, 0, 7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.32126441,  0.45322649,  0.2255091 ]]), ' weighted param [', 0, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 1]]))\n",
      "('gate i = ', 2, 'arity:', 0, 'gate inputs: ', array([[7, 0, 7, 1]]))\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 1, 0]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[7, 0, 7, 1, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.20645429,  0.19894187,  0.25380748,  0.16261885,  0.17817752]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.14688518,  0.1683899 ,  0.15564776,  0.1441193 ,  0.38495786]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 1, 0, 1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[7, 0, 7, 1, 0, 1]]))\n",
      "('compute_gate_new: coeff', array([[ 0.3046057 ,  0.19877896,  0.21271786,  0.06538033,  0.13670822,\n",
      "         0.08180892]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.10428001,  0.28190856,  0.1382271 ,  0.12244495,  0.21607756,\n",
      "         0.13706182]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 1, 0, 1, 0]]))\n",
      "('gate i = ', 5, 'arity:', 2, 'gate inputs: ', array([[7, 0, 7, 1, 0, 1, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.00192077,  0.00416314,  0.00186793,  0.00448873,  0.98154248,\n",
      "         0.00330965,  0.00270731]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[  1.13227176e-03,   7.29808024e-04,   9.93766137e-01,\n",
      "          1.23296231e-03,   7.10111189e-04,   1.21663348e-03,\n",
      "          1.21207617e-03]]), ' weighted param [', 1, '] = ', 7)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 1, 0, 1, 0, 7]]))\n",
      "('register [', 0, ']  new value: reg_coef', 2, 'weighted_avg of gate inputs and reg_coef: ', 7)\n",
      "('register [', 1, ']  new value: reg_coef', 0, 'weighted_avg of gate inputs and reg_coef: ', 0)\n",
      "('loss ', array([-8.55429254]))\n",
      "('prob_complete_t', array([[[ 0.00058399]]]))\n",
      "('p_incomplete', array([[[ 0.99901995]]]))\n",
      "('prob_complete', array([[[ 0.00058376]]]))\n",
      "('cum_prob_t', array([[[ 0.00098005]]]))\n",
      "('cost_t*prob_complete', array([[[-0.00499367]]]))\n",
      "('cum_cost', array([[[ 0.0984161]]]))\n",
      "('registers = ', array([[7, 0]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.0984161]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99901995]]]))\n",
      "('registers: ', array([[[  1.81884423e-01,   9.58210101e-03,   2.20756229e-05,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   7.88799374e-01,   3.75223489e-03,\n",
      "           4.67320706e-06,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   5.57942469e-03,   1.51123743e-05,\n",
      "           0.00000000e+00],\n",
      "        [  6.63673633e-01,   5.28063009e-03,   5.22864528e-06,\n",
      "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   3.23836139e-01,   1.51164414e-03,\n",
      "           1.10685629e-06,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   6.15711696e-05,   3.57938913e-06,\n",
      "           0.00000000e+00]]]))\n",
      "('registers[:,:,0]: ', array([[ 0.18188442,  0.66367363]]))\n",
      "('inputs: ', array([[[ 0.18188442,  0.66367363,  1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 1.49738552,  0.        ,  0.        ,  0.        ,  1.41535849,\n",
      "          1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 3.14621231,  0.17606654,  0.        ,  3.24363192,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(W)', array([[[ 3.38912455,  3.32022508, -1.0608034 , -1.73342801, -0.3628047 ,\n",
      "         -1.40280941, -0.75146028, -1.16749416]]]))\n",
      "('inputs.dot(W)[0]', array([[ 3.38912455,  3.32022508, -1.0608034 , -1.73342801, -0.3628047 ,\n",
      "        -1.40280941, -0.75146028, -1.16749416]]))\n",
      "('p_complete inputs: ', array([[[ 3.14621231,  0.17606654,  0.        ,  3.24363192,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(weight_matrix[-1]: ', array([[[-6.5044746]]]))\n",
      "('p_complete: ', array([[[ 0.00149449]]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[7, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.01355362,  0.98644638]]), ' weighted param [', 0, '] = ', 0)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[7, 0, 7]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[7, 0, 7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.32259689,  0.4409763 ,  0.23642681]]), ' weighted param [', 0, '] = ', 7)\n",
      "('gate output: ', 8)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 8]]))\n",
      "('gate i = ', 2, 'arity:', 0, 'gate inputs: ', array([[7, 0, 7, 8]]))\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 8, 0]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[7, 0, 7, 8, 0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.2055158 ,  0.19921459,  0.24729274,  0.16719333,  0.18078354]]), ' weighted param [', 0, '] = ', 7)\n",
      "('compute_gate_new: coeff', array([[ 0.15626515,  0.17337956,  0.16064655,  0.15161353,  0.35809521]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 8, 0, 1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[7, 0, 7, 8, 0, 1]]))\n",
      "('compute_gate_new: coeff', array([[ 0.28576571,  0.19754232,  0.20987981,  0.07474638,  0.14048056,\n",
      "         0.09158522]]), ' weighted param [', 0, '] = ', 7)\n",
      "('compute_gate_new: coeff', array([[ 0.11186717,  0.26482054,  0.14266149,  0.12866458,  0.20983895,\n",
      "         0.14214728]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 8, 0, 1, 7]]))\n",
      "('gate i = ', 5, 'arity:', 2, 'gate inputs: ', array([[7, 0, 7, 8, 0, 1, 7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.00406916,  0.00804025,  0.00399087,  0.00878523,  0.96296831,\n",
      "         0.00659816,  0.00554802]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.00267984,  0.00177283,  0.98547382,  0.00274032,  0.00180642,\n",
      "         0.0027889 ,  0.00273786]]), ' weighted param [', 1, '] = ', 7)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[7, 0, 7, 8, 0, 1, 7, 7]]))\n",
      "('register [', 0, ']  new value: reg_coef', 2, 'weighted_avg of gate inputs and reg_coef: ', 7)\n",
      "('register [', 1, ']  new value: reg_coef', 0, 'weighted_avg of gate inputs and reg_coef: ', 7)\n",
      "('loss ', array([-2.20762817]))\n",
      "('prob_complete_t', array([[[ 0.00149449]]]))\n",
      "('p_incomplete', array([[[ 0.99752692]]]))\n",
      "('prob_complete', array([[[ 0.00149303]]]))\n",
      "('cum_prob_t', array([[[ 0.00247308]]]))\n",
      "('cost_t*prob_complete', array([[[-0.00329604]]]))\n",
      "('cum_cost', array([[[ 0.10171214]]]))\n",
      "('registers = ', array([[7, 7]]))\n",
      "('memory tape:  ', array([[ 7,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.10171214]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99752692]]]))\n",
      "('registers: ', array([[[  1.27357761e-01,   1.58081634e-02,   9.60027245e-05,\n",
      "           1.24138471e-07,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   6.36324911e-01,   9.15685707e-03,\n",
      "           3.07655863e-05,   2.55833898e-08,   7.72341523e-05,\n",
      "           5.59470674e-06,   1.91111492e-01,   9.78681096e-04,\n",
      "           8.27324272e-08],\n",
      "        [  4.13149063e-01,   9.90714072e-03,   3.92086962e-05,\n",
      "           3.68783286e-08,   0.00000000e+00,   0.00000000e+00,\n",
      "           0.00000000e+00,   5.53484062e-01,   4.57364307e-03,\n",
      "           1.14404357e-05,   7.60016335e-09,   1.72173370e-06,\n",
      "           2.31294239e-07,   7.03824993e-03,   2.98181165e-04,\n",
      "           2.45776641e-08]]]))\n",
      "('registers[:,:,0]: ', array([[ 0.12735776,  0.41314906]]))\n",
      "('inputs: ', array([[[ 0.12735776,  0.41314906,  1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 1.30316086,  0.        ,  0.        ,  0.        ,  1.25873862,\n",
      "          1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 2.79536779,  0.1590139 ,  0.        ,  2.89278739,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(W)', array([[[ 3.0285733 ,  2.97700563, -0.93335887, -1.55427915, -0.32586154,\n",
      "         -1.25937454, -0.65985839, -1.04772339]]]))\n",
      "('inputs.dot(W)[0]', array([[ 3.0285733 ,  2.97700563, -0.93335887, -1.55427915, -0.32586154,\n",
      "        -1.25937454, -0.65985839, -1.04772339]]))\n",
      "('p_complete inputs: ', array([[[ 2.79536779,  0.1590139 ,  0.        ,  2.89278739,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(weight_matrix[-1]: ', array([[[-5.84054441]]]))\n",
      "('p_complete: ', array([[[ 0.00289883]]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[7, 7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.02152957,  0.97847043]]), ' weighted param [', 0, '] = ', 7)\n",
      "('gate output: ', 13)\n",
      "('concatenated inputs: ', array([[ 7,  7, 13]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[ 7,  7, 13]]))\n",
      "('compute_gate_new: coeff', array([[ 0.32337241,  0.4323045 ,  0.24432309]]), ' weighted param [', 0, '] = ', 7)\n",
      "('gate output: ', 8)\n",
      "('concatenated inputs: ', array([[ 7,  7, 13,  8]]))\n",
      "('gate i = ', 2, 'arity:', 0, 'gate inputs: ', array([[ 7,  7, 13,  8]]))\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[ 7,  7, 13,  8,  0]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[ 7,  7, 13,  8,  0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.20481443,  0.1993663 ,  0.24274563,  0.17046495,  0.18260869]]), ' weighted param [', 0, '] = ', 7)\n",
      "('compute_gate_new: coeff', array([[ 0.16293248,  0.17665232,  0.16395847,  0.15683685,  0.33961988]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[ 7,  7, 13,  8,  0,  1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[ 7,  7, 13,  8,  0,  1]]))\n",
      "('compute_gate_new: coeff', array([[ 0.27254891,  0.19622526,  0.20742383,  0.08196713,  0.14287934,\n",
      "         0.09895553]]), ' weighted param [', 0, '] = ', 7)\n",
      "('compute_gate_new: coeff', array([[ 0.11738204,  0.25301801,  0.14566531,  0.13305086,  0.20524523,\n",
      "         0.14563856]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 7)\n",
      "('concatenated inputs: ', array([[ 7,  7, 13,  8,  0,  1,  7]]))\n",
      "('gate i = ', 5, 'arity:', 2, 'gate inputs: ', array([[ 7,  7, 13,  8,  0,  1,  7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.00683979,  0.01266024,  0.00674841,  0.01396393,  0.94005314,\n",
      "         0.01062508,  0.0091094 ]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.00489313,  0.00329701,  0.97373722,  0.00478634,  0.0034707 ,\n",
      "         0.00497862,  0.00483699]]), ' weighted param [', 1, '] = ', 13)\n",
      "('gate output: ', 13)\n",
      "('concatenated inputs: ', array([[ 7,  7, 13,  8,  0,  1,  7, 13]]))\n",
      "('register [', 0, ']  new value: reg_coef', 2, 'weighted_avg of gate inputs and reg_coef: ', 13)\n",
      "('register [', 1, ']  new value: reg_coef', 0, 'weighted_avg of gate inputs and reg_coef: ', 7)\n",
      "('loss ', array([-0.82780897]))\n",
      "('prob_complete_t', array([[[ 0.00289883]]]))\n",
      "('p_incomplete', array([[[ 0.99463526]]]))\n",
      "('prob_complete', array([[[ 0.00289166]]]))\n",
      "('cum_prob_t', array([[[ 0.00536474]]]))\n",
      "('cost_t*prob_complete', array([[[-0.00239374]]]))\n",
      "('cum_cost', array([[[ 0.10410589]]]))\n",
      "('registers = ', array([[13,  7]]))\n",
      "('memory tape:  ', array([[13,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.10410589]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99463526]]]))\n",
      "('registers: ', array([[[  1.10867896e-01,   2.28915378e-02,   2.62182022e-04,\n",
      "           2.76464600e-06,   3.58702577e-08,   1.61567406e-10,\n",
      "           0.00000000e+00,   3.82207265e-01,   1.52591768e-02,\n",
      "           1.22215017e-04,   2.76948913e-07,   5.97831596e-03,\n",
      "           2.40676221e-04,   4.27665635e-01,   4.31735885e-03,\n",
      "           8.03300552e-06],\n",
      "        [  2.71244663e-01,   1.61638365e-02,   1.41313956e-04,\n",
      "           4.62290399e-07,   6.00188784e-09,   5.65679723e-11,\n",
      "           0.00000000e+00,   5.70252960e-01,   9.74144098e-03,\n",
      "           5.88315334e-05,   1.09468230e-07,   2.55694066e-04,\n",
      "           2.61141453e-05,   1.09586612e-01,   1.99313956e-03,\n",
      "           2.85294777e-06]]]))\n",
      "('registers[:,:,0]: ', array([[ 0.1108679 ,  0.27124466]]))\n",
      "('inputs: ', array([[[ 0.1108679 ,  0.27124466,  1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 1.19743709,  0.        ,  0.        ,  0.        ,  1.17019807,\n",
      "          1.        ]]]))\n",
      "('compute layers inputs: ', array([[[ 2.60110347,  0.14958147,  0.        ,  2.69852307,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(W)', array([[[ 2.8289348 ,  2.78696335, -0.86279218, -1.45508358, -0.30540583,\n",
      "         -1.17995377, -0.60913841, -0.9814057 ]]]))\n",
      "('inputs.dot(W)[0]', array([[ 2.8289348 ,  2.78696335, -0.86279218, -1.45508358, -0.30540583,\n",
      "        -1.17995377, -0.60913841, -0.9814057 ]]))\n",
      "('p_complete inputs: ', array([[[ 2.60110347,  0.14958147,  0.        ,  2.69852307,  0.        ,\n",
      "          1.        ]]]))\n",
      "('inputs.dot(weight_matrix[-1]: ', array([[[-5.47292338]]]))\n",
      "('p_complete: ', array([[[ 0.00418138]]]))\n",
      "('gate i = ', 0, 'arity:', 1, 'gate inputs: ', array([[13,  7]]))\n",
      "('compute_gate_new: coeff', array([[ 0.0277648,  0.9722352]]), ' weighted param [', 0, '] = ', 7)\n",
      "('gate output: ', 13)\n",
      "('concatenated inputs: ', array([[13,  7, 13]]))\n",
      "('gate i = ', 1, 'arity:', 1, 'gate inputs: ', array([[13,  7, 13]]))\n",
      "('compute_gate_new: coeff', array([[ 0.32374196,  0.42749646,  0.24876158]]), ' weighted param [', 0, '] = ', 7)\n",
      "('gate output: ', 8)\n",
      "('concatenated inputs: ', array([[13,  7, 13,  8]]))\n",
      "('gate i = ', 2, 'arity:', 0, 'gate inputs: ', array([[13,  7, 13,  8]]))\n",
      "('gate output: ', 0)\n",
      "('concatenated inputs: ', array([[13,  7, 13,  8,  0]]))\n",
      "('gate i = ', 3, 'arity:', 2, 'gate inputs: ', array([[13,  7, 13,  8,  0]]))\n",
      "('compute_gate_new: coeff', array([[ 0.20441234,  0.19943582,  0.24024653,  0.17229144,  0.18361386]]), ' weighted param [', 0, '] = ', 13)\n",
      "('compute_gate_new: coeff', array([[ 0.16663447,  0.17837187,  0.16571106,  0.1596994 ,  0.3295832 ]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 1)\n",
      "('concatenated inputs: ', array([[13,  7, 13,  8,  0,  1]]))\n",
      "('gate i = ', 4, 'arity:', 2, 'gate inputs: ', array([[13,  7, 13,  8,  0,  1]]))\n",
      "('compute_gate_new: coeff', array([[ 0.26527089,  0.19533446,  0.20590188,  0.0861882 ,  0.1441032 ,\n",
      "         0.10320136]]), ' weighted param [', 0, '] = ', 13)\n",
      "('compute_gate_new: coeff', array([[ 0.12048965,  0.24658368,  0.1472798 ,  0.13547379,  0.20264062,\n",
      "         0.14753246]]), ' weighted param [', 1, '] = ', 0)\n",
      "('gate output: ', 13)\n",
      "('concatenated inputs: ', array([[13,  7, 13,  8,  0,  1, 13]]))\n",
      "('gate i = ', 5, 'arity:', 2, 'gate inputs: ', array([[13,  7, 13,  8,  0,  1, 13]]))\n",
      "('compute_gate_new: coeff', array([[ 0.0090651 ,  0.01618324,  0.00897364,  0.01794286,  0.92216639,\n",
      "         0.01375141,  0.01191735]]), ' weighted param [', 0, '] = ', 0)\n",
      "('compute_gate_new: coeff', array([[ 0.00680354,  0.00463108,  0.96366782,  0.0064935 ,  0.00496378,\n",
      "         0.00683643,  0.00660385]]), ' weighted param [', 1, '] = ', 13)\n",
      "('gate output: ', 13)\n",
      "('concatenated inputs: ', array([[13,  7, 13,  8,  0,  1, 13, 13]]))\n",
      "('register [', 0, ']  new value: reg_coef', 2, 'weighted_avg of gate inputs and reg_coef: ', 13)\n",
      "('register [', 1, ']  new value: reg_coef', 0, 'weighted_avg of gate inputs and reg_coef: ', 7)\n",
      "('loss ', array([-0.63398834]))\n",
      "('prob_complete_t', array([[[ 0.00418138]]]))\n",
      "('p_incomplete', array([[[ 0.99047631]]]))\n",
      "('prob_complete', array([[[ 0.99463526]]]))\n",
      "('cum_prob_t', array([[[ 1.]]]))\n",
      "('cost_t*prob_complete', array([[[-0.63058715]]]))\n",
      "('cum_cost', array([[[ 0.73469304]]]))\n",
      "('registers = ', array([[13,  7]]))\n",
      "('memory tape:  ', array([[13,  1, 12,  4,  7, 12,  1, 13,  8,  2,  1,  3, 11, 11, 12,  0]]))\n",
      "('desired tape: ', array([[13]]))\n",
      "('cost = ', array([[[ 0.73469304]]]))\n",
      "('prob_incomplete = ', array([[[ 0.99047631]]]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "v0 = as_tensor(0)\n",
    "v1 = as_tensor(1)\n",
    "output = [registers, memory_tape, v0, v0, v1]\n",
    "new_registers = []\n",
    "print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "for timestep in range(MAX_TIMESTEP):\n",
    "    output = machine_compute_step_t(True, R, layers, w, gates, timestep+1, desired_out, 1, *(output))\n",
    "    registers, memory_tape, cost_t, cum_prob_t, prob_incomplete = output    \n",
    "    print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "    print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "    print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "    print(\"cost = \", output[2].eval())\n",
    "    print(\"prob_incomplete = \", prob_incomplete.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": "6",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
