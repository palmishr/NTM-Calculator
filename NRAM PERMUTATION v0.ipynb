{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "READ (described in Sec. 3.2),\n",
    "WRITE (described in Sec. 3.2).\n",
    "\n",
    "ZERO(a, b) = 0, \n",
    "ONE(a, b) = 1, \n",
    "TWO(a, b) = 2, \n",
    "\n",
    "INC(a, b) = (a+1) mod M, \n",
    "ADD(a, b) = (a+b) mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = mod M, \n",
    "SUB(a, b) = (a−b) mod M, \n",
    "DEC(a, b) = (a−1) mod M, \n",
    "LESS-THAN(a, b) = [a < b], \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n",
    "LESS-OR-EQUAL-THAN(a, b) = [a ≤ b], \n",
    "EQUALITY-TEST(a, b) = [a = b], \n",
    "MIN(a, b) = min(a, b), \n",
    "MAX(a, b) = max(a, b), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "from theano import tensor\n",
    "from collections import namedtuple\n",
    "from theano.tensor.extra_ops import to_one_hot\n",
    "from theano.tensor import roll\n",
    "from theano.tensor import stack\n",
    "from theano.tensor import batched_dot\n",
    "from theano.tensor import concatenate\n",
    "from theano.tensor import as_tensor\n",
    "from theano.tensor import set_subtensor\n",
    "from theano import shared\n",
    "from numpy.random import uniform\n",
    "from theano.tensor.nnet import softmax, relu, sigmoid\n",
    "from theano import function, config, shared, sandbox, Out\n",
    "\n",
    "def zero() :\n",
    "    return to_one_hot(np.asarray([0]),M)\n",
    "def one() :\n",
    "    return to_one_hot(np.asarray([1]),M)\n",
    "def two() :\n",
    "    return to_one_hot(np.asarray([2]),M)\n",
    "def get_const(value) :\n",
    "    return to_one_hot(np.asarray([value % M]),M)\n",
    "def create_memory_tape(init_val=0):\n",
    "    m = stack([get_const(init_val) for i in range(M)], axis=1)\n",
    "    #return shared(np.asarray(m.eval()), config.floatX) \n",
    "    return m\n",
    "def inc(a) :\n",
    "    return roll(a, 1, axis=1)\n",
    "def negate(a) :\n",
    "    return roll(a[:, ::-1], 1, axis=1)\n",
    "def add(a,b) :\n",
    "    rows = [roll(b[:,], j, axis=1) for j in range(M)]\n",
    "    return (batched_dot(a, stack(rows, axis=1)))\n",
    "def sub(a,b) :\n",
    "    b_negative = negate(b)\n",
    "    return add(a, b_negative)\n",
    "def eq_zero(a) :\n",
    "    r = tensor.zeros_like(as_tensor(a))\n",
    "    r = set_subtensor(r[:,1], a[:, 0])\n",
    "    r = set_subtensor(r[:, 0], 1 - a[:, 0])\n",
    "    return r\n",
    "def lt(a,b):\n",
    "    a = as_tensor(a)\n",
    "    b = as_tensor(b)\n",
    "    b = set_subtensor(b[:,0], [0]) \n",
    "    b = roll(b[:,], -1, axis=1)\n",
    "    rows = [set_subtensor(tensor.zeros_like(as_tensor(b))[:,j:M], b[:,j:M]) for j in range(M)]\n",
    "    result = ((tensor.dot(as_tensor(a), stack(rows, axis =1))).sum()).dimshuffle('x')\n",
    "    return set_subtensor(tensor.zeros_like(as_tensor(b))[:,1], result)\n",
    "def eq(a,b):\n",
    "    elemwise_result = tensor.eq(as_tensor(a),as_tensor(b))\n",
    "    sum = elemwise_result.sum()\n",
    "    result = tensor.eq(sum,M).dimshuffle('x')\n",
    "    return set_subtensor(tensor.zeros_like(as_tensor(a))[:,1], result)\n",
    "def max_(a,b):\n",
    "    if(tensor.eq([0],lt(a,b))):\n",
    "        return as_tensor(b)\n",
    "    else:\n",
    "        return as_tensor(a)\n",
    "def min_(a,b):\n",
    "    if(tensor.eq([1],lt(a,b))):\n",
    "        return as_tensor(a)\n",
    "    else:\n",
    "        return as_tensor(b)    \n",
    "def read(mem, a) :\n",
    "    ptr = as_tensor(a)\n",
    "    return weighted_avg(mem, ptr), mem\n",
    "def write(mem, a, b) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    mem = (x + y)\n",
    "    return val, mem\n",
    "def write_external(a, b, ext_mem) :\n",
    "    ptr = as_tensor(a)\n",
    "    val = as_tensor(b)\n",
    "    J = (tensor.ones_like(zero())).T\n",
    "    erase_vector = (J-ptr.T).dot(J.T)\n",
    "    x = tensor.mul(erase_vector, ext_mem)\n",
    "    y = (ptr.T).dot(val)\n",
    "    ext_mem = (x + y)\n",
    "    return ext_mem\n",
    "\n",
    "def get_registers(init_val):\n",
    "    return stack([get_const(init_val) for i in range(R)], axis=1)\n",
    "\n",
    "def weighted_avg(inputs, coefficient) :\n",
    "    return batched_dot(inputs.transpose(0, 2, 1), coefficient.dimshuffle(0, 1, 'x')).flatten(2);\n",
    "\n",
    "def compute_gate_new(module, inputs, coefficients, memory_tape, debug=False) :\n",
    "    \"\"\" Arity of this gate must be equal to the number of given\n",
    "        coefficients list\n",
    "    \"\"\" \n",
    "    if (len(coefficients) != module.arity) :\n",
    "        print(\"Error: Incorrect number of coefficients: \",  len(coefficients), \" to module arity: \", module.arity)\n",
    "    \n",
    "    params = [weighted_avg(inputs, as_tensor(coef)) for coef in coefficients]\n",
    "    \n",
    "    if (debug == True):\n",
    "        for i, p in enumerate(params):\n",
    "            print(\"compute_gate_new: coeff\", coefficients[i].eval(), \" weighted param [\", i ,\"] = \", p.eval().argmax())\n",
    "    \n",
    "    if (module.memory_function == True) :\n",
    "        #print(\"read/write \")\n",
    "        output, memory_tape = module.function(memory_tape, *params)\n",
    "    else :   \n",
    "        output = module.function(*params)\n",
    "    \n",
    "    #error check for constant gates\n",
    "    return output, memory_tape\n",
    "\n",
    "\n",
    "def get_n_tensor(t, count, idx):\n",
    "    result=[]\n",
    "    if count > 0: \n",
    "        result = [t[idx+i] for i in range(count)]\n",
    "    return result, (idx+count)\n",
    "\n",
    "def fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug=False):\n",
    "    # Initially, only the registers may be used as inputs.\n",
    "    Q= len(gates)\n",
    "    gate_inputs = registers\n",
    "    idx=0    \n",
    "    \n",
    "    # Run through all the gates.\n",
    "    for i in range(Q):\n",
    "        c, idx = get_n_tensor(gate_coef, gates[i].arity, idx) \n",
    "        if (debug==True):\n",
    "            print(\"gate i = \", i, \"arity:\", gates[i].arity, \"gate inputs: \", gate_inputs.eval().argmax(axis=2))\n",
    "        output, memory_tape = compute_gate_new(gates[i], gate_inputs, c, memory_tape, debug)\n",
    "        # Append the output of the gate as an input for future gates.\n",
    "        gate_inputs = concatenate([gate_inputs, output.dimshuffle(0,'x',1)], axis=1)\n",
    "        if (debug==True):\n",
    "            print(\"gate output: \", output.eval().argmax())    \n",
    "            print(\"concatenated inputs: \", gate_inputs.eval().argmax(axis=2))       \n",
    "        \n",
    "    # All leftover coefficients are for registers.\n",
    "    new_registers = []\n",
    "             \n",
    "    for i in range(len(reg_coef)):\n",
    "        # (R+Q) x M dot 1 X (R+Q) \n",
    "        new_registers.append(weighted_avg(gate_inputs, reg_coef[i]))\n",
    "        if (debug == True) :\n",
    "            print(\"register [\", i, \"]  new value: reg_coef\", reg_coef[i].eval().argmax(),\"weighted_avg of gate inputs and reg_coef: \", weighted_avg(gate_inputs, reg_coef[i]).eval().argmax())\n",
    "    return tensor.stack(new_registers, axis=1), memory_tape\n",
    "\n",
    "\n",
    "# coefficients = [r1,r2..rR,g1_param1,g1_param2,...,gQ_param1,gQ_param2,c1,c1..CR,cR+1,..cR+Q]\n",
    "def gen_random_weights(layer1, layer2, dtype=np.float64, _min=-1, _max=1):\n",
    "    weights = uniform(low=_min, high=_max, size=(layer1, layer2))\n",
    "    var = shared(weights.astype(dtype), name=\"w{0}x{1}\".format(layer1, layer2))   \n",
    "    #var = tensor.addbroadcast(var, 0)\n",
    "    return var\n",
    "\n",
    "def gen_network_weights(gates, layers):\n",
    "    n_registers = R #input is R registers\n",
    "    w = []\n",
    "    current_layer_units = n_registers\n",
    "    for next_layer_units in layers:\n",
    "        w.append(gen_random_weights(current_layer_units + 1, next_layer_units))\n",
    "        current_layer_units = next_layer_units\n",
    "    #output wt for gate coefficients\n",
    "    gate_coef = []\n",
    "    for i, gate in enumerate(gates):\n",
    "        print(i, gate)\n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            gate_coef.append(gen_random_weights(current_layer_units + 1, gate_output_units))            \n",
    "    \n",
    "    #print(\"gen_network_weights => gate_coef\", gate_coef)         \n",
    "    #output wt for new registers\n",
    "    reg_coef = []\n",
    "    reg_output_units = n_registers + len(gates)\n",
    "    for _ in range(n_registers):\n",
    "        reg_coef.append(gen_random_weights(current_layer_units + 1, n_registers + len(gates)))    \n",
    "    \n",
    "    #print(\"gen_network_weights => reg_coef\", reg_coef)      \n",
    "    prob_completion_coef = (gen_random_weights(current_layer_units + 1, 1))\n",
    "\n",
    "    for i in gate_coef:\n",
    "        w.append(i)\n",
    "\n",
    "    for x in reg_coef:\n",
    "        w.append(x)\n",
    "    \n",
    "    w.append(prob_completion_coef)   \n",
    "    return w\n",
    "\n",
    "def aug_ones_col(inputs):\n",
    "    print(\"OMFG\")\n",
    "    s = inputs.shape\n",
    "    col_elems = s[1]\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), col_elems))\n",
    "    x = concatenate([inputs.T,ones], axis=1)\n",
    "    return x.T\n",
    "\n",
    "def aug_ones_col_new(inputs):\n",
    "    x=[]\n",
    "    s = inputs.shape\n",
    "    d = inputs.ndim\n",
    "    row_elems = s[d-2]\n",
    "    matrix = tensor.reshape(inputs, (s[d-2],s[d-1]))\n",
    "    matrix = tensor.shape_padleft(matrix)\n",
    "    ones = tensor.ones_like(to_one_hot(np.asarray([0]), row_elems))\n",
    "    x = concatenate([matrix.dimshuffle(0,2,1),ones.dimshuffle(0,'x',1)], axis=1)\n",
    "    return x.dimshuffle(0,2,1)\n",
    "\n",
    "def controller_forward_prop(n_registers, layers, weight_matrix, gates, registers, debug) :\n",
    "    inputs = aug_ones_col_new(registers[:,:,0])\n",
    "    if (debug == True):\n",
    "        #print(\"registers: \", registers.eval())\n",
    "        #print(\"registers[:,:,0]: \", registers[:,:,0].eval())\n",
    "        print(\"inputs: \", inputs.eval())\n",
    "        \n",
    "    for i in range(len(layers)):\n",
    "        W = weight_matrix[i]\n",
    "        inputs = aug_ones_col_new(relu(inputs.dot(W)))  \n",
    "        if (debug == True):\n",
    "            print(\"compute layers inputs: \", inputs.eval())\n",
    "    \n",
    "    #extract gate coefficients\n",
    "    gate_coef = []\n",
    "    n_gate_coef = 0\n",
    "    \n",
    "    for i, gate in enumerate(gates): \n",
    "        #each param to gates are R+i depending on arity \n",
    "        gate_output_units = n_registers + i\n",
    "        for _ in range(gate.arity):\n",
    "            n_gate_coef += 1  \n",
    "            \n",
    "    for W in weight_matrix[len(layers):len(layers) + n_gate_coef]:\n",
    "        gate_coef.append(softmax(inputs.dot(W)[0]))            \n",
    "    \n",
    "    reg_coef = []\n",
    "    for W in (weight_matrix[len(layers)+n_gate_coef:len(layers)+n_gate_coef+n_registers]):\n",
    "        reg_coef.append(softmax(inputs.dot(W)[0]))  \n",
    "    \n",
    "    if (debug == True):\n",
    "        #print(\"inputs.dot(W)\", inputs.dot(W).eval())\n",
    "        #print(\"inputs.dot(W)[0]\", inputs.dot(W)[0].eval())\n",
    "        #print(\"p_complete inputs: \", inputs.eval())\n",
    "        print(\"inputs.dot(weight_matrix[-1]: \", inputs.dot(weight_matrix[-1]).eval())  \n",
    "              \n",
    "    p = sigmoid((inputs.dot(weight_matrix[-1])))\n",
    "    if (debug == True):\n",
    "        print(\"p_complete: \", p.eval())\n",
    "        \n",
    "    return p, reg_coef, gate_coef\n",
    "\n",
    "def calculate_cost_at_t(prob_complete_t, t, cum_error, cum_cost, cum_prob_t, p_incomplete, memory_in, desired_output, output_len, debug) :\n",
    "    e_min = 1e-100\n",
    "    e_max = 1e+100\n",
    "    cost_t = 0\n",
    "    entropy = 0\n",
    "    #TODO: Find use for desired registers in calculating cost. Now, only desired memory layout is matched.\n",
    "    for i in range(output_len):\n",
    "        #Compute the loss for this register using the mask.\n",
    "        y = to_one_hot(desired_output.argmax(axis=2)[:,i], M)   \n",
    "        y_hat = to_one_hot(memory_in.argmax(axis=2)[:,i], M) \n",
    "        ln_y_hat = tensor.log(tensor.clip(memory_in[:, i, :], e_min, e_max))\n",
    "        ln_1_minus_y_hat = tensor.log(tensor.clip(1 - memory_in[:, i, :], e_min, e_max))\n",
    "        x1 = y * ln_y_hat\n",
    "        x2 = (1 - y) * ln_1_minus_y_hat\n",
    "        loss = (x1+x2).sum(axis=1) \n",
    "        cost_t += tensor.shape_padright(loss, 1)\n",
    "        entropy += ((memory_in[:, i, :]) * ln_y_hat).sum(axis=1)\n",
    "        if (debug == True):\n",
    "            #print(\"desired_output at i\", desired_output[:,i].eval())\n",
    "            #print(\"memory value at i\", memory_in[:, i, :].eval())\n",
    "            #print(\"y \", y.eval())\n",
    "            #print(\"y_hat \", y_hat.eval())\n",
    "            #print(\"ln_y_hat \", ln_y_hat.eval())\n",
    "            #print(\"ln_1_minus_y_hat \", ln_1_minus_y_hat.eval())\n",
    "            #print(\"x1 \", x1.eval())\n",
    "            #print(\"x2 \", x2.eval())\n",
    "            print(\"loss \", loss.eval())\n",
    "            print(\"cost_t \", cost_t.eval())\n",
    "            print(\"entropy \", entropy.eval())\n",
    "            #print(\"tensor.shape_padright(loss, 1) \", tensor.shape_padright(loss, 1).eval())\n",
    "            #print(\"Desired value at mem location [\", i, \"] is \", y.eval().argmax(), \"but actual value is [\", memory_in[:,i,:].eval().argmax(), \"loss is \", loss.eval(), \" cost = \", cost_t.eval()) \n",
    "    \n",
    "    if (t == MAX_TIMESTEP):\n",
    "        prob_complete = 1 - cum_prob_t\n",
    "        #penalize cost if execution not over (cost_t should be zero)\n",
    "        cum_cost = cum_cost - cum_error*cost_t\n",
    "    else:\n",
    "        prob_complete = (prob_complete_t * p_incomplete)\n",
    "    \n",
    "    cum_prob_t += prob_complete\n",
    "    p_incomplete *= (1 - prob_complete_t)\n",
    "    cum_cost -= (cost_t*prob_complete)\n",
    "    cum_cost -= entropy * (1/(1 + t)**0.55)\n",
    "    cum_error = cum_error - cost_t\n",
    "    \n",
    "    if (debug == True):\n",
    "        print(\"prob_complete_t\", prob_complete_t.eval())\n",
    "        print(\"p_incomplete\", p_incomplete.eval())\n",
    "        print(\"prob_complete\", prob_complete.eval())\n",
    "        print(\"cum_prob_t\", cum_prob_t.eval())\n",
    "        print(\"cost_t*prob_complete\", (cost_t*prob_complete).eval())\n",
    "        print(\"cum_cost\", cum_cost.eval())\n",
    "        print(\"cum_error\", cum_error.eval())\n",
    "    return cum_error, cum_cost, cum_prob_t, p_incomplete\n",
    "\n",
    "def machine_compute_step_t(debug, R, layers, w, gates, t, desired_output, output_len, registers, memory_tape, cum_error, cost_t, cum_prob, prob_incomplete) : \n",
    "    prob_complete_t, reg_coef, gate_coef = controller_forward_prop(R, layers, w, gates, registers, debug)\n",
    "    new_registers, new_memory_tape = fuzzy_circuit(registers, gates, memory_tape, gate_coef, reg_coef, debug)\n",
    "    cum_error, cost_t, cum_prob_t, prob_incomplete = calculate_cost_at_t(prob_complete_t, t, cum_error, cost_t,  cum_prob, prob_incomplete, new_memory_tape, desired_output, output_len, debug)\n",
    "    return new_registers, new_memory_tape, cum_error, cost_t, cum_prob_t, prob_incomplete\n",
    "\n",
    "def compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len):\n",
    "    #w = make_broadcastable(w)\n",
    "    # Create symbolic variables for the input to the machine\n",
    "    # and for the desired output of the machine.\n",
    "      \n",
    "    #initial_registers = registers\n",
    "    #desired_output = memory_tape\n",
    "\n",
    "    initial_registers = tensor.dtensor3(\"Registers\")\n",
    "    initial_memory = tensor.dtensor3(\"Memory_Tape\")\n",
    "    desired_output = tensor.dtensor3(\"Y\")\n",
    "     \n",
    "    \n",
    "    # Run the model for all timesteps. The arguments are \n",
    "    # registers, cost, cumulative probability complete, \n",
    "    # and probability incomplete. The latter are initialized\n",
    "    # to zero and to one, respectively.\n",
    "    \n",
    "    v0 = as_tensor(0)\n",
    "    v1 = as_tensor(1)\n",
    "    output = [initial_registers, initial_memory, v0, v0, v0, v1]\n",
    "    intermediate_registers = []\n",
    "    for timestep in range(MAX_TIMESTEP):\n",
    "        print(\"compute_all_timesteps t = \", timestep)\n",
    "        output = machine_compute_step_t(False, R, layers, w, gates, timestep+1, desired_output, output_len, *(output))\n",
    "        intermediate_registers.append(output[0])\n",
    "\n",
    "    # Add in regularization, to avoid overfitting simple examples.\n",
    "    reg_cost = reg_lambda * sum((p * p).sum() for p in list(w))\n",
    "    \n",
    "    # Get the final cost: regularization plus loss.\n",
    "    final_cost = reg_cost + output[3].sum()\n",
    "    \n",
    "    # Return the symbolic variables, the final cost, and the\n",
    "    # intermediate register values for analysis and prediction.\n",
    "    return initial_registers, initial_memory, desired_output, final_cost, intermediate_registers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Module(arity=1, function=<function read at 0x106cc5758>, memory_function=True))\n",
      "(1, Module(arity=1, function=<function inc at 0x106cc5320>, memory_function=False))\n",
      "(2, Module(arity=2, function=<function add at 0x106cc5410>, memory_function=False))\n",
      "(3, Module(arity=2, function=<function min_ at 0x106cc56e0>, memory_function=False))\n",
      "(4, Module(arity=2, function=<function write at 0x106cc57d0>, memory_function=True))\n",
      "('weight matrix: ', [w6x5, w6x5, w6x5, w6x6, w6x7, w6x7, w6x8, w6x8, w6x9, w6x9, w6x10, w6x10, w6x10, w6x10, w6x10, w6x1])\n"
     ]
    }
   ],
   "source": [
    "#Maximum Representable Integer M is set below\n",
    "M = 16\n",
    "# Number of registers\n",
    "R = 5\n",
    "#Max number of timesteps\n",
    "MAX_TIMESTEP = 15\n",
    "\n",
    "Module = namedtuple(\"Module\", \"arity function memory_function\")\n",
    "\n",
    "m_zero = Module(0, zero, False)\n",
    "m_one = Module(0, one, False)\n",
    "m_two = Module(0, two, False)\n",
    "m_inc = Module(1, inc, False)\n",
    "m_negate = Module(1, negate, False)\n",
    "m_add = Module(2, add, False)\n",
    "m_sub = Module(2, sub, False)\n",
    "m_eq_zero = Module(1, eq_zero, False)\n",
    "m_read = Module(1, read, True)\n",
    "m_write = Module(2, write, True)\n",
    "m_lt = Module(2, lt, False)\n",
    "m_eq = Module(2, eq, False)\n",
    "m_min = Module(2, min_, False)\n",
    "m_max = Module(2, max_, False)\n",
    "\n",
    "gates = [m_read, m_inc, m_add, m_min, m_write]\n",
    "#gates = [m_read, m_write]\n",
    "N = len(gates)\n",
    "\n",
    "registers = get_registers(1)\n",
    "memory_tape = create_memory_tape()\n",
    "desired_out = create_memory_tape(0)\n",
    "for i in range(M):\n",
    "     desired_out = write_external(get_const(i), get_const(i), desired_out)\n",
    "        \n",
    "layers = [5,5]\n",
    "w = gen_network_weights(gates, layers)\n",
    "print(\"weight matrix: \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('compute_all_timesteps t = ', 0)\n",
      "('compute_all_timesteps t = ', 1)\n",
      "('compute_all_timesteps t = ', 2)\n",
      "('compute_all_timesteps t = ', 3)\n",
      "('compute_all_timesteps t = ', 4)\n",
      "('compute_all_timesteps t = ', 5)\n",
      "('compute_all_timesteps t = ', 6)\n",
      "('compute_all_timesteps t = ', 7)\n",
      "('compute_all_timesteps t = ', 8)\n",
      "('compute_all_timesteps t = ', 9)\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "output_len = 5\n",
    "result  = compute_all_timesteps(gates, layers, registers, memory_tape, w, reg_lambda, output_len)\n",
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Registers,\n",
       " Memory_Tape,\n",
       " Y,\n",
       " Elemwise{add,no_inplace}.0,\n",
       " [Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0,\n",
       "  Join.0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_registers, initial_memory, desired_output, final_cost, intermediate_registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradients = theano.grad(final_cost, list(w)) #, disconnected_inputs='warn', return_disconnected='Disconnected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(gradients)):\n",
    "    theano.gradient.grad_clip(gradients[i], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training took', 471.1658170223236, 'seconds')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()  \n",
    "# Compile training function to compute gradients.\n",
    "train = theano.function([initial_registers, initial_memory, desired_output], [final_cost] + gradients) #, on_unused_input='ignore', allow_input_downcast=True)\n",
    "t1 = time.time()  \n",
    "print (\"Training took\", t1 - t0, \"seconds\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Access Task\n",
    "input = [ 7,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "output = [ 13 ]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Permutation Task\n",
    "input = [ 6,  1,  3,  2,  5,  4,  9,  13,  8,  2, 1, 0, 0, 0, 0, 0]\n",
    "output = [ 9, 8, 13, 1, 2]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('desired_out.eval()', array([[ 9,  8, 13,  1,  2]]))\n",
      "('memory_tape.eval()', array([[ 6,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('registers.eval()', array([[0, 0, 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print (\"desired_out.eval()\", desired_out.eval().argmax(axis=2))\n",
    "print (\"memory_tape.eval()\", memory_tape.eval().argmax(axis=2))\n",
    "print (\"registers.eval()\", registers.eval().argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(32566.870061579906), array([[  1.56772140e-02,   4.68593674e-03,   8.11880607e-02,\n",
      "          2.34807082e+02,   6.62956322e-03],\n",
      "       [  1.89930322e-01,  -1.21110046e-01,  -1.10753222e-01,\n",
      "          2.35082040e+02,   5.00692735e-02],\n",
      "       [ -1.99829372e-01,  -5.11300890e-02,  -1.61575687e-01,\n",
      "          2.35018937e+02,  -1.73288272e-01],\n",
      "       [ -1.50021053e-01,   3.83501191e-02,  -7.81398272e-02,\n",
      "          2.35052690e+02,   8.07285554e-02],\n",
      "       [  8.08193604e-02,   1.88556788e-01,   1.36148384e-01,\n",
      "          2.34942764e+02,  -1.58006263e-01],\n",
      "       [ -1.72135284e-01,  -1.07849495e-01,  -1.42119016e-01,\n",
      "          2.34929385e+02,  -1.92288685e-02]]), array([[  6.94147563e-03,  -1.48663567e-01,   1.73079969e-01,\n",
      "         -1.00802647e-01,   6.87998768e-02],\n",
      "       [ -1.62503148e-01,   1.46361431e-01,  -1.48898013e-01,\n",
      "         -1.46055339e-01,   3.76768882e-02],\n",
      "       [  1.31528884e-01,   1.28943219e-01,   3.62986464e-03,\n",
      "          3.00508273e-02,   1.25315576e-01],\n",
      "       [  3.63904004e-02,  -1.94068798e+02,   7.59097806e+02,\n",
      "          2.64931736e-02,  -4.22676523e-02],\n",
      "       [  2.81841778e-02,  -6.25100041e-02,   9.63293505e-02,\n",
      "          1.27881662e-01,   6.86715986e-03],\n",
      "       [ -1.64026803e-01,  -1.73963585e+02,   6.79782975e+02,\n",
      "         -9.66775850e-02,  -1.26643814e-01]]), array([[ -1.62143864e-02,  -1.90779654e-01,  -7.26895406e-02,\n",
      "          1.89911922e-01,   3.97458632e-02],\n",
      "       [ -1.20883249e-01,   2.04986830e-02,   8.26412047e-02,\n",
      "          1.48165873e-01,  -2.89690462e-02],\n",
      "       [ -1.13541146e-01,  -4.63522483e-02,   2.88331194e-02,\n",
      "          4.60846377e-02,  -1.95554460e-01],\n",
      "       [  5.77405102e-02,   7.43453881e-02,  -5.56386131e-02,\n",
      "          1.44150774e-01,   1.45270452e-01],\n",
      "       [ -7.91118201e-02,   1.73282021e-01,  -1.77932893e-01,\n",
      "         -1.07200573e-01,  -4.00827406e-02],\n",
      "       [  3.84767053e+01,  -1.26033657e+01,   4.94128247e+01,\n",
      "         -4.01658905e+01,  -3.50485436e+01]]), array([[  8.90640724e-02,   4.55964872e-02,   8.52804142e-03,\n",
      "          1.33654609e-01,   1.43563647e-01,   1.64822447e-01],\n",
      "       [ -3.87168716e+00,  -7.96716770e+00,  -8.90615746e+00,\n",
      "         -5.21719602e+00,  -3.43893981e+00,   2.92490207e+01],\n",
      "       [ -9.10396520e+00,  -1.90425436e+01,  -2.19114400e+01,\n",
      "         -1.28151736e+01,  -8.10064113e+00,   7.09676568e+01],\n",
      "       [  6.70737301e-02,  -5.20705861e-02,  -4.51881403e-02,\n",
      "          1.74969885e-01,  -1.17980113e-01,  -1.71083629e-02],\n",
      "       [  3.68145361e-02,  -5.50542053e-02,  -9.23984519e-02,\n",
      "          1.84039510e-01,   1.86293532e-01,   1.16329976e-01],\n",
      "       [ -8.99923131e+01,  -1.90910978e+02,  -1.22968308e+02,\n",
      "         -1.80188555e+02,  -8.49035633e+01,   6.68955788e+02]]), array([[ -1.57276492e-01,   7.63703706e-02,  -8.19187890e-02,\n",
      "         -9.39643415e-02,   7.78372464e-02,  -8.87206642e-02,\n",
      "         -1.88103474e-03],\n",
      "       [  8.43776702e-01,   1.37058919e+00,   1.34846552e+00,\n",
      "          1.15924113e-01,   8.91829216e-01,   5.31701981e+00,\n",
      "         -9.84693483e+00],\n",
      "       [  2.51040052e+00,   3.49590370e+00,   2.86161044e+00,\n",
      "          7.52762015e-01,   2.34090623e+00,   1.23256791e+01,\n",
      "         -2.39250243e+01],\n",
      "       [ -1.54007216e-01,   7.14992535e-02,   7.47367932e-02,\n",
      "          9.72753037e-02,   1.56570859e-01,  -2.35275896e-02,\n",
      "         -1.27693670e-01],\n",
      "       [ -1.24503311e-01,   1.95963354e-01,  -7.45767883e-02,\n",
      "          4.39536748e-02,  -7.40749982e-02,  -1.55371422e-01,\n",
      "          1.60665887e-01],\n",
      "       [  5.72103500e+01,   7.41088891e+01,   9.31491729e+01,\n",
      "          9.22822820e+00,   4.95335778e+01,   8.12151733e+01,\n",
      "         -3.63831762e+02]]), array([[  9.51718758e-02,  -1.65244148e-01,   5.59251041e-02,\n",
      "         -1.59054578e-01,   2.42777991e-02,   1.11712655e-01,\n",
      "         -1.11077689e-02],\n",
      "       [  3.00337432e+00,   1.05907162e+00,   8.83265446e-01,\n",
      "          2.97388598e+00,   1.18057638e+00,   2.42822286e+00,\n",
      "         -1.16486067e+01],\n",
      "       [  7.19908995e+00,   2.44961713e+00,   2.51232988e+00,\n",
      "          7.03544013e+00,   2.99909216e+00,   6.01822570e+00,\n",
      "         -2.79724688e+01],\n",
      "       [ -1.06144935e-01,   1.63216046e-01,  -8.53849459e-02,\n",
      "          1.83541814e-01,   9.08917389e-03,   1.07779792e-01,\n",
      "          1.01615575e-01],\n",
      "       [  8.09488217e-02,   6.92616252e-02,   1.36276820e-02,\n",
      "         -4.31598999e-02,  -1.45736229e-01,  -9.15165339e-02,\n",
      "         -1.96566737e-01],\n",
      "       [  1.56703092e+02,   4.84149367e+01,   5.47211439e+01,\n",
      "          1.14469950e+02,   5.88451912e+01,   4.77542500e+01,\n",
      "         -4.81148189e+02]]), array([[ -7.36885731e-03,   6.59188799e-02,   1.55378889e-01,\n",
      "          1.07388686e-01,   4.93338515e-02,  -1.47436615e-01,\n",
      "          3.56050686e-02,  -1.20727278e-01],\n",
      "       [  1.83434211e+00,   3.68310122e-01,   1.29893738e+00,\n",
      "          1.09943230e+00,   5.72453051e-01,   1.66471118e+00,\n",
      "         -5.45371701e+00,  -1.28061039e+00],\n",
      "       [  4.41669169e+00,   8.78514472e-01,   2.77503918e+00,\n",
      "          2.73917490e+00,   1.59617910e+00,   3.76159481e+00,\n",
      "         -1.28797653e+01,  -2.99561680e+00],\n",
      "       [ -2.97981938e-02,   1.69006450e-01,   3.86637246e-02,\n",
      "          1.70876314e-01,   1.08555806e-01,  -1.32158011e-01,\n",
      "          8.92012623e-03,   1.58482013e-01],\n",
      "       [ -6.33333809e-02,   1.16177025e-01,   8.61047507e-02,\n",
      "         -7.57056975e-02,  -1.72352544e-01,  -1.06352275e-01,\n",
      "         -1.53191894e-02,   1.91517280e-02],\n",
      "       [  1.64910634e+02,   3.55434823e+01,   1.56277460e+02,\n",
      "          8.26416413e+01,   7.58567292e+01,   2.00021651e+01,\n",
      "         -4.32114101e+02,  -1.03012583e+02]]), array([[-0.08809431,  0.1752488 , -0.19156752, -0.0866791 , -0.08554064,\n",
      "        -0.09650378,  0.04657932, -0.18087309],\n",
      "       [-0.19873496, -0.11497073, -0.08482416, -0.15798631, -0.12673393,\n",
      "         0.19307375, -0.19734573,  0.11802624],\n",
      "       [ 0.00583637, -0.00715498, -0.01344398, -0.08853241,  0.10520698,\n",
      "        -0.04925907,  0.08469931, -0.12603737],\n",
      "       [ 0.17888901, -0.18550275,  0.06786427,  0.11780092, -0.06889705,\n",
      "         0.0095477 ,  0.16549386,  0.0756876 ],\n",
      "       [-0.01255075,  0.16380075, -0.03251179, -0.19106981,  0.18815869,\n",
      "         0.0766019 ,  0.00073959, -0.06374324],\n",
      "       [ 0.08304479,  0.01432531, -0.04266082,  0.16377353,  0.19689971,\n",
      "        -0.04157352,  0.0983978 , -0.10853039]]), array([[  1.15224890e-01,   7.96167857e-02,   1.15780313e-02,\n",
      "          1.79431843e-01,   1.45766891e-01,   1.69008566e-02,\n",
      "         -1.06461921e-01,   5.58139513e-03,   6.91146787e-03],\n",
      "       [ -3.22668533e+00,  -1.94214150e+00,  -4.15171334e+00,\n",
      "         -6.31373810e-01,  -2.36066831e+00,   4.53113671e+00,\n",
      "          3.35154295e+00,   3.52936532e+00,   7.90616129e-01],\n",
      "       [ -7.72789555e+00,  -4.41829113e+00,  -9.62979369e+00,\n",
      "         -1.47594729e+00,  -5.96668861e+00,   1.12337635e+01,\n",
      "          7.78954624e+00,   8.65928945e+00,   1.77992417e+00],\n",
      "       [ -1.13438892e-01,   1.07530861e-02,   1.30907839e-01,\n",
      "          2.63039433e-02,   3.76350148e-02,   1.57134544e-01,\n",
      "         -9.63487847e-02,  -1.09025423e-01,   8.91845006e-03],\n",
      "       [  2.18866666e-02,   5.06462464e-02,  -1.38852453e-01,\n",
      "         -9.83293930e-02,   1.95288759e-01,   2.90676352e-02,\n",
      "          1.16919176e-01,  -4.63683334e-02,   3.07429870e-02],\n",
      "       [  8.38646336e+01,   2.93748537e+01,   1.64843847e+02,\n",
      "          9.39350651e+00,   4.80508273e+01,   1.05785284e+02,\n",
      "         -9.61551259e+01,  -2.98807984e+02,  -4.59618255e+01]]), array([[  1.70072220e-01,  -6.01184618e-03,  -1.46229463e-01,\n",
      "         -3.52672057e-03,   1.37963750e-01,   1.00309786e-01,\n",
      "         -1.40653126e-01,   7.12800912e-02,   1.57075044e-01],\n",
      "       [  1.42644998e-01,   3.51803353e-01,  -3.61347322e-02,\n",
      "          2.40932344e-01,   4.02564788e-01,   1.39168436e+01,\n",
      "         -9.85246205e+00,  -4.13203640e+00,  -1.38302439e+00],\n",
      "       [  5.92783447e-02,   3.22760083e-01,   2.32833801e-01,\n",
      "          1.16665336e+00,   1.13654437e+00,   3.34938637e+01,\n",
      "         -2.34400097e+01,  -1.00861334e+01,  -2.71674117e+00],\n",
      "       [ -7.28651362e-02,   9.83104960e-02,   8.02364725e-02,\n",
      "         -1.82481180e-01,  -1.92563230e-01,   2.15974967e-02,\n",
      "         -7.69698093e-02,   1.55719217e-01,   1.06506714e-01],\n",
      "       [  1.83206400e-01,   1.90935971e-01,   1.77354877e-01,\n",
      "         -8.08482418e-02,  -1.37552425e-01,   9.75719063e-03,\n",
      "          1.45830586e-01,   1.84123399e-02,   9.68711471e-02],\n",
      "       [  5.56950671e+01,   1.26472336e+02,   1.49404891e+02,\n",
      "          2.08268333e+02,   2.78276401e+02,  -3.66963661e+02,\n",
      "         -3.31360793e+02,  -1.08460015e+02,  -1.13619074e+01]]), array([[ -1.35082743e-01,   7.44818072e-02,  -1.30042960e-01,\n",
      "          5.43716790e-04,   1.42393415e-01,   3.43976580e-02,\n",
      "          1.15545583e-01,   1.19227753e-02,   1.54661422e-01,\n",
      "          1.30779306e-01],\n",
      "       [  1.66104721e+00,   1.06310113e+00,   6.99599016e-01,\n",
      "          2.33135799e+00,   1.16804613e+00,   1.07113533e+00,\n",
      "         -4.93961932e+00,  -2.52547925e+00,  -1.50556360e+00,\n",
      "          7.57540071e-01],\n",
      "       [  4.40785319e+00,   2.78145713e+00,   1.77052448e+00,\n",
      "          5.53316336e+00,   2.92149068e+00,   2.23151405e+00,\n",
      "         -1.20515416e+01,  -6.13584728e+00,  -3.48938782e+00,\n",
      "          1.92108447e+00],\n",
      "       [  3.81375474e-02,   3.24968686e-02,  -3.12929919e-02,\n",
      "          2.19425778e-02,  -1.02068661e-01,   8.34238357e-02,\n",
      "          2.60120185e-02,  -1.66132336e-01,   2.33613967e-02,\n",
      "          2.59233801e-02],\n",
      "       [  5.69774026e-02,   1.76907776e-01,   1.43137701e-01,\n",
      "         -1.41878503e-01,   2.59097317e-02,   3.36289942e-02,\n",
      "         -4.15906632e-02,  -9.16780390e-02,   1.40255994e-01,\n",
      "         -1.51540775e-01],\n",
      "       [  1.37701727e+02,   6.02467874e+01,   8.51218895e+01,\n",
      "          1.05937099e+02,   6.27524233e+01,   3.72094901e+00,\n",
      "         -3.02460865e+02,  -1.12447326e+02,  -6.02425214e+01,\n",
      "          1.95630064e+01]]), array([[  1.10522939e-01,  -1.69085596e-01,   7.13086530e-02,\n",
      "          1.15973908e-01,   7.91234437e-02,  -1.05008514e-01,\n",
      "          1.41905281e-01,   1.64300016e-01,   1.31794666e-01,\n",
      "         -1.83682001e-02],\n",
      "       [  6.59369583e-01,   1.84720203e+00,   3.76716476e-01,\n",
      "          1.04174133e+00,   1.51649806e+00,   4.71582116e+00,\n",
      "         -8.32532460e+00,  -1.87873135e+00,  -5.97942621e-01,\n",
      "          5.10499419e-01],\n",
      "       [  1.70715449e+00,   4.22568364e+00,   1.28125284e+00,\n",
      "          3.04470511e+00,   3.79261060e+00,   1.13464135e+01,\n",
      "         -2.02084840e+01,  -4.60759805e+00,  -1.10361106e+00,\n",
      "          9.21870940e-01],\n",
      "       [  1.01928708e-01,   6.40804450e-02,  -1.91774430e-01,\n",
      "          4.65706266e-02,   1.56427752e-02,   1.55134882e-01,\n",
      "          1.17696136e-01,   5.17849683e-02,   5.55718437e-02,\n",
      "         -1.12309546e-01],\n",
      "       [  1.73116064e-01,  -1.03326586e-01,   1.28665391e-01,\n",
      "         -3.44039392e-02,  -4.71358082e-02,   6.97503280e-02,\n",
      "         -3.30983937e-02,  -1.05149283e-01,  -5.27493111e-02,\n",
      "          7.73035935e-02],\n",
      "       [  7.42926384e+01,   1.26612899e+02,   6.09815348e+01,\n",
      "          7.08344177e+01,   1.00532814e+02,   5.08005296e+01,\n",
      "         -4.26745477e+02,  -5.95919355e+01,  -7.01757986e+00,\n",
      "          1.00561675e+01]]), array([[  1.46442439e-01,  -3.17446570e-02,  -6.06916368e-02,\n",
      "         -9.70155807e-02,   3.94452347e-02,  -2.12969999e-02,\n",
      "         -1.22908396e-01,  -1.37150975e-01,  -5.77348916e-02,\n",
      "         -1.33428537e-01],\n",
      "       [  1.17629168e-02,   1.92242409e-02,   2.14571301e-02,\n",
      "          2.38904426e-01,   7.63347622e-02,   5.85536823e+00,\n",
      "         -2.66061717e+00,  -1.42194033e+00,  -2.23978034e+00,\n",
      "         -2.54240168e-02],\n",
      "       [  4.97739954e-01,  -1.35124374e-01,   3.36787755e-01,\n",
      "          2.75739062e-01,   3.48084272e-01,   1.38586574e+01,\n",
      "         -6.29255591e+00,  -2.90530701e+00,  -5.78471711e+00,\n",
      "         -6.20735880e-03],\n",
      "       [ -1.18527727e-01,   2.56868366e-02,   6.68518875e-02,\n",
      "         -1.87153690e-01,   1.61541498e-02,  -1.56209977e-01,\n",
      "          1.99403973e-01,   4.98537587e-02,  -5.73759458e-02,\n",
      "         -1.89358536e-01],\n",
      "       [  1.07070547e-01,  -1.30539392e-01,   1.23623583e-01,\n",
      "         -1.71240929e-01,   2.60491982e-02,  -1.22208783e-01,\n",
      "          1.88714389e-01,   5.21625727e-03,   1.65835847e-01,\n",
      "         -1.32388135e-01],\n",
      "       [  8.78692346e+01,   9.94237228e+00,   1.53944501e+02,\n",
      "          4.00990110e+00,   5.51129184e+01,   3.64599303e+00,\n",
      "         -1.43460070e+02,  -6.10944933e+01,  -1.01890391e+02,\n",
      "         -8.25365655e+00]]), array([[  3.90772802e-02,   1.64876324e-01,  -6.03735284e-02,\n",
      "         -1.16823104e-01,   8.87446787e-02,  -1.88236556e-01,\n",
      "         -1.89131243e-01,   1.82750914e-01,  -1.22255039e-01,\n",
      "          1.86755567e-01],\n",
      "       [  2.37758225e+00,   3.00057288e+00,   1.22404392e+00,\n",
      "          3.18838695e+00,   1.50166998e+00,   2.26243148e+00,\n",
      "         -1.38672704e+01,  -8.02201022e-01,   4.93633668e-02,\n",
      "          9.38650053e-01],\n",
      "       [  6.05621703e+00,   7.32801221e+00,   3.23231271e+00,\n",
      "          8.20402011e+00,   3.21955623e+00,   5.61702817e+00,\n",
      "         -3.37194422e+01,  -2.28535469e+00,   1.95020300e-01,\n",
      "          1.96063676e+00],\n",
      "       [  1.39414199e-01,   1.93444361e-01,  -5.10073398e-02,\n",
      "          1.27278378e-01,  -9.80132589e-03,  -9.26238022e-02,\n",
      "          1.65531509e-01,  -1.01203881e-01,  -1.53919152e-01,\n",
      "          1.83202742e-01],\n",
      "       [  4.24532228e-02,   1.67683907e-01,   1.94839652e-01,\n",
      "         -9.06050924e-02,   4.02324093e-02,   1.20909944e-01,\n",
      "         -9.22884642e-02,  -9.14582781e-02,  -1.43518636e-03,\n",
      "          1.88793471e-01],\n",
      "       [  1.62104917e+02,   1.64551434e+02,   9.75273695e+01,\n",
      "          1.53496117e+02,   7.68228631e+01,   1.48551910e+01,\n",
      "         -6.69869617e+02,  -3.31961827e+01,   1.17156226e+01,\n",
      "          2.17386253e+01]]), array([[  3.33076558e-02,  -1.62310833e-01,  -1.58845227e-01,\n",
      "         -1.36493121e-01,   7.24929562e-02,   1.72597821e-01,\n",
      "         -1.06014455e-01,  -1.29837850e-01,  -1.30955994e-01,\n",
      "          5.69372574e-02],\n",
      "       [  6.66529371e-01,   1.96377413e+00,   3.25235926e+00,\n",
      "          6.31372466e-01,   1.11675127e+00,   2.77482582e+00,\n",
      "         -9.97420599e+00,  -1.89313104e+00,  -2.49413226e-01,\n",
      "          1.40396656e+00],\n",
      "       [  1.92474758e+00,   5.10333874e+00,   7.63036910e+00,\n",
      "          1.66634146e+00,   2.66347641e+00,   7.02154501e+00,\n",
      "         -2.45725153e+01,  -4.32311667e+00,  -3.38844723e-01,\n",
      "          3.49301539e+00],\n",
      "       [  1.70914545e-01,   1.95333834e-01,  -1.77068142e-01,\n",
      "         -1.98622634e-01,  -5.16132973e-02,   8.66819241e-02,\n",
      "          1.47977238e-01,  -1.20263451e-01,   4.92767780e-02,\n",
      "         -1.62768368e-01],\n",
      "       [ -3.69357954e-02,  -1.18060314e-01,   1.91655258e-01,\n",
      "         -1.39996857e-01,   1.84195606e-01,  -5.88025256e-02,\n",
      "          1.45283902e-01,   1.01734624e-01,   1.31675425e-01,\n",
      "         -1.03283619e-01],\n",
      "       [  6.30165995e+01,   1.47655660e+02,   2.90073759e+02,\n",
      "          4.95443826e+01,   7.67601213e+01,  -4.38644036e-01,\n",
      "         -5.86148906e+02,  -8.55116949e+01,  -6.23416242e-01,\n",
      "          4.51842732e+01]]), array([[ -1.13036199e-02],\n",
      "       [  1.83267830e+01],\n",
      "       [  4.43349208e+01],\n",
      "       [  2.14119488e-03],\n",
      "       [ -1.83155569e-01],\n",
      "       [  2.80903697e+02]])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    output_train = train(registers.eval(), memory_tape.eval(), desired_out.eval())\n",
    "    cost = output_train[0]\n",
    "    gradients = output_train[1:]\n",
    "    print(output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0]\n",
      "[Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0]\n"
     ]
    }
   ],
   "source": [
    "#training data for \"access\" \n",
    "train_data_size = 50\n",
    "train_inputs_access = []\n",
    "train_outputs_access = []\n",
    "\n",
    "input = []\n",
    "output = []\n",
    "for i in range(train_data_size):\n",
    "    #generated a random array\n",
    "    input = np.random.randint(1,15,size=(M))\n",
    "    input_t = stack([get_const(i) for i in input], axis=1)\n",
    "    #print(\"input array\", input_t.eval().argmax(axis=2))\n",
    "    train_inputs_access.append(input_t)\n",
    "    first_elem = input[0]\n",
    "    output = np.array([[input[first_elem]]])\n",
    "    output_t = stack([get_const(i) for i in output], axis=1)\n",
    "    #print(output_t.eval().argmax(axis=2))\n",
    "    train_outputs_access.append(output_t)\n",
    "print(train_inputs_access)    \n",
    "print(train_outputs_access)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0]\n",
      "[Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0, Join.0]\n"
     ]
    }
   ],
   "source": [
    "#training data for \"permutation\" \n",
    "train_data_size = 50\n",
    "train_inputs_access = []\n",
    "train_outputs_access = []\n",
    "\n",
    "start_idx = 6\n",
    "start = [start_idx]\n",
    "end = [0]\n",
    "array_len = 5\n",
    "#array_len = np.random.randint(5,M-start_idx-1)\n",
    "for i in range(train_data_size):\n",
    "    P = np.arange(array_len)\n",
    "    np.random.shuffle(P)\n",
    "    A = np.random.randint(1, M, size=M-6)\n",
    "    A[array_len] = 0\n",
    "    input = np.concatenate((start, P, A), axis=0)\n",
    "    input_t = stack([get_const(i) for i in input], axis=1)\n",
    "    #print(\"input array\", input_t.eval().argmax(axis=2))\n",
    "    train_inputs_access.append(input_t)\n",
    "    output = np.array([A[idx] for idx in P])\n",
    "    output_t = stack([get_const(i) for i in output], axis=1)\n",
    "    #print(\"output array\", output_t.eval().argmax(axis=2))\n",
    "    train_outputs_access.append(output_t)\n",
    "print(train_inputs_access)    \n",
    "print(train_outputs_access)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clamp(n, minn, maxn):\n",
    "    for i, item in enumerate(n):\n",
    "        n[i] = (map(lambda x: max(min(maxn, x), minn), item))\n",
    "    return n    \n",
    "    \n",
    "def get_l2_norm(w):\n",
    "    x=0\n",
    "    for i, item in enumerate(w):\n",
    "        x += np.linalg.norm(item)\n",
    "    return x    \n",
    "\n",
    "def add_noise(gradients, mean, std_dev):\n",
    "    result = map(lambda x: x + np.random.normal(mean,std_dev,x.shape), gradients)\n",
    "    return result\n",
    "\n",
    "\n",
    "def adam_optimize(params, train, registers, train_inputs, train_outputs, output_len,\n",
    "                  alpha=0.001, b1=0.9, b2=0.999,\n",
    "                  epsilon=1e-8, batch_size=1):\n",
    "    \"\"\"Implementation of Adam optimization method, with hyperparameters\n",
    "    taken as recommended by the original publication.\"\"\"\n",
    "    # Initialize first and second moment estimates to zero.\n",
    "    # This causes some bias, which is addressed later.\n",
    "    moment1 =  [0 for _ in params]\n",
    "    moment2 = [0 for _ in params]\n",
    "    \n",
    "    timestep = 0  # Current optimization step\n",
    "    batch = 0     # Where does this batch start\n",
    "    \n",
    "    converged = False\n",
    "    gradients = []\n",
    "    \n",
    "    while not converged:\n",
    "        timestep += 1\n",
    "        \n",
    "        inputs  = train_inputs[batch:batch+batch_size][0]\n",
    "        outputs = train_outputs[batch:batch+batch_size][0] \n",
    "        \n",
    "        #print(inputs.eval())\n",
    "        #print(outputs.eval())\n",
    "        \n",
    "        result = train(registers, inputs.eval(), outputs.eval())\n",
    "        \n",
    "        cost = result[0]\n",
    "        gradients = result[1:]\n",
    "        \n",
    "        gradients=add_noise(gradients, 0, 1/(1 + timestep)**0.55)\n",
    "        \n",
    "        # Advance to next batch.\n",
    "        batch = (batch + batch_size) % len(train_inputs)\n",
    "\n",
    "        # Compute first and second moment estimates.\n",
    "        # These are decaying moving averages; first moment\n",
    "        # uses the gradient, second uses squared gradient.\n",
    "        moment1  = [b1 * m + (1 - b1) * gradient\n",
    "                    for (m, gradient)\n",
    "                    in zip(moment1, gradients)]\n",
    "        moment2 = [b2 * v + (1 - b2) * gradient ** 2\n",
    "                   for (v, gradient)\n",
    "                   in zip(moment2, gradients)]\n",
    "        \n",
    "        # Correct for initialization bias and compute new values.\n",
    "        correction1 = 1. / (1 - b1 ** timestep)\n",
    "        correction2 = 1. / (1 - b2 ** timestep)\n",
    "        corrected1 = [correction1 * m for m in moment1]\n",
    "        corrected2 = [correction2 * v for v in moment2]\n",
    "        \n",
    "        # Compute new parameter values.\n",
    "        params_new = [p.get_value() - alpha * m1 / (np.sqrt(m2) + epsilon)\n",
    "                      for (p, m1, m2) in zip(params, corrected1, corrected2)]\n",
    "\n",
    "        # Check for convergence by looking at magnitude of delta.\n",
    "        delta = [abs(p.get_value() - p_new)\n",
    "                 for (p, p_new) in zip(params, params_new)]\n",
    "        converged = all((d < 0.5 * alpha).all() for d in delta)        \n",
    "        \n",
    "        # Update parameters to new values.\n",
    "        for p, p_new in zip(params, params_new):\n",
    "            p_new = clamp(p_new, -1, 5)\n",
    "            p.set_value(p_new.astype('float32'))\n",
    "            \n",
    "        # Provide some output for tracking during runtime.\n",
    "        if timestep % 100 == 1 or converged:\n",
    "            print(\"Cost (t = %4d): \\t%.2f\" % (timestep - 1, cost))\n",
    "            print(\"l2 norm of gradients: \", get_l2_norm(gradients))\n",
    "            print(\"l2 norm of p_new: \", get_l2_norm(p_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (t =    0): \t105640.50\n",
      "('l2 norm of gradients: ', 281789.40697129804)\n",
      "('l2 norm of p_new: ', 5.9948665952700306)\n",
      "Cost (t =  100): \t105640.50\n",
      "('l2 norm of gradients: ', 281789.40697129804)\n",
      "('l2 norm of p_new: ', 6.5598948680308338)\n",
      "Cost (t =  200): \t105640.50\n",
      "('l2 norm of gradients: ', 281789.40697129804)\n",
      "('l2 norm of p_new: ', 7.1243232976148976)\n",
      "Cost (t =  300): \t105640.50\n",
      "('l2 norm of gradients: ', 281789.40697129804)\n",
      "('l2 norm of p_new: ', 7.6884925376849358)\n",
      "Cost (t =  400): \t105640.50\n",
      "('l2 norm of gradients: ', 281789.40697129804)\n",
      "('l2 norm of p_new: ', 8.2525565404827663)\n",
      "Cost (t =  500): \t105640.50\n",
      "('l2 norm of gradients: ', 281789.40697129804)\n",
      "('l2 norm of p_new: ', 8.8165649779983486)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f12188ab5934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#                  epsilon=1e-8, batch_size=1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_inputs_access\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_outputs_access\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-15fe629519a8>\u001b[0m in \u001b[0;36madam_optimize\u001b[0;34m(params, train, registers, train_inputs, train_outputs, output_len, alpha, b1, b2, epsilon, batch_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#print(outputs.eval())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregisters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def adam_optimize(params, train, train_inputs, mem, train_outputs, output_len,\n",
    "#                  alpha=0.001, b1=0.9, b2=0.999,\n",
    "#                  epsilon=1e-8, batch_size=1):\n",
    "    \n",
    "result = adam_optimize(w, train, registers.eval(), train_inputs_access, train_outputs_access, output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5820272  -1.58195782 -1.39006913 -1.46808684 -1.5820272 ]\n",
      " [-1.5820272   1.85517943 -1.36681986 -1.17259645 -1.5820272 ]\n",
      " [-1.5820272   1.9800458  -0.67167199 -1.4658426   1.9800458 ]\n",
      " [ 1.9800458  -0.82227963 -0.48235503 -1.45985949  1.9800458 ]\n",
      " [-1.5820272   1.97981215 -1.3075155  -1.46052396 -1.5820272 ]\n",
      " [ 1.9800458   1.75512171  0.08379318 -1.54254603  1.9800458 ]]\n",
      "[[ 1.9800458   1.9800458  -1.5820272   1.9800458   1.9800458 ]\n",
      " [-1.5820272  -1.58195782  0.7977922   1.9800458  -1.58195782]\n",
      " [-1.58181906 -1.53766978  1.86326826 -1.53687298 -1.53352511]\n",
      " [ 0.83942389 -1.53775883  1.50290775 -1.53697324 -1.53362954]\n",
      " [ 1.05409169  1.9800458  -1.5820272   1.9800458   1.9800458 ]\n",
      " [ 1.14313841 -1.53770864  1.86337221 -1.53691614 -1.53356898]]\n",
      "[[-1.58195782  1.97981215 -1.5820272   1.97992897  0.91708648]\n",
      " [-0.87685418  0.56759787 -1.08618116  0.25055104 -0.78728998]\n",
      " [-0.12010951  0.35268214  0.23217726  0.87799788  1.1698575 ]\n",
      " [-0.15461349 -0.90247059 -1.09806836 -0.43884385 -0.96770763]\n",
      " [ 0.66977215 -0.0438819  -0.5756591   0.75751722 -0.05508063]\n",
      " [-0.52499354  0.5272752  -1.08058465  0.39865842  0.9725827 ]]\n",
      "[[ 1.97992897 -1.24703169  1.18245554  1.9800458  -1.40422416 -0.73865324]\n",
      " [ 1.28219211  1.85948968 -1.3747195   1.85672402  1.86012709  1.79519343]\n",
      " [ 1.35537958  1.86334562 -1.49867666  1.5797261   1.86309779  1.79523301]\n",
      " [ 1.83599722  1.85981977 -1.49869001  1.64268255  1.86067617  1.42573678]\n",
      " [ 1.83597958  1.8590951  -1.49861133  1.8562454   1.85979223  1.79517293]\n",
      " [ 1.83598197  1.85934019 -1.49860561  1.85662377  1.86006939  1.45814919]]\n",
      "[[-1.58195782 -1.29560423  1.26223779  0.86806715  1.92869771 -1.58195782\n",
      "  -1.5820272 ]\n",
      " [ 1.83291829 -0.83182406 -1.44192958 -1.3637408  -1.39795971  1.76011372\n",
      "   1.70109355]\n",
      " [ 1.83065283 -0.51807195 -1.44192851 -0.77835178 -1.04542303  1.4454881\n",
      "   1.61358595]\n",
      " [ 1.8334173  -1.40437043 -1.44196069 -0.73000062 -1.40389776  1.69511485\n",
      "   1.70112729]\n",
      " [ 1.83311188 -1.39756525 -1.08106542 -1.36517525 -1.40078425  1.76014268\n",
      "   1.70107317]\n",
      " [ 1.8325218  -1.39438677 -1.44192195 -1.36319435 -1.39828217  1.76017833\n",
      "   1.45254016]]\n",
      "[[ 1.97992897  1.97992897  1.89554882 -1.58195782 -1.58195782 -0.80599606\n",
      "  -1.16336334]\n",
      " [ 1.83478665 -1.45527399 -1.48176003 -1.39281607 -1.45163012  1.77196741\n",
      "   1.77109611]\n",
      " [ 1.83488309 -1.45084369 -1.48178458 -1.39115024 -1.44809079  1.77193868\n",
      "   1.77112997]\n",
      " [ 1.83490491 -1.17779887 -1.4818002  -1.24034059 -1.45098925  1.77202034\n",
      "   1.771173  ]\n",
      " [ 1.83475876 -1.45568991 -1.48174977 -1.36833811 -1.2377485   1.56478763\n",
      "   1.77108061]\n",
      " [ 1.83474123 -1.45547926 -1.48174477 -1.39393687 -1.45169342  1.23313844\n",
      "   1.77106726]]\n",
      "[[ 1.47014821  1.67693937 -1.36095953 -1.5820272  -1.58195782  0.98993498\n",
      "   1.97992897  1.01107407]\n",
      " [ 1.90287316 -1.52973664 -1.54269028  1.34091818 -1.53503478  1.88073146\n",
      "   1.89464998  1.91895604]\n",
      " [ 1.90301216 -1.50131011 -1.54063511  1.94943523 -1.53505814  1.68394804\n",
      "   1.52049708  1.91902351]\n",
      " [ 1.90283704 -1.53378201 -1.54298389 -0.24564998 -1.53508544  1.66507161\n",
      "   1.45840287  1.91893911]\n",
      " [ 1.62460899 -1.53106952 -1.54281509  1.06726122 -1.53502309  1.88070321\n",
      "   1.89463294  1.91896415]\n",
      " [ 1.90289879 -1.53032088 -1.54272628  1.16048229 -1.53501594  1.88069212\n",
      "   1.89461076  1.91897178]]\n",
      "[[ 1.34828353 -1.35518038  0.96759111 -1.16979635 -1.58195782  1.36628807\n",
      "   1.67077422  1.9800458 ]\n",
      " [ 1.97992897  1.85907519  0.89466131  1.670856    1.9800458   1.34496295\n",
      "  -1.58195782  1.97992897]\n",
      " [ 1.41431892 -1.5820272  -1.02574301 -1.58195782  1.97992897  1.45897293\n",
      "   1.10345292  0.95506829]\n",
      " [ 1.7295047   1.97992897  1.66353333  1.0616678  -1.58195782  1.9795785\n",
      "   1.64312851 -1.5820272 ]\n",
      " [-0.97245145 -1.5820272   1.26910102 -0.77273774 -1.58195782  1.97992897\n",
      "   1.97992897 -0.96943611]\n",
      " [ 1.3737818  -0.99508935 -0.80880797 -0.73245513  1.41814673 -1.31035304\n",
      "  -0.98412317  1.41379178]]\n",
      "[[-1.22982025 -0.85559094  1.9795785  -1.58195782 -1.26129425 -1.12753737\n",
      "  -1.58188844  1.74038839 -1.57449603]\n",
      " [ 1.9157238  -1.55599058 -1.55550373  0.13734347 -1.55559504  1.87905014\n",
      "   1.93589103  1.9210645   0.15273795]\n",
      " [ 1.91574752 -1.55665815 -1.55557024  1.62137806 -1.55560708  1.87910366\n",
      "   1.93581116  1.92097104  0.00903955]\n",
      " [ 1.91567993 -1.55556893 -1.55539978 -0.79533774 -1.55561674  1.44981885\n",
      "   1.68309546  1.92103446  0.04747731]\n",
      " [ 1.91572905 -1.55604339 -1.55560756  0.38260525 -1.55558968  1.87901962\n",
      "   1.93592536  1.51710606 -0.21665956]\n",
      " [ 1.6576941  -1.55622792 -1.55557549  0.15522164 -1.55558527  1.80515778\n",
      "   1.93596148  1.92109716 -0.32675666]]\n",
      "[[ 1.97992897 -1.58195782  1.97992897  0.9676829   1.97992897 -1.58195782\n",
      "  -1.58091712  0.86607862 -1.5820272 ]\n",
      " [ 1.63246024  1.45037031  1.44909489  1.45090735  1.45042396 -1.46749616\n",
      "   1.55244732  1.26711285  1.40050769]\n",
      " [ 1.14750814  1.4569025   1.07223868  1.29988265  0.46782684 -1.46745849\n",
      "   1.55010283  1.77257621  1.46466029]\n",
      " [ 1.05109155  1.16553974  0.69119126  1.24890161  0.40340957 -1.46738005\n",
      "   0.54764253  1.29805648  1.46491599]\n",
      " [ 0.99201018  1.09396303  1.4499172   0.99053955  0.99103415 -1.46752441\n",
      "   0.93881655  1.77281833  1.4643122 ]\n",
      " [ 1.10544848  0.71630746  1.25477135  0.94447136  1.45095122 -1.46755826\n",
      "   1.55273187  1.7728833   0.95903879]]\n",
      "[[-1.35851264  1.40384972  0.8814261  -1.58195782 -1.58195782  1.02085924\n",
      "   1.78635097  1.87286699 -0.94766361 -1.5820272 ]\n",
      " [-0.94721055 -1.34633911 -1.3745873  -1.28358841 -1.34119976  1.55608594\n",
      "  -0.83608776  1.40603805 -1.33614886  1.01896703]\n",
      " [-1.4055841  -1.33280742 -1.35031044 -1.23849118 -1.33000982  1.55625451\n",
      "   0.39621708  1.49394572 -0.49204022  1.4043535 ]\n",
      " [-1.40566909 -1.34645021 -1.37589431 -1.05481231 -1.34107614  1.55608308\n",
      "   0.41693467  1.05472672 -1.33716786  1.51126254]\n",
      " [-1.40555251 -1.34745967 -1.37635911 -1.28368843 -1.14733434  1.55607176\n",
      "   0.12749697  0.99069339 -1.33745778  0.59279865]\n",
      " [-1.40552711 -1.33104932 -0.77488661 -1.28365588 -1.34097648  1.55608261\n",
      "   0.24685657  1.49384558 -1.33601809  0.58434629]]\n",
      "[[-1.58195782  1.9800458  -1.58195782 -1.58195782 -0.88074005  1.06594598\n",
      "  -1.58195782 -1.54327917 -1.58195782  1.61505938]\n",
      " [ 1.52463329 -1.48938918 -1.5485239   1.54479289 -1.53810716  1.90612102\n",
      "   1.90416718  1.8983798   1.86624062  1.90616405]\n",
      " [ 1.895419   -1.5443356  -1.54853415  1.90955842 -1.53820431  1.90616381\n",
      "   1.90422952  1.89837861  1.68835056  1.90620327]\n",
      " [ 1.8954016  -1.54433632 -1.54854739  1.90356219 -1.5380882   1.90618765\n",
      "   1.90423155  1.89836895  1.89959514  1.90623093]\n",
      " [ 1.89542127 -1.54431212 -1.54852116  1.90398085 -1.53809941  1.9061048\n",
      "   1.9041481   1.89838493  1.89951754  1.90614581]\n",
      " [ 1.89542258 -1.54431665 -1.54851806  1.90417683 -1.53815305  1.76300168\n",
      "   1.90413785  1.89838672  1.89955735  1.47780418]]\n",
      "[[ 1.96186352 -1.58195782  1.97969532  1.97992897  1.06190944 -1.58188844\n",
      "  -1.58188844  1.97992897 -1.58188844  1.66077995]\n",
      " [ 1.52055836  1.77468717 -1.52204537  1.8908993   1.89271235  1.84658861\n",
      "   1.78107667  1.86312652  1.58243942  1.84671056]\n",
      " [ 1.86571968  1.78308523 -1.52206933  1.89458084  1.89336634  1.38641989\n",
      "   1.78115749  1.86314821  1.36741483  1.84676933]\n",
      " [ 1.66097414  1.8928746  -1.5220964   1.89025092  1.89286911  1.84667444\n",
      "   1.78121507  1.86314738  1.85223973  1.84679413]\n",
      " [ 1.86568832  1.89312327 -1.52203417  1.89058721  1.66497815  1.84656894\n",
      "   1.69560409  1.34325135  1.85208571  1.84669185]\n",
      " [ 1.8656863   1.89321637 -1.4070735   1.89071381  1.8926897   1.84655809\n",
      "   1.78102779  1.86311829  1.51224017  1.8466785 ]]\n",
      "[[ 1.97992897 -1.58195782 -1.58195782  1.29849148  1.97992897 -1.24982786\n",
      "  -0.91290444  1.9800458  -0.79714006 -1.4975704 ]\n",
      " [ 1.86075175 -1.37648284  1.12385082  1.45786285  1.58269453  1.41698742\n",
      "   1.48751533  1.88274336  0.89829296  1.54148579]\n",
      " [ 1.88793242 -1.37521875  1.85738349 -1.57693386  1.9713546   1.55055559\n",
      "   1.90889251  1.88568127  1.97399509  0.62091058]\n",
      " [ 1.48365021 -1.37673664  0.05635317  1.9393115  -0.05067687  1.54206896\n",
      "   1.8634634   1.88223135 -0.00929141  0.66483921]\n",
      " [ 1.51227474 -1.37660027 -0.53023708 -0.43062308  1.29099667  0.98062992\n",
      "   1.86842191  1.88253534  1.27768993  1.54271328]\n",
      " [ 1.60316598 -1.36416852  0.2654441  -1.57392478  1.42485046  0.80297828\n",
      "   1.8715831   1.44102657  1.76391304  1.39129281]]\n",
      "[[-1.58195782  1.16874039 -1.58188844  0.79604834 -1.58195782 -1.58195782\n",
      "   1.65362501  1.45266759  1.97981215 -1.5820272 ]\n",
      " [ 1.44374764 -1.54637325 -1.54787886  1.50709891 -1.54284453  1.89102781\n",
      "   1.90671861  1.68497467  1.5934813   1.89108682]\n",
      " [ 1.89944136 -1.54638338 -1.54790103  1.90357399 -1.54082274  1.89108801\n",
      "   1.90679097  1.90818453  1.89129174  1.89115155]\n",
      " [ 1.65314698 -1.54641032 -1.54790354  1.89666498 -1.54326785  1.89112711\n",
      "   1.744349    1.90816939  1.88715076  1.89118755]\n",
      " [ 1.62610471 -1.546368   -1.54787016  1.8972789  -1.54297388  1.89100373\n",
      "   1.9066999   1.90819871  1.88746977  1.89106345]\n",
      " [ 1.89945245 -1.54636288 -1.54787135  1.89741647 -1.54294062  1.50875545\n",
      "   1.90668797  1.90820253  1.88749492  1.89104939]]\n",
      "[[-1.5708251 ]\n",
      " [-1.54042614]\n",
      " [-1.53935897]\n",
      " [-1.54051483]\n",
      " [-1.54055953]\n",
      " [-1.54040134]]\n"
     ]
    }
   ],
   "source": [
    "for W in w:\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Access Task\n",
    "input = [ 7,  1,  12,  4,  7,  12,  1,  13,  8,  2, 1, 3, 11, 11, 12, 0]\n",
    "output = [ 13 ]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Permutation Task\n",
    "input = [ 6,  1,  3,  2,  5,  4,  9,  13,  8,  2, 1, 0, 0, 0, 0, 0]\n",
    "output = [ 9, 8, 13, 1, 2]\n",
    "registers = get_registers(0)\n",
    "memory_tape = stack([get_const(i) for i in input], axis=1)\n",
    "desired_out = stack([get_const(i) for i in output], axis=1)\n",
    "output_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('registers = ', array([[0, 0, 0, 0, 0]]))\n",
      "('memory tape:  ', array([[ 6,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('registers = ', array([[6, 0, 0, 1, 0]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 1.12074194]]]))\n",
      "('cum error = ', array([[ 1186.88086259]]))\n",
      "('prob_incomplete = ', array([[[ 1.]]]))\n",
      "('registers = ', array([[ 9,  1,  0,  1, 12]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 2.21756133]]]))\n",
      "('cum error = ', array([[ 1250.66919713]]))\n",
      "('prob_incomplete = ', array([[[ 1.]]]))\n",
      "('registers = ', array([[1, 1, 1, 2, 9]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 3.91212552]]]))\n",
      "('cum error = ', array([[ 1291.17321054]]))\n",
      "('prob_incomplete = ', array([[[ 1.]]]))\n",
      "('registers = ', array([[1, 1, 2, 1, 1]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 6.07162712]]]))\n",
      "('cum error = ', array([[ 1322.89801789]]))\n",
      "('prob_incomplete = ', array([[[ 1.]]]))\n",
      "('registers = ', array([[0, 0, 1, 3, 1]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 8.55554056]]]))\n",
      "('cum error = ', array([[ 1350.78113837]]))\n",
      "('prob_incomplete = ', array([[[ 1.]]]))\n",
      "('registers = ', array([[0, 0, 2, 2, 1]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 11.17673496]]]))\n",
      "('cum error = ', array([[ 1376.7922067]]))\n",
      "('prob_incomplete = ', array([[[ 0.99999991]]]))\n",
      "('registers = ', array([[0, 0, 2, 2, 2]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 13.8519956]]]))\n",
      "('cum error = ', array([[ 1401.61023353]]))\n",
      "('prob_incomplete = ', array([[[ 0.9999999]]]))\n",
      "('registers = ', array([[0, 0, 2, 2, 2]]))\n",
      "('memory tape:  ', array([[ 0,  1,  3,  2,  5,  4,  9, 13,  8,  2,  1,  0,  0,  0,  0,  0]]))\n",
      "('desired tape: ', array([[ 9,  8, 13,  1,  2]]))\n",
      "('cum cost = ', array([[[ 16.54904656]]]))\n",
      "('cum error = ', array([[ 1425.48914475]]))\n",
      "('prob_incomplete = ', array([[[ 0.9999999]]]))\n",
      "('registers = ', array([[0, 0, 2, 2, 0]]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-480ee9ab1df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mregisters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcum_prob_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_incomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"registers = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory tape:  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"desired tape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cum cost = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, inputs_to_values)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m             defaults)\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1454\u001b[0m                         optimizer, inputs, outputs)\n\u001b[1;32m   1455\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m                     \u001b[0moptimizer_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph, start_from)\u001b[0m\n\u001b[1;32m   1877\u001b[0m                     \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0mcurrent_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m                 \u001b[0mnb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1880\u001b[0m             \u001b[0mloop_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(self, fgraph, node, lopt)\u001b[0m\n\u001b[1;32m   1805\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m             \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_all_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/toolbox.pyc\u001b[0m in \u001b[0;36mreplace_all_validate\u001b[0;34m(self, fgraph, replacements, reason, verbose)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/toolbox.pyc\u001b[0m in \u001b[0;36mvalidate_\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mexecute_callbacks\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mtf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_callbacks_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_callbacks_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/destroyhandler.pyc\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_contains_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInconsistencyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dependency graph contains cycles\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavimishra/miniconda2/lib/python2.7/site-packages/theano/gof/destroyhandler.pyc\u001b[0m in \u001b[0;36m_contains_cycle\u001b[0;34m(fgraph, orderings)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0;31m# insert node in node_to_children[r]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;31m# (if r is not already in node_to_children,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v0 = as_tensor(0)\n",
    "v1 = as_tensor(1)\n",
    "output = [registers, memory_tape, v0, v0, v0, v1]\n",
    "new_registers = []\n",
    "print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "for timestep in range(MAX_TIMESTEP):\n",
    "    output = machine_compute_step_t(False, R, layers, w, gates, timestep+1, desired_out, output_len, *(output))\n",
    "    registers, memory_tape, cum_error, cost, cum_prob_t, prob_incomplete = output    \n",
    "    print(\"registers = \", registers.eval().argmax(axis=2))\n",
    "    print(\"memory tape:  \", memory_tape.eval().argmax(axis=2))\n",
    "    print(\"desired tape: \", desired_out.eval().argmax(axis=2))\n",
    "    print(\"cum cost = \", cost.eval())\n",
    "    print(\"cum error = \", cum_error.eval())\n",
    "    print(\"prob_incomplete = \", prob_incomplete.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": "6",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
